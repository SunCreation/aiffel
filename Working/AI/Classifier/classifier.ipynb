{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Making Datas Classifier\n",
    "=\n",
    "\n",
    "## 1. 목적 및 의의\n",
    "## 2. 데이터 준비 및 살펴보기\n",
    "## 3. 데이터 구분: train, validation 용도에 맞춰 나누기\n",
    "## 4. 머신러닝 모델 준비하기\n",
    "## 5. 머신러닝 모델 평가\n",
    "## 6. 정확도 분석을 통한 좋은 모델 선택\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 목적 및 의의\n",
    "\n",
    "### 숫자, 와인, 유방암의 자료를 분석해보고, 정보들을 기준으로 구분하는 머신러닝 모델을 구현하겠다. 뛰어난 성능을 기대하기보다는 여러가지 자료를 다뤄보고, 데이터 분석을 위해 여러 모델을 사용해본 후, 데이터에 따라 어떤 모델을 사용하는 것이 적합할지 확인해보겠다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 데이터 준비 및 살펴보기\n",
    "\n",
    " - ## 데이터 준비: (데이터 준비 부터는 Digits, Wine, Dreast cancer 나눠서 진행하겠습니다. 해당 위치를 클릭하세요.)\n",
    "     - ## <li> [Digits](#digits) </li>\n",
    "     - ## <li> [Wine](#wine) </li>\n",
    "     - ## <li> [Breast cancer](#breast-cancer) </li>\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "digits = load_digits()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " - 데이터 분석\n",
    " 먼저 데이터를 출력해보겠다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "print(digits)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
      "       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), 'target': array([0, 1, 2, ..., 8, 9, 8]), 'frame': None, 'feature_names': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
      "        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
      "        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
      "        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
      "        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
      "        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
      "        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
      "        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
      "        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]), 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 조금 길지만, digits데이터는 dictionary형태로 생김이 확인된다.\n",
    "### 이어서 key값을 확인해보겠다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "print(digits.keys()) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 위에도 어렴풋이 보이는 키값들이 나온다. data는 행렬 형태로 정수 값들이 들어있는 것으로 보이며, DESCR은 무언가의 설명으로 보인다. 정보를 파악할 필요가 있으므로, DESCR부터 출력해보겠다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "print(digits.DESCR)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 숫자 손글씨에 대한 시각적 인식을 위한 자료이다. 이는 Nist의 자료에서 가져온 데이터로, 30명의 손글씨로 train하고, 13명의 손글씨로 test를 할 수 있도록 제공하고 있다. 32x32의bit-map을 4x4크기 단위로 묶어서 데이터 크기를 $\\frac{1}{16}$ 로 줄였다. 이로 학습 속도를 높이고, 여러가지 모델을 확인해보기 좋게 되어있다. 이러한 내용들이 나와있다.\n",
    "\n",
    "### 이어서 각 항목에 대한 자료는 다음과 같다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "print(digits.data)  # 8x8 그림으로 예상된다."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize= (14,7))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(digits.data[i].reshape(8,8),cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show() "
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x504 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "해상도를 조금 포기했지만, 어렴풋이 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 임을 확인 할 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "print(digits.target)\n",
    "print(digits.target.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 2 ... 8 9 8]\n",
      "(1797,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "위 사진자료에 대한 정답지로 생각할 수 있겠다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "print(digits.frame)                       # 아무것도 들어있지 않다.\n",
    "print(digits.feature_names)               # 픽셀의 각 자리의 이름이 들어있다."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n",
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "print(digits.target_names)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "0, 1, 2, 3, 4, 5, 6, 7, 8, 9 가 맞다는 것이 드러났다. target_names는 사진자료가 무엇으로 분류될 수 있는지 범주를 제공한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "print(digits.images)\n",
    "print(\"digits.images.shape:\", digits.images.shape, \"\\tdigits.data.shape\",digits.data.shape)\n",
    "print(\"digits.images:\", type(digits.images), \"\\tdigits.data:\", type(digits.data))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[ 0.  0.  5. ...  1.  0.  0.]\n",
      "  [ 0.  0. 13. ... 15.  5.  0.]\n",
      "  [ 0.  3. 15. ... 11.  8.  0.]\n",
      "  ...\n",
      "  [ 0.  4. 11. ... 12.  7.  0.]\n",
      "  [ 0.  2. 14. ... 12.  0.  0.]\n",
      "  [ 0.  0.  6. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  5.  0.  0.]\n",
      "  [ 0.  0.  0. ...  9.  0.  0.]\n",
      "  [ 0.  0.  3. ...  6.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  1. ...  6.  0.  0.]\n",
      "  [ 0.  0.  1. ...  6.  0.  0.]\n",
      "  [ 0.  0.  0. ... 10.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ... 12.  0.  0.]\n",
      "  [ 0.  0.  3. ... 14.  0.  0.]\n",
      "  [ 0.  0.  8. ... 16.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  9. 16. ...  0.  0.  0.]\n",
      "  [ 0.  3. 13. ... 11.  5.  0.]\n",
      "  [ 0.  0.  0. ... 16.  9.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  1. ...  1.  0.  0.]\n",
      "  [ 0.  0. 13. ...  2.  1.  0.]\n",
      "  [ 0.  0. 16. ... 16.  5.  0.]\n",
      "  ...\n",
      "  [ 0.  0. 16. ... 15.  0.  0.]\n",
      "  [ 0.  0. 15. ... 16.  0.  0.]\n",
      "  [ 0.  0.  2. ...  6.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  2. ...  0.  0.  0.]\n",
      "  [ 0.  0. 14. ... 15.  1.  0.]\n",
      "  [ 0.  4. 16. ... 16.  7.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ... 16.  2.  0.]\n",
      "  [ 0.  0.  4. ... 16.  2.  0.]\n",
      "  [ 0.  0.  5. ... 12.  0.  0.]]\n",
      "\n",
      " [[ 0.  0. 10. ...  1.  0.  0.]\n",
      "  [ 0.  2. 16. ...  1.  0.  0.]\n",
      "  [ 0.  0. 15. ... 15.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  4. 16. ... 16.  6.  0.]\n",
      "  [ 0.  8. 16. ... 16.  8.  0.]\n",
      "  [ 0.  1.  8. ... 12.  1.  0.]]]\n",
      "digits.images.shape: (1797, 8, 8) \tdigits.data.shape (1797, 64)\n",
      "digits.images: <class 'numpy.ndarray'> \tdigits.data: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 왜인지 data와 겹치게, images 데이터가 또 있다. 자세히 보니 data는 images의 $8 \\times 8$ 크기의 자료를 계산에 다루기 쉽게, $1 \\times 64$ 의 행렬로 펴준 상태인 것으로 보인다. 머신러닝 모델 학습에는 data를 활용하도록 하겠다.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# 3. 데이터 구분\n",
    "\n",
    "### 이제 digits의 데이터를 머신러닝 모델 학습에 사용할 수 있도록 가공하겠다. 다만 제공되는 digits.data에서 이미 $ 8 \\times 8$ 데이터를 한줄로 펴주었으니, 그대로 활용하도록 하겠다.\n",
    "### 현재 1797개의 손글씨가 digits.data에 $64 \\times 1$ 형태로 들어있고, 그 수의 숫자가 digits.target에 들어있다. 그러므로 이 두 정보를 학습시키는데에, 또 성능을 검사하는데에도 사용할 수 있다. 하지만, 학습한 데이터로 성능을 검사한다면, 답지를 주고 시험을 보는 것과 다를 것이 없기때문에, 인공지능의 성능을 올바로 평가할 수 없다. 따라서 이 두 데이터를 각각 다시 둘로 나눠 생각하도록 하겠다. digits.data를 x_train, x_test, digits.target을 y_train, y_test로 나누도록 하겠다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(digits.data,\n",
    "                            digits.target,\n",
    "                            test_size=0.2,\n",
    "                            random_state=21) \n",
    "\n",
    "# random_state를 보면 알 수 있듯이, train_test_split함수가 데이터를 무작위하게 나누어 준다."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. 머신러닝 모델 준비하기\n",
    "\n",
    "기다렸던 대망의 머신러닝 모델입니다. 가장 중요한 부분이라고 할 수 있죠. 본 글에서 제가 다뤄볼 모델은 5가지 입니다.\n",
    " 1. ### Decision Tree Classifier      \n",
    " 2. ### Random Forest Classifier     \n",
    " 3. ### Support Vector Mechine Classifier    \n",
    " 4. ### Stochastic Gradient Descent Classifier    \n",
    " 5. ### Logistic Regression Classifier     "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# wine\n",
    "\n",
    "[\\[목차\\]](#making-datas-classifier)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Breast cancer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('Working': venv)"
  },
  "interpreter": {
   "hash": "2e073fd8b018c378d21515a579cd74fd900bc137dc30cf56adc43f33b9b98e44"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}