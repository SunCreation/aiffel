{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Making Datas Classifier\n",
    "=\n",
    "\n",
    "## 1. 목적 및 의의\n",
    "## 2. 데이터 준비 및 살펴보기\n",
    "## 3. 데이터 구분: train, validation 용도에 맞춰 나누기\n",
    "## 4. 머신러닝 모델 학습 및 평가\n",
    "## 5. 정확도 분석을 통한 좋은 모델 선택\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 목적 및 의의\n",
    "\n",
    "### 숫자, 와인, 유방암의 자료를 분석해보고, 정보들을 기준으로 구분하는 머신러닝 모델을 구현하겠습니다. 뛰어난 성능을 기대하기보다는 여러가지 자료를 다뤄보고, 데이터 분석을 위해 여러 모델을 사용해본 후, 데이터에 따라 어떤 모델을 사용하는 것이 적합할지 확인해볼 예정입니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 데이터 준비 및 살펴보기\n",
    "\n",
    " - ## 데이터 준비: (데이터 준비 부터는 [Digits](#digits), [Wine](#wine), [Breast cancer](#breast-cancer) 나눠서 진행하겠습니다. 해당 위치를 클릭하세요.)\n",
    "    \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "digits = load_digits()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " - 데이터 분석\n",
    " 먼저 데이터를 출력해보겠다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "print(digits)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
      "       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), 'target': array([0, 1, 2, ..., 8, 9, 8]), 'frame': None, 'feature_names': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
      "        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
      "        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
      "        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
      "        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
      "        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
      "        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
      "        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
      "        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]), 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 조금 길지만, digits데이터는 dictionary형태로 생김이 확인된다.\n",
    "### 이어서 key값을 확인해보겠다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print(digits.keys()) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 위에도 어렴풋이 보이는 키값들이 나온다. data는 행렬 형태로 정수 값들이 들어있는 것으로 보이며, DESCR은 무언가의 설명으로 보인다. 정보를 파악할 필요가 있으므로, DESCR부터 출력해보겠다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(digits.DESCR)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 숫자 손글씨에 대한 시각적 인식을 위한 자료이다. 이는 Nist의 자료에서 가져온 데이터로, 30명의 손글씨로 train하고, 13명의 손글씨로 test를 할 수 있도록 제공하고 있다. 32x32의bit-map을 4x4크기 단위로 묶어서 데이터 크기를 $\\frac{1}{16}$ 로 줄였다. 이로 학습 속도를 높이고, 여러가지 모델을 확인해보기 좋게 되어있다. 이러한 내용들이 나와있다.\n",
    "\n",
    "### 이어서 각 항목에 대한 자료는 다음과 같다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(digits.data)  # 8x8 그림으로 예상된다."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize= (14,7))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(digits.data[i].reshape(8,8),cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show() "
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x504 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "해상도를 조금 포기했지만, 어렴풋이 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 임을 확인 할 수 있다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print(digits.target)\n",
    "print(digits.target.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 2 ... 8 9 8]\n",
      "(1797,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "위 사진자료에 대한 정답지로 생각할 수 있겠습니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(digits.frame)                       # 아무것도 들어있지 않다.\n",
    "print(digits.feature_names)               # 픽셀의 각 자리의 이름이 들어있다."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n",
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "각 픽셀의 이름이 들어있으니, 사용해보도록 하겠습니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "digits.frame = pd.DataFrame(digits.data,columns=digits.feature_names)\n",
    "digits.frame.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0        0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1        0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2        0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3        0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4        0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "\n",
       "   pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3        0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "\n",
       "   pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0        0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1        0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2        0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3        0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4        0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "\n",
       "   pixel_7_6  pixel_7_7  \n",
       "0        0.0        0.0  \n",
       "1        0.0        0.0  \n",
       "2        9.0        0.0  \n",
       "3        0.0        0.0  \n",
       "4        0.0        0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 원하던대로, DataFrame이 생성된 것을 확인할 수 있습니다. 이제 정답까지 매칭시켜 보겠습니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "digits.frame['target'] = digits.target.astype(str)\n",
    "digits.frame.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0        0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1        0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2        0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3        0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4        0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "\n",
       "   pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
       "0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "3        0.0        0.0        0.0        8.0  ...        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "\n",
       "   pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
       "0        0.0        6.0       13.0       10.0        0.0        0.0   \n",
       "1        0.0        0.0       11.0       16.0       10.0        0.0   \n",
       "2        0.0        0.0        3.0       11.0       16.0        9.0   \n",
       "3        0.0        7.0       13.0       13.0        9.0        0.0   \n",
       "4        0.0        0.0        2.0       16.0        4.0        0.0   \n",
       "\n",
       "   pixel_7_7  target  \n",
       "0        0.0       0  \n",
       "1        0.0       1  \n",
       "2        0.0       2  \n",
       "3        0.0       3  \n",
       "4        0.0       4  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(digits.target_names)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "target_names는 사진자료가 무엇으로 분류될 수 있는지 범주를 제공합니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(digits.images)\n",
    "print(\"digits.images.shape:\", digits.images.shape, \"\\tdigits.data.shape\",digits.data.shape)\n",
    "print(\"digits.images:\", type(digits.images), \"\\tdigits.data:\", type(digits.data))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[ 0.  0.  5. ...  1.  0.  0.]\n",
      "  [ 0.  0. 13. ... 15.  5.  0.]\n",
      "  [ 0.  3. 15. ... 11.  8.  0.]\n",
      "  ...\n",
      "  [ 0.  4. 11. ... 12.  7.  0.]\n",
      "  [ 0.  2. 14. ... 12.  0.  0.]\n",
      "  [ 0.  0.  6. ...  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...  5.  0.  0.]\n",
      "  [ 0.  0.  0. ...  9.  0.  0.]\n",
      "  [ 0.  0.  3. ...  6.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  1. ...  6.  0.  0.]\n",
      "  [ 0.  0.  1. ...  6.  0.  0.]\n",
      "  [ 0.  0.  0. ... 10.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ... 12.  0.  0.]\n",
      "  [ 0.  0.  3. ... 14.  0.  0.]\n",
      "  [ 0.  0.  8. ... 16.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  9. 16. ...  0.  0.  0.]\n",
      "  [ 0.  3. 13. ... 11.  5.  0.]\n",
      "  [ 0.  0.  0. ... 16.  9.  0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.  0.  1. ...  1.  0.  0.]\n",
      "  [ 0.  0. 13. ...  2.  1.  0.]\n",
      "  [ 0.  0. 16. ... 16.  5.  0.]\n",
      "  ...\n",
      "  [ 0.  0. 16. ... 15.  0.  0.]\n",
      "  [ 0.  0. 15. ... 16.  0.  0.]\n",
      "  [ 0.  0.  2. ...  6.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  2. ...  0.  0.  0.]\n",
      "  [ 0.  0. 14. ... 15.  1.  0.]\n",
      "  [ 0.  4. 16. ... 16.  7.  0.]\n",
      "  ...\n",
      "  [ 0.  0.  0. ... 16.  2.  0.]\n",
      "  [ 0.  0.  4. ... 16.  2.  0.]\n",
      "  [ 0.  0.  5. ... 12.  0.  0.]]\n",
      "\n",
      " [[ 0.  0. 10. ...  1.  0.  0.]\n",
      "  [ 0.  2. 16. ...  1.  0.  0.]\n",
      "  [ 0.  0. 15. ... 15.  0.  0.]\n",
      "  ...\n",
      "  [ 0.  4. 16. ... 16.  6.  0.]\n",
      "  [ 0.  8. 16. ... 16.  8.  0.]\n",
      "  [ 0.  1.  8. ... 12.  1.  0.]]]\n",
      "digits.images.shape: (1797, 8, 8) \tdigits.data.shape (1797, 64)\n",
      "digits.images: <class 'numpy.ndarray'> \tdigits.data: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 왜인지 data와 겹치게, images 데이터가 또 있습니다. 자세히 보니 data는 images의 $8 \\times 8$ 크기의 자료를 계산에 다루기 쉽게, $1 \\times 64$ 의 행렬로 펴준 상태인 것으로 보여요. 이미지 자료 출력으로는 images, 머신러닝 모델 학습에는 data를 활용하도록 하겠습니다.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "plt.figure(figsize= (14,7))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(digits.images[i],cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show() "
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x504 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 앞에서 digits.data를 reshape해서 출력한 이미지와 완전히 일치하네요. 앞에서 한 가정이 올바름을 알 수 있습니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# 3. 데이터 구분\n",
    "\n",
    "### 이제 digits의 데이터를 머신러닝 모델 학습에 사용할 수 있도록 가공하겠다. 다만 제공되는 digits.data에서 이미 $ 8 \\times 8$ 데이터를 한줄로 펴주었으니, 그대로 활용하도록 하겠다.\n",
    "### 현재 1797개의 손글씨가 digits.data에 $64 \\times 1$ 형태로 들어있고, 그 수의 숫자가 digits.target에 들어있다. 그러므로 이 두 정보를 학습시키는데에, 또 성능을 검사하는데에도 사용할 수 있다. 하지만, 학습한 데이터로 성능을 검사한다면, 답지를 주고 시험을 보는 것과 다를 것이 없기때문에, 인공지능의 성능을 올바로 평가할 수 없다. 따라서 이 두 데이터를 각각 다시 둘로 나눠 생각하도록 하겠다. digits.data를 x_train, x_test, digits.target을 y_train, y_test로 나누도록 하겠다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(digits.data,\n",
    "                            digits.target,\n",
    "                            test_size=0.2,\n",
    "                            random_state=21) \n",
    "\n",
    "# random_state를 보면 알 수 있듯이, train_test_split함수가 데이터를 무작위하게 나누어 준다."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. 머신러닝 학습 및 평가\n",
    "\n",
    "기다렸던 대망의 머신러닝 모델입니다. 가장 중요한 부분이라고 할 수 있죠. 본 글에서 제가 다뤄볼 모델은 5가지 입니다.\n",
    " 1. ### Decision Tree Classifier      \n",
    " 2. ### Random Forest Classifier     \n",
    " 3. ### Support Vector Mechine Classifier    \n",
    " 4. ### Stochastic Gradient Descent Classifier    \n",
    " 5. ### Logistic Regression Classifier     "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(digits.data,\n",
    "                            digits.target,\n",
    "                            test_size=0.2,\n",
    "                            random_state=21) \n",
    "```\n",
    "### 위와같이 훈련 및 실험 자료를 준비했었습니다.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "model_tree = DecisionTreeClassifier()\n",
    "model_forest = RandomForestClassifier()\n",
    "model_svc = SVC()\n",
    "model_sgdc = SGDClassifier()\n",
    "model_logistic = LogisticRegression()\n",
    "\n",
    "\n",
    "model_tree.fit(x_train,y_train)\n",
    "model_forest.fit(x_train,y_train)\n",
    "model_svc.fit(x_train,y_train)\n",
    "model_sgdc.fit(x_train,y_train)\n",
    "model_logistic.fit(x_train,y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/hchang/Working/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### scikit learn이 제공하는 간단한 식으로 모델을 정의 및 학습시켰습니다. 이제 그 성능을 확인해보겠습니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "y_pred1=model_tree.predict(x_test)\n",
    "y_pred2=model_forest.predict(x_test)\n",
    "y_pred3=model_svc.predict(x_test)\n",
    "y_pred4=model_sgdc.predict(x_test)\n",
    "y_pred5=model_logistic.predict(x_test)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 위와같이 예상 데이터를 만들어서 미리 준비한 y_test와 비교하여 정확도를 비교하겠습니다. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# print(accuracy_score(y_test,y_pred1))\n",
    "# print(accuracy_score(y_test,y_pred2))\n",
    "# print(accuracy_score(y_test,y_pred3))\n",
    "# print(accuracy_score(y_test,y_pred4))\n",
    "# print(accuracy_score(y_test,y_pred5))  이와같이 확인 가능하지만, 보기 좋게 정리해서 출력해보겠습니다."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import re\n",
    "y_predset=[(\"DecisionTreeClassifier\",y_pred1),(\"RandomForestClassifier\",y_pred2),(\"SVC\",y_pred3),(\"SGDClassifier\",y_pred4),(\"LogisticRegression\",y_pred5)]\n",
    "for i,j in y_predset:\n",
    "    print(i+\"의 accuracy는\", \" \"*(25-len(i)-len(re.findall('[가-힣]',i))) ,format(accuracy_score(y_test,j),\".5f\"), \"입니다.\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DecisionTreeClassifier의 accuracy는     0.83333 입니다.\n",
      "RandomForestClassifier의 accuracy는     0.97500 입니다.\n",
      "SVC의 accuracy는                        0.98611 입니다.\n",
      "SGDClassifier의 accuracy는              0.95278 입니다.\n",
      "LogisticRegression의 accuracy는         0.97778 입니다.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 결과는 위와 같군요. 그렇다면, SVC 즉 support vectormachine이 손글씨를 분류하기 가장 적합한 모델일까요?\n",
    "### 반드시 그렇다고 할 수는 없습니다. 아래를 같이 확인해봅시다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "for i,j in y_predset:\n",
    "    print(\"#\",i+\"의 Confusion Matrix\")\n",
    "    print(confusion_matrix(y_test, j))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# DecisionTreeClassifier의 Confusion Matrix\n",
      "[[30  0  0  0  0  0  0  1  1  0]\n",
      " [ 0 24  1  1  2  2  0  0  4  2]\n",
      " [ 0  1 20  4  0  1  1  0  3  0]\n",
      " [ 0  0  0 35  0  1  0  0  3  2]\n",
      " [ 0  0  0  0 25  0  1  1  3  2]\n",
      " [ 1  0  0  0  0 43  1  0  1  0]\n",
      " [ 0  0  0  1  2  1 28  0  0  0]\n",
      " [ 0  0  1  0  0  0  0 37  0  2]\n",
      " [ 0  1  1  1  0  0  0  0 36  3]\n",
      " [ 1  0  0  2  2  1  0  0  1 22]]\n",
      "# RandomForestClassifier의 Confusion Matrix\n",
      "[[30  0  0  0  2  0  0  0  0  0]\n",
      " [ 0 36  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 30  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 41  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 30  0  0  1  0  1]\n",
      " [ 0  0  0  0  0 46  0  0  0  0]\n",
      " [ 1  0  0  0  0  0 31  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 40  0  0]\n",
      " [ 0  1  0  0  0  0  0  1 40  0]\n",
      " [ 0  0  0  0  0  1  0  0  1 27]]\n",
      "# SVC의 Confusion Matrix\n",
      "[[31  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 36  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 30  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 41  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 32  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 46  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 32  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 40  0  0]\n",
      " [ 0  2  0  0  0  0  0  0 40  0]\n",
      " [ 0  0  0  0  0  1  0  0  1 27]]\n",
      "# SGDClassifier의 Confusion Matrix\n",
      "[[32  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 33  0  1  0  0  0  0  0  2]\n",
      " [ 0  0 30  0  0  0  0  0  0  0]\n",
      " [ 0  1  0 36  0  1  0  0  3  0]\n",
      " [ 0  0  0  0 32  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 45  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 32  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 38  0  2]\n",
      " [ 0  3  0  0  0  0  1  1 37  0]\n",
      " [ 0  0  0  0  0  1  0  0  0 28]]\n",
      "# LogisticRegression의 Confusion Matrix\n",
      "[[32  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 35  0  1  0  0  0  0  0  0]\n",
      " [ 0  0 30  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 41  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 31  0  0  1  0  0]\n",
      " [ 0  0  0  0  1 45  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 32  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 39  0  1]\n",
      " [ 0  1  0  0  1  0  0  0 40  0]\n",
      " [ 0  1  0  0  0  1  0  0  0 27]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "for i,j in y_predset:\n",
    "    print(\"--------\",i+\"의 Classification Report\",\"---------\")\n",
    "    print(classification_report(y_test, j))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-------- DecisionTreeClassifier의 Classification Report ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        32\n",
      "           1       0.92      0.67      0.77        36\n",
      "           2       0.87      0.67      0.75        30\n",
      "           3       0.80      0.85      0.82        41\n",
      "           4       0.81      0.78      0.79        32\n",
      "           5       0.88      0.93      0.91        46\n",
      "           6       0.90      0.88      0.89        32\n",
      "           7       0.95      0.93      0.94        40\n",
      "           8       0.69      0.86      0.77        42\n",
      "           9       0.67      0.76      0.71        29\n",
      "\n",
      "    accuracy                           0.83       360\n",
      "   macro avg       0.84      0.83      0.83       360\n",
      "weighted avg       0.84      0.83      0.83       360\n",
      "\n",
      "-------- RandomForestClassifier의 Classification Report ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        32\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       1.00      1.00      1.00        41\n",
      "           4       0.94      0.94      0.94        32\n",
      "           5       0.98      1.00      0.99        46\n",
      "           6       1.00      0.97      0.98        32\n",
      "           7       0.95      1.00      0.98        40\n",
      "           8       0.98      0.95      0.96        42\n",
      "           9       0.96      0.93      0.95        29\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.98      0.97      0.97       360\n",
      "\n",
      "-------- SVC의 Classification Report ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        32\n",
      "           1       0.95      1.00      0.97        36\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       1.00      1.00      1.00        41\n",
      "           4       0.97      1.00      0.98        32\n",
      "           5       0.98      1.00      0.99        46\n",
      "           6       1.00      1.00      1.00        32\n",
      "           7       1.00      1.00      1.00        40\n",
      "           8       0.98      0.95      0.96        42\n",
      "           9       1.00      0.93      0.96        29\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "-------- SGDClassifier의 Classification Report ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.89      0.92      0.90        36\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       0.97      0.88      0.92        41\n",
      "           4       1.00      1.00      1.00        32\n",
      "           5       0.96      0.98      0.97        46\n",
      "           6       0.97      1.00      0.98        32\n",
      "           7       0.97      0.95      0.96        40\n",
      "           8       0.93      0.88      0.90        42\n",
      "           9       0.85      0.97      0.90        29\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.96      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n",
      "-------- LogisticRegression의 Classification Report ---------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.95      0.97      0.96        36\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       0.98      1.00      0.99        41\n",
      "           4       0.94      0.97      0.95        32\n",
      "           5       0.98      0.98      0.98        46\n",
      "           6       1.00      1.00      1.00        32\n",
      "           7       0.97      0.97      0.97        40\n",
      "           8       1.00      0.95      0.98        42\n",
      "           9       0.96      0.93      0.95        29\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. 정확도 분석을 통한 좋은 모델 선택"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Wine\n",
    "\n",
    "[\\[목차\\]](#making-datas-classifier)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Breast cancer\n",
    "\n",
    "[\\[목차\\]](#making-datas-classifier)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('Working': venv)"
  },
  "interpreter": {
   "hash": "2e073fd8b018c378d21515a579cd74fd900bc137dc30cf56adc43f33b9b98e44"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}