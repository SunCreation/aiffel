{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "To make AI writer\n",
    "=\n",
    "> ## 목차\n",
    "> ---\n",
    "> ### 1. 실행 방법   \n",
    "> ### 2. 목표 및 의의   \n",
    "> ### 3. 이론 [go](#3-이론)\n",
    ">   > 1 RNN과 LSTM\n",
    ">   > 2 \n",
    "> ### 4. 코드 분석 [go](#4-코드-분석)\n",
    ">   > [1 데이터 준비 및 정제](#1-데이터-준비-및-정제)    \n",
    ">   > [2 모델 설계](#2-모델-설계)   \n",
    ">   > [3 학습!](#3-학습)   \n",
    ">   > [4 모델 평가](#4-모델-평가)   \n",
    "> ### 5. 아쉬운 점 [go](#5-아쉬운-점)\n",
    "\n",
    "---\n",
    "# 1. 실행 방법\n",
    "  1. 왠만한 그래픽카드로도 학습시간이 한,두시간 걸리는 것 같으니, 해보길 크게 권하지 않습니다. 그래도 꼭 하고싶으면 해보세요!\n",
    "  2. aiffel repository를 다운받습니다. ``` git clone https://github.com/SunCreation/aiffel.git```\n",
    "  3. writer.py를 실행해줍니다. ```python3 {aiffel까지 경로}/aiffel/Working/AI/writer/writer.py``` {aiffel까지 경로} 추가 입력, 학습이 시작됩니다.(라이브러리 tensorflow, matplotlib, sklearn 가 필요합니다.)\n",
    "  4. 학습결과는 아래내용 그 이상이 없으므로, 굳이 해보실 필요 없습니다.\n",
    "  \n",
    "---\n",
    "# 2. 목표 및 의의\n",
    "  - 그럴 듯한 글을 쓰는 인공지능을 만든다.\n",
    "  - 원하는 바를 해본다: 인공지능이 만들어주는 글의 길이 조절, 학습데이터 정제.\n",
    "  - LSTM에 대하여 이해해본다.\n",
    "  - mini_batch를 활용하는 방법을 익힌다.\n",
    "  - 적절한 hidden_size, embedding_size를 정할 방법을 생각해본다.\n",
    "  - validation loss 값이 의미하는 바를 안다.\n",
    "\n",
    "---\n",
    "# 3. 이론\n",
    "[목차](#to-make-ai-writer)\n",
    "## 1) RNN과 LSTM\n",
    "---\n",
    "#### RNN(Recurrent Neural Networks)은 인공 신경망 학습모델의 일종으로, hidden_node가 방향을 가지고 연결돼 순환구조를 이루는(directed cycle) 형태를 가지고 있습니다. 이 역시 실제 뇌의 신경에서 본따온 학습형태라고 합니다.\n",
    "\n",
    "![이미지](https://i.imgur.com/Q8zv6TQ.png)\n",
    "\n",
    "#### 위의 그림에서도 알 수 있듯 시퀀스 길이에 관계없이 인풋과 아웃풋을 받아들일 수 있는 네트워크 구조이기 때문에 필요에 따라 다양하고 유연하게 구조를 만들 수 있다는 점이 RNN의 가장 큰 장점입니다.\n",
    "#### 하지만 vanishing gradient problem라고 하는 문제가 존재합니다. 바로 학습데이터와 연관된 타겟데이터가 멀리있을 때, 학습률이 떨어지는 현상인데, RNN을 사용할 경우에는 이런 일이 많기때문에, 이는 큰 문제중에 하나라고 할 수 있습니다.\n",
    "\n",
    "#### 이어서 LSTM은 다음과 같은데, 바로 vanishing gradient problem을 해결 할 방법이라고 할 수 있겠습니다. 세부 적인 내용은 차차 알아가 보겠습니다!\n",
    "![이미지](https://i.imgur.com/jKodJ1u.png)\n",
    "\n",
    "---\n",
    "# 4. 코드 분석\n",
    "[목차](#to-make-ai-writer)\n",
    "## 1) 데이터 준비 및 정제\n",
    "---\n",
    "#### 이번에는 노래 가사를 쓰는 인공지능을 만들도록 해볼게요. tf.keras.layers.LSTM모델을 사용할겁니다!\n",
    " \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "from sklearn.utils import validation \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.ops.nn_ops import dropout\n",
    "\n",
    "txt_files ='data/lyrics/*'\n",
    "txt_file_path ='data/lyrics' \n",
    "txt_list = glob.glob(txt_files)\n",
    "txt_name_list = os.listdir(txt_file_path)\n",
    "raw_corpus = []\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\",encoding='utf-8') as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "            \n",
    "print(\"노래제목 예시 5개:\\n\", txt_name_list[:5], \"\\n노래 개수:\", len(txt_list))\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", np.array(raw_corpus[:15]))\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "노래제목 예시 5개:\n",
      " ['michael-jackson.txt', 'paul-simon.txt', 'amy-winehouse.txt', 'bob-dylan.txt', 'bruce-springsteen.txt'] \n",
      "노래 개수: 49\n",
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['' '' '[Spoken Intro:]' 'You ever want something '\n",
      " \"that you know you shouldn't have \"\n",
      " \"The more you know you shouldn't have it, \" 'The more you want it '\n",
      " 'And then one day you get it, ' \"It's so good too \"\n",
      " \"But it's just like my girl \" \"When she's around me \"\n",
      " 'I just feel so good, so good '\n",
      " 'But right now I just feel cold, so cold ' 'Right down to my bones '\n",
      " \"'Cause ooh... \"]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## - 데이터 정제하기\n",
    "#### 이제 문장을 기계가 학습할 수 있는 숫자로 바꿔줄 것입니다. 그냥 encoding을 하면 되는게 아닌가 생각할 수 있지만, 저희는 문장들을 그저 기계어로 바꾸고 싶은 것이 아니라, 글자 하나하나가 대응되는 숫자가 있기를 원합니다. 따라서 단어들을 대응되는 숫자를 지정하는 Tokenize를 해봅시다!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    # 정제를 하고 담아주세요\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    if len(preprocessed_sentence.split()) > 15 : continue\n",
    "    corpus.append(preprocessed_sentence)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 먼저 단어들을 잘 정리해봅시다. me 와 me, 등이 하나하나 전부 다르면 곤란하므로 다음과 위와같이 특수문자를 단어들과 분리합니다. 또 학습에 필요한 도구로서 문장의 앞뒤에 \\<start>, \\<end>를 넣어줍니다. 위 함수를 이용해서 문장을 모두 정제하겠습니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def tokenize(corpus):\n",
    "    # 13000단어를 기억할 수 있는 tokenizer를 만들겁니다\n",
    "    # 우리는 이미 문장을 정제했으니 filters가 필요없어요\n",
    "    # 13000단어에 포함되지 못한 단어는 '<unk>'로 바꿀거에요\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=13000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다.\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다.\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다.\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
    "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다.\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)\n",
    "print(tensor[:3, :10])\n",
    "tensor.shape\n",
    "#%%\n",
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break\n",
    "\n",
    "\n",
    "src_input = tensor[:, :-1]  \n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0][:10])\n",
    "print(tgt_input[0][:10])\n",
    "\n",
    "from sklearn.model_selection import train_test_split as ttst\n",
    "enc_train, enc_val, dec_train, dec_val = ttst(src_input,\n",
    "                            tgt_input,\n",
    "                            test_size=0.2,\n",
    "                            random_state=21)\n",
    "\n",
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)\n",
    "\n",
    "#%%\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[   2 2711 2353 ...    0    0    0]\n",
      " [   2    7  161 ...    0    0    0]\n",
      " [   2   15    7 ...    0    0    0]\n",
      " ...\n",
      " [   2   32  133 ...    0    0    0]\n",
      " [   2    4   61 ...    0    0    0]\n",
      " [   2  169    3 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f439ea10690>\n",
      "[[   2 2711 2353    3    0    0    0    0    0    0]\n",
      " [   2    7  161   64  197    3    0    0    0    0]\n",
      " [   2   15    7   34    7 1629   16   74    3    0]]\n",
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : i\n",
      "5 : ,\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n",
      "[   2 2711 2353    3    0    0    0    0    0    0]\n",
      "[2711 2353    3    0    0    0    0    0    0    0]\n",
      "Source Train: (124810, 14)\n",
      "Target Train: (124810, 14)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 이제 잘 학습되고 있는지, 확인할 목적으로 validation set을 나눠주겠습니다.(sklearn사용)\n",
    "\n",
    "#### 원하는 모습으로 잘 나온 것 같아요!\n",
    "#### 다음을 ft.data.Dataset 을 사용하여, 데이터를 학습하기 좋게 조정해볼게요.\n",
    "dataset메소드에 관한 정보들   \n",
    "[here](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)   \n",
    "tf.data.Dataset에는 알아주면 편리한 기능이 아주 많다고 해요.   \n",
    "저는 tf.data.Dataset을 사용하여 입력데이터를 하나로 묶고, mini-batch로 나누어주었습니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "BUFFER_SIZE = len(enc_train)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
    "val_BUFFER_SIZE = len(enc_val)\n",
    " # tokenizer가 구축한 단어사전 내 13000개와, 여기 포함되지 않은 0:<pad>를 포함하여 13001개\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset\n",
    "val_dataset = val_dataset.shuffle(val_BUFFER_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "val_dataset\n",
    "#%%\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[목차](#to-make-ai-writer)\n",
    "## 2) 모델 설계\n",
    "---\n",
    "#### 이제 준비가 많이 되었군요. 학습을 할 모델을 만들어보겠습니다!\n",
    "#### 오늘 인공지능이 해줬으면 좋겠는 일은 언어에 대한 학습입니다. 우리의 모델은 특정 단어를 특정 숫자로 인지할 수 밖에 없습니다. 이를 위해 단어들을 숫자와 해주는 작업을 이미 마쳤습니다. 이제 모델은 그 숫자에 특정 수치들을 매겨, 기억할 것입니다. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 1400\n",
    "hidden_size = 2048\n",
    "mywriter = TextGenerator(VOCAB_SIZE, embedding_size , hidden_size)\n",
    "\n",
    "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
    "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
    "print(mywriter(src_sample))\n",
    "# #%%\n",
    "# print(mywriter)\n",
    "# test 14\n",
    "mywriter.summary()\n",
    "#%%\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[[ 2.27168814e-04  2.24591829e-04  2.59923196e-04 ... -2.62834335e-04\n",
      "    5.55005936e-05  2.94099329e-04]\n",
      "  [ 1.67691323e-05  4.36665519e-04 -9.40987156e-05 ... -1.20378761e-04\n",
      "    2.13345105e-04  1.02851016e-03]\n",
      "  [-5.39508124e-04 -2.76321953e-05 -3.10240226e-04 ...  4.89324273e-04\n",
      "    2.73176178e-04  1.10375811e-03]\n",
      "  ...\n",
      "  [-2.59967474e-03 -1.13959331e-03 -2.47546658e-03 ...  4.09871852e-03\n",
      "    5.57829626e-04  1.54354231e-04]\n",
      "  [-1.81715901e-03 -1.15971512e-03 -2.46666581e-03 ...  3.41451401e-03\n",
      "    1.06869510e-03 -7.39549403e-04]\n",
      "  [-1.01525581e-03 -1.31073152e-03 -2.49895523e-03 ...  2.53617228e-03\n",
      "    1.73966668e-03 -1.59957365e-03]]\n",
      "\n",
      " [[ 2.27168814e-04  2.24591829e-04  2.59923196e-04 ... -2.62834335e-04\n",
      "    5.55005936e-05  2.94099329e-04]\n",
      "  [ 2.21413371e-04  3.57676210e-04  9.02355023e-05 ... -4.31843160e-04\n",
      "    1.97494992e-05  5.68016025e-04]\n",
      "  [ 3.17645347e-04  3.48460802e-04 -2.67675263e-04 ...  4.96235443e-04\n",
      "   -2.43743663e-04  5.88113558e-04]\n",
      "  ...\n",
      "  [-1.23653983e-04  1.94832828e-04 -1.65538234e-03 ...  1.25562679e-03\n",
      "    1.23455015e-03 -3.73038609e-04]\n",
      "  [ 2.20371767e-05  2.41258880e-04 -1.61551137e-03 ...  1.08292908e-03\n",
      "    1.59621448e-03 -1.08626473e-03]\n",
      "  [ 3.49284470e-04  1.32968242e-04 -1.66403386e-03 ...  7.17186194e-04\n",
      "    2.21002242e-03 -1.81173766e-03]]\n",
      "\n",
      " [[ 2.27168814e-04  2.24591829e-04  2.59923196e-04 ... -2.62834335e-04\n",
      "    5.55005936e-05  2.94099329e-04]\n",
      "  [ 7.02755002e-04  2.14155716e-05  3.09820200e-04 ...  1.70267143e-04\n",
      "    4.21447003e-05  7.15842936e-04]\n",
      "  [ 1.01841544e-03 -6.38675177e-04 -7.40495103e-04 ...  8.64828471e-04\n",
      "    3.36351484e-04  8.21486232e-04]\n",
      "  ...\n",
      "  [ 1.81582430e-03 -1.78471836e-03 -3.51966056e-03 ... -3.43242707e-03\n",
      "    3.19265528e-03 -1.73032633e-03]\n",
      "  [ 2.06361827e-03 -2.15701386e-03 -3.52638680e-03 ... -4.09755018e-03\n",
      "    4.04893374e-03 -2.22919579e-03]\n",
      "  [ 2.25428934e-03 -2.53567053e-03 -3.54536041e-03 ... -4.73379716e-03\n",
      "    4.80852462e-03 -2.61768093e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 2.27168814e-04  2.24591829e-04  2.59923196e-04 ... -2.62834335e-04\n",
      "    5.55005936e-05  2.94099329e-04]\n",
      "  [ 7.02755002e-04  2.14155716e-05  3.09820200e-04 ...  1.70267143e-04\n",
      "    4.21447003e-05  7.15842936e-04]\n",
      "  [ 7.57714093e-04 -1.51971210e-04  1.26484883e-04 ...  9.96158196e-05\n",
      "   -5.04924217e-04  1.34418253e-03]\n",
      "  ...\n",
      "  [-1.00928405e-03 -4.93955158e-04  2.60656560e-03 ...  9.56990625e-05\n",
      "    1.84683176e-03 -1.31090361e-04]\n",
      "  [-4.13653412e-04 -3.76179582e-04  2.18185433e-03 ... -4.46772203e-04\n",
      "    2.19343114e-03 -9.46703425e-04]\n",
      "  [ 2.13089297e-04 -4.05554747e-04  1.55414140e-03 ... -1.04804628e-03\n",
      "    2.77254311e-03 -1.80997245e-03]]\n",
      "\n",
      " [[ 2.27168814e-04  2.24591829e-04  2.59923196e-04 ... -2.62834335e-04\n",
      "    5.55005936e-05  2.94099329e-04]\n",
      "  [ 7.47621598e-05  4.08708642e-04  6.17397076e-04 ... -7.12933397e-05\n",
      "    1.54083318e-04  3.02439264e-04]\n",
      "  [-6.91619789e-05  5.42778405e-04  8.20612186e-04 ...  2.55365798e-04\n",
      "    1.27095700e-04  5.49957680e-04]\n",
      "  ...\n",
      "  [-1.44501741e-03 -6.23914122e-04  4.68404643e-04 ... -1.78719952e-03\n",
      "    1.65991450e-03 -1.21465989e-03]\n",
      "  [-6.88763859e-04 -1.10474974e-03  4.48638566e-05 ... -2.22621392e-03\n",
      "    2.21929885e-03 -1.66741782e-03]\n",
      "  [ 5.57792100e-06 -1.61138549e-03 -4.03916318e-04 ... -2.74156127e-03\n",
      "    2.83917831e-03 -2.10599555e-03]]\n",
      "\n",
      " [[ 2.27168814e-04  2.24591829e-04  2.59923196e-04 ... -2.62834335e-04\n",
      "    5.55005936e-05  2.94099329e-04]\n",
      "  [ 2.77654442e-04  3.64268752e-04  4.55362140e-04 ... -1.07025655e-04\n",
      "    2.91682682e-05  7.12734356e-04]\n",
      "  [ 3.48982780e-04  2.93771212e-04  2.72603706e-04 ...  3.49485141e-04\n",
      "   -2.64475297e-04  1.91093469e-03]\n",
      "  ...\n",
      "  [ 2.20818818e-03 -1.79425883e-03  3.11724398e-05 ... -3.42420390e-04\n",
      "   -1.38028595e-03 -9.18405131e-04]\n",
      "  [ 2.50271452e-03 -2.11412716e-03 -3.14035831e-04 ... -1.15295628e-03\n",
      "   -3.31477146e-04 -1.66111498e-03]\n",
      "  [ 2.75333039e-03 -2.44390103e-03 -6.86324725e-04 ... -1.98765448e-03\n",
      "    7.21223885e-04 -2.27199332e-03]]], shape=(256, 14, 13001), dtype=float32)\n",
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  18201400  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  28254208  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  33562624  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  26639049  \n",
      "=================================================================\n",
      "Total params: 106,657,281\n",
      "Trainable params: 106,657,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[목차](#to-make-ai-writer)\n",
    "## 3) 학습!\n",
    "---\n",
    "#### 이제 학습을 하며 확인할 값들을 정의해주고, 학습을 시작하겠습니다!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "mywriter.compile(loss=loss, optimizer=optimizer)\n",
    "lyricist = mywriter.fit(dataset, \n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=8)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/8\n",
      "487/487 [==============================] - 562s 1s/step - loss: 3.6775 - val_loss: 2.8327\n",
      "Epoch 2/8\n",
      "487/487 [==============================] - 560s 1s/step - loss: 2.7021 - val_loss: 2.5728\n",
      "Epoch 3/8\n",
      "487/487 [==============================] - 559s 1s/step - loss: 2.3301 - val_loss: 2.3941\n",
      "Epoch 4/8\n",
      "487/487 [==============================] - 558s 1s/step - loss: 1.9753 - val_loss: 2.2670\n",
      "Epoch 5/8\n",
      "487/487 [==============================] - 569s 1s/step - loss: 1.6534 - val_loss: 2.1845\n",
      "Epoch 6/8\n",
      "487/487 [==============================] - 559s 1s/step - loss: 1.3878 - val_loss: 2.1396\n",
      "Epoch 7/8\n",
      "487/487 [==============================] - 564s 1s/step - loss: 1.1943 - val_loss: 2.1333\n",
      "Epoch 8/8\n",
      "487/487 [==============================] - 558s 1s/step - loss: 1.0678 - val_loss: 2.1498\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1,(10,10))\n",
    "plt.plot(range(1,9),lyricist.history['loss'])\n",
    "plt.plot(range(1,9),lyricist.history['val_loss'])\n",
    "plt.hlines(2.2, 4, 8, colors='g')\n",
    "plt.ylim(0.5,3.8)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('loss & val_loss of test14')\n",
    "plt.legend([\"loss\",\"val_loss\",\"2.2line\"],loc='upper right')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAJcCAYAAACxEXM4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABYRklEQVR4nO3dd3xUZd7+8eubQhIICb2X0HsLoRcRFwsqVkRAXNQVG2Bft6/rz9VnXXtFVEBRsbsWVGwgxUboHemEltAJkH7//pgRYggQIJMzk3zer9e8nJw5c+bK7PPolfucc9/mnBMAAABKVpjXAQAAAMoiShgAAIAHKGEAAAAeoIQBAAB4gBIGAADgAUoYAACAByhhAAAAHqCEAWWEmW0ws995nSMQzGyGmf3hJPuMNLPZJZXpRMyshZktNLMDZjbW6zwAvEEJAxAQZnauma30F41FZtbJ60xB5I+SpjvnKjrnni74YlFKZVGYWT8zSymwra2ZTTOznWZ23Nm6zayZmWWY2etnmgNA4ShhAALlVUmPSYqTNEzSHm/jBJWGkpZ59NnZkt6RdMNJ9ntO0tzAxwHKLkoYUAaZWZSZPWlmW/2PJ80syv9aNTP71Mz2mtluM5tlZmH+1+4zsy3+0a1VZnbOCT4mW9IG57PMObfhJHn2mlnbfNuqm9lhM6thZpX9mdLMbI//eb0z/A56mtlcM9vn/2fPfK+NNLN1/t9zvZkN929vambf+d+z08zePsHxB5nZMv/vNcPMWvm3fyvpbEnPmlm6mTUv8L5/S+qT7/Vn/dtbmtlX/v9NVpnZVfneM9DMlvvzbjGze8ysgqTPJdXxHyfdzOo451Y5517RCUqgmV0taa+kb071ewVQdJQwoGz6q6TukjpK6iCpq6S/+V+7W1KKpOqSakr6iyRnZi0kjZbUxTlXUdJ5kjYUdnAzM0k/S3rZzBJOFsY5lynpA0lD822+StJ3zrlU+f5dNVG+EaQGkg5Leraov2wh+apImirpaUlVJT0uaaqZVfWXl6clXeD/PXtKWuh/6/+T9KWkypLqSXrmOMdvLmmKpDvk+x4/k/SJmZVzzvWXNEvSaOdcrHNudYHv4q8FXh/tz/SVpDcl1ZB0taTnzay1/22vSLrJn7etpG+dcwclXSBpq/84sc65rUX4buIkPSDprpPtC+DMUMKAsmm4pAecc6nOuTRJ/5I0wv9atqTakho657Kdc7Occ05SrqQoSa3NLNI5t8E5t/Y4x79PUnn5Ctw3vxYxM/uDmb1/nPe8KV+5+NUw/zY553Y55953zh1yzh2Q9G9JZ53ery5JulDSL865yc65HOfcFEkrJV3sfz1PUlszi3HObXPO/TpqlC1fEazjnMtwzh3vQv8hkqY6575yzmVLelRSjHyF7nRcJN+o4kR/3gWS3pc0OF+u1mYW55zb45ybf5qfI/mK5ivOuZST7gngjFDCgLKpjqSN+X7e6N8mSf+VtEbSl/5Tcn+SJOfcGvlGdu6XlGpmb5lZHRXudkn/zzn3hv940/1FrJekb4/znumSyptZN/++HSV9KElmVt7MXjSzjWa2X9JMSZXMLPxUf3G/gr+//D/X9Y8gDZF0s6RtZjbVzFr69/mjJJP0s/9U4/VFOb5zLk/SZkl1TzNvQ0nd/Kc295rZXvmKdC3/61dIGihpo/90aY/T+RAz6yjpd5KeOM2cAE4BJQwom7bK9x/2XzXwb5Nz7oBz7m7nXGNJgyTd9eu1X865N51zvf3vdZL+c5zjR0iK9L9nnKSXJM2Q71qo1wp7g3MuV74Lxof6H5/6R70k3ynSFpK6OefiJPX1b7dT+7WPKPj7S77vYIs/yzTn3AD5RgRX+vPLObfdOXejc66OpJvkOyXY9GTH95+erf/r8Yug4F2Lm+U7NVsp3yPWOXeLP9dc59wl8p2q/J9832NhxzmZfpISJG0ys+2S7pF0hZmdycgagOOghAFl0xRJf/Nf/F5N0j8kvS5JZnaR/wJ0k7RPvtOQeeab26q//wL+DPmuy8o7zvHflfRfM2tsZhHyXR9WRVKmpBONXr0p3yjUcP/zX1X0f95e//Vc/zyt3/qozyQ1N7NhZhZhZkMktZb0qZnVNLNL/NdhZUpKl//3NLPB+W4I2CNfySnsO3hH0oVmdo6ZRcpXIjMlfV/EfDskNc7386f+vCPMLNL/6GJmrcysnJkNN7N4/6nP/fky7ZBU1czifz2Q+URLKuf/Odr/v6kkjZfURL5RyI6Sxsl37dx5RcwN4BRQwoCy6UFJyZIWS1oiab5/myQ1k/S1fOXjB0nPO+emy3c92P9J2ilpu3yjLn8+zvHvlu/i8pny3WV3v6TLJC2S9IG/mBzDOfeTpIPync77PN9LT8p3TdVOST9K+uKUfttjP2eXfNdZ3S1pl3ynGS9yzu2U79+Ld8k3mrVbvmvPbvG/tYukn8wsXdLHkm53zq0r5PirJF0j34X7O+W71uxi51xWESM+JelK890J+rR/RPBc+a6Z2yrf9/8f+f43kXzX823wn6q9Wb4SK+fcSvkK9zr/acw68o3QHdbRuyMPS1rl3/+Qf7Rvu3Nuu3z/N5Dhv24QQDEz3/W2AAAAKEmMhAEAAHiAEgag1DCzcfkmJs3/GOd1NgAoiNORAAAAHojwOsCpqlatmktISPA6BgAAwEnNmzdvp3OuemGvhVwJS0hIUHJystcxAAAATsrMCk4MfQTXhAEAAHiAEgYAAOABShgAAIAHQu6aMAAAUHKys7OVkpKijIwMr6MEtejoaNWrV0+RkYUuCFIoShgAADiulJQUVaxYUQkJCfItKYuCnHPatWuXUlJS1KhRoyK/j9ORAADguDIyMlS1alUK2AmYmapWrXrKo4WUMAAAcEIUsJM7ne+IEgYAAOABShgAAAhqsbGxXkcICEoYAACAByhhAAAgJDjndO+996pt27Zq166d3n77bUnStm3b1LdvX3Xs2FFt27bVrFmzlJubq5EjRx7Z94knnvA4/bGYogIAABTJvz5ZpuVb9xfrMVvXidM/L25TpH0/+OADLVy4UIsWLdLOnTvVpUsX9e3bV2+++abOO+88/fWvf1Vubq4OHTqkhQsXasuWLVq6dKkkae/evcWauzgwEgYAAELC7NmzNXToUIWHh6tmzZo666yzNHfuXHXp0kUTJ07U/fffryVLlqhixYpq3Lix1q1bpzFjxuiLL75QXFyc1/GPwUgYAAAokqKOWJW0vn37aubMmZo6dapGjhypu+66S9dee60WLVqkadOmady4cXrnnXc0YcIEr6P+BiNhAAAgJPTp00dvv/22cnNzlZaWppkzZ6pr167auHGjatasqRtvvFF/+MMfNH/+fO3cuVN5eXm64oor9OCDD2r+/Plexz8GI2EAACAkXHbZZfrhhx/UoUMHmZkeeeQR1apVS6+++qr++9//KjIyUrGxsXrttde0ZcsWXXfddcrLy5MkPfzwwx6nP5Y557zOcEqSkpJccnKy1zEAACgTVqxYoVatWnkdIyQU9l2Z2TznXFJh+3M6EgAAwAOUMAAAAA9QwgAAADxACQMAAPAAJQwAAMADlDAAAAAPUMIAAAA8QAkDAAClRmxs7HFf27Bhg9q2bVuCaU6MEgYAAOABli0CAABF8/mfpO1LiveYtdpJF/zfcV/+05/+pPr16+u2226TJN1///2KiIjQ9OnTtWfPHmVnZ+vBBx/UJZdcckofm5GRoVtuuUXJycmKiIjQ448/rrPPPlvLli3Tddddp6ysLOXl5en9999XnTp1dNVVVyklJUW5ubn6+9//riFDhpzRry1RwgAAQBAbMmSI7rjjjiMl7J133tG0adM0duxYxcXFaefOnerevbsGDRokMyvycZ977jmZmZYsWaKVK1fq3HPP1erVqzVu3DjdfvvtGj58uLKyspSbm6vPPvtMderU0dSpUyVJ+/btK5bfjRIGAACK5gQjVoHSqVMnpaamauvWrUpLS1PlypVVq1Yt3XnnnZo5c6bCwsK0ZcsW7dixQ7Vq1SrycWfPnq0xY8ZIklq2bKmGDRtq9erV6tGjh/79738rJSVFl19+uZo1a6Z27drp7rvv1n333aeLLrpIffr0KZbfjWvCAABAUBs8eLDee+89vf322xoyZIjeeOMNpaWlad68eVq4cKFq1qypjIyMYvmsYcOG6eOPP1ZMTIwGDhyob7/9Vs2bN9f8+fPVrl07/e1vf9MDDzxQLJ/FSBgAAAhqQ4YM0Y033qidO3fqu+++0zvvvKMaNWooMjJS06dP18aNG0/5mH369NEbb7yh/v37a/Xq1dq0aZNatGihdevWqXHjxho7dqw2bdqkxYsXq2XLlqpSpYquueYaVapUSS+//HKx/F6UMAAAENTatGmjAwcOqG7duqpdu7aGDx+uiy++WO3atVNSUpJatmx5yse89dZbdcstt6hdu3aKiIjQpEmTFBUVpXfeeUeTJ09WZGSkatWqpb/85S+aO3eu7r33XoWFhSkyMlIvvPBCsfxe5pwrlgOVlKSkJJecnOx1DAAAyoQVK1aoVatWXscICYV9V2Y2zzmXVNj+XBMGAADgAU5HAgCAUmXJkiUaMWLEb7ZFRUXpp59+8ihR4ShhAACgVGnXrp0WLlzodYyT4nQkAACAByhhAAAAHqCEAQAAeIASBgAAgtrmzZt19tlnq3Xr1mrTpo2eeuqpY/Z544031L59e7Vr1049e/bUokWLjrwWGxsrSdq6dauuvPLKEst9MlyYDwAAglpERIQee+wxJSYm6sCBA+rcubMGDBig1q1bH9mnUaNG+u6771S5cmV9/vnnGjVq1DF3Q9apU0fvvfdeScc/LkbCAABAUKtdu7YSExMlSRUrVlSrVq20ZcuW3+zTs2dPVa5cWZLUvXt3paSkHHOcDRs2qG3btpKkSZMm6fLLL9f555+vZs2a6Y9//OOR/b788kv16NFDiYmJGjx4sNLT0wPyezESBgAAiqzfpH7FerwZI2ec0v4bNmzQggUL1K1bt+Pu88orr+iCCy446bEWLlyoBQsWKCoqSi1atNCYMWMUExOjBx98UF9//bUqVKig//znP3r88cf1j3/845RyFgUlDAAAhIT09HRdccUVevLJJxUXF1foPtOnT9crr7yi2bNnn/R455xzjuLj4yVJrVu31saNG7V3714tX75cvXr1kiRlZWWpR48exfdL5EMJAwAARXaqI1fFJTs7W1dccYWGDx+uyy+/vNB9Fi9erD/84Q/6/PPPVbVq1ZMeMyoq6sjz8PBw5eTkyDmnAQMGaMqUKcWW/XgCdk2YmUWb2c9mtsjMlpnZvwrZZ6SZpZnZQv/jD4HKAwAAQpNzTjfccINatWqlu+66q9B9Nm3apMsvv1yTJ09W8+bNT/uzunfvrjlz5mjNmjWSpIMHD2r16tWnfbwTCeRIWKak/s65dDOLlDTbzD53zv1YYL+3nXOjA5gDAACEsDlz5mjy5Mlq166dOnbsKEl66KGHtGnTJknSzTffrAceeEC7du3SrbfeKsl3R2VycvIpf1b16tU1adIkDR06VJmZmZKkBx988IyK3fGYc67YD3rMh5iVlzRb0i3OuZ/ybR8pKelUSlhSUpI7nS8VAACcuhUrVqhVq1ZexwgJhX1XZjbPOZdU2P4BnaLCzMLNbKGkVElf5S9g+VxhZovN7D0zq3+c44wys2QzS05LSwtkZAAAgBIR0BLmnMt1znWUVE9SVzNrW2CXTyQlOOfaS/pK0qvHOc5451yScy6pevXqgYwMAABQIkpkslbn3F5J0yWdX2D7Ludcpv/HlyV1Lok8AACg6Eri0qVQdzrfUSDvjqxuZpX8z2MkDZC0ssA+tfP9OEjSikDlAQAApy46Olq7du2iiJ2Ac067du1SdHT0Kb0vkHdH1pb0qpmFy1f23nHOfWpmD0hKds59LGmsmQ2SlCNpt6SRAcwDAABOUb169ZSSkiKuyT6x6Oho1atX75TeUyJ3RxYn7o4EAAChwrO7IwEAAFA4ShgAAIAHKGEAAAAeoIQBAAB4gBIGAADgAUoYAACAByhhAAAAHqCEAQAAeIASBgAA4AFKGAAAgAcoYQAAAB6ghAEAAHiAEgYAAOABShgAAIAHKGEAAAAeoIQBAAB4gBIGAADgAUoYAACAByhhAAAAHqCEAQAAeIASBgAA4AFKGAAAgAcoYQAAAB6ghAEAAHiAEgYAAOABShgAAIAHKGEAAAAeoIQBAAB4gBIGAADgAUoYAACAByhhAAAAHqCEAQAAeIASBgAA4AFKGAAAgAcoYQAAAB6ghAEAAHiAEgYAAOABShgAAIAHKGEAAAAeoIQBAAB4gBIGAADgAUoYAACAByhhAAAAHqCEFZCdm6cXZqzV4axcr6MAAIBSjBJWwMLNe/XItJW6971Fcs55HQcAAJRSlLACuiRU0b3ntdCni7dp3HfrvI4DAABKKUpYIW45q4kual9bj0xbqekrU72OAwAASiFKWCHMTI9c2V6tasVp7FsLtDYt3etIAACglKGEHUf5chEaf21nRYaH6cbXkrU/I9vrSAAAoBShhJ1Avcrl9dywRG3cdUh3vrVQeXlcqA8AAIoHJewkejSpqn9e3FrfrEzV41+t9joOAAAoJSK8DhAKRnRvqGVb9uvZ6WvUqnacLmxf2+tIAAAgxDESVgRmpgcubaPEBpV0z7uLtHzrfq8jAQCAEEcJK6KoiHCNu6az4mIidONrydp9MMvrSAAAIIRRwk5BjbhovTgiSWnpmbrtjfnKzs3zOhIAAAhRlLBT1LF+JT18WTv9sG6X/j11hddxAABAiOLC/NNwRed6WrZ1vybMWa/WdeJ0VVJ9ryMBAIAQw0jYafrLwJbq1bSq/vbhUs3ftMfrOAAAIMRQwk5TRHiYnh2aqJrxUbp58jzt2J/hdSQAABBCKGFnoHKFcnrp2iSlZ+bopsnzlJGd63UkAAAQIihhZ6hlrTg9flUHLdy8V3/731I5x9JGAADg5ChhxeD8trU1tn9TvTcvRZO+3+B1HAAAEAIoYcXkjt811+9a1dSDU1fo+zU7vY4DAACCHCWsmISFmZ4Y0kGNqlXQrW/O1+bdh7yOBAAAghglrBhVjI7US9cmKS/P6cbXknUwM8frSAAAIEhRwopZo2oV9MywRK3ecUD3vreIC/UBAEChKGEBcFbz6rrv/Jb6bMl2PTd9jddxAABAEKKEBciovo11Scc6euyr1fp6+Q6v4wAAgCBDCQsQM9N/rmivNnXidMfbC7Um9YDXkQAAQBChhAVQdGS4XhyRpOjIMN342jztO5ztdSQAABAkKGEBVrdSjJ4f3lmbdx/S2CkLlJvHhfoAAIASViK6Nqqif13SRt+tTtN/p63yOg4AAAgCEV4HKCuGd2uoZVv3a9x3a9WqdkVd0rGu15EAAICHAjYSZmbRZvazmS0ys2Vm9q9C9okys7fNbI2Z/WRmCYHKEwzuv7iNuiRU1n3vL9bSLfu8jgMAADwUyNORmZL6O+c6SOoo6Xwz615gnxsk7XHONZX0hKT/BDCP58pFhOn54Z1VuXw53TR5nnamZ3odCQAAeCRgJcz5pPt/jPQ/Cl6VfomkV/3P35N0jplZoDIFg+oVozR+RJJ2pmfq1jfmKzs3z+tIAADAAwG9MN/Mws1soaRUSV85534qsEtdSZslyTmXI2mfpKqFHGeUmSWbWXJaWlogI5eIdvXi9Z8r2uvn9bv1wCfLvY4DAAA8ENAS5pzLdc51lFRPUlcza3uaxxnvnEtyziVVr169WDN65dJOdTWqb2NN/nGjpvy8yes4AACghJXIFBXOub2Spks6v8BLWyTVlyQzi5AUL2lXSWQKBved31J9mlXTPz5aquQNu72OAwAASlAg746sbmaV/M9jJA2QtLLAbh9L+r3/+ZWSvnXOlZnZTMPDTM8OTVTdSjG6+fX52rbvsNeRAABACQnkSFhtSdPNbLGkufJdE/apmT1gZoP8+7wiqaqZrZF0l6Q/BTBPUIovH6nx1ybpcFaObpo8TxnZuV5HAgAAJcBCbeApKSnJJScnex2j2H25bLtGTZ6nyzrV1eNXdVApv0kUAIAywczmOeeSCnuNZYuCxLltaunO3zXXhwu26JXZ672OAwAAAowSFkTG9G+q89rU1EOfrdCsX0J/Kg4AAHB8lLAgEhZmeuyqjmpWo6JGv7lAG3cd9DoSAAAIEEpYkImNitD4aztLkm58LVnpmTkeJwIAAIFACQtCDatW0HPDErUmNV13v7NQeXmhdfMEAAA4OUpYkOrdrJr+MrCVpi3boae//cXrOAAAoJhRwoLYDb0b6fLEunry6180bdl2r+MAAIBiRAkLYmamhy5rpw714nXX2wu1escBryMBAIBiQgkLctGR4Ro3orNiykXoxteStfdQlteRAABAMaCEhYDa8TF6cUSitu49rDFTFignN8/rSAAA4AxRwkJE54ZV9P8uaatZv+zUf74ouA46AAAINRFeB0DRXd21gZZv26+XZq1X6zpxuqxTPa8jAQCA08RIWIj5+0Wt1a1RFd33/hItTtnrdRwAAHCaKGEhJjI8TM8PT1T12CjdNHme0g5keh0JAACcBkpYCKoaG6UXR3TWnkNZuuX1ecrK4UJ9AABCDSUsRLWtG6//XtlByRv36J8fL/M6DgAAOEVcmB/CLu5QR8u37dcLM9aqTZ04XdO9odeRAABAETESFuLuObeF+rWorvs/Xqaf1u3yOg4AACgiSliICw8zPXV1JzWoUl63vjFfW/Ye9joSAAAoAkpYKRAfE6nx1yYpKydPN01O1uGsXK8jAQCAk6CEFWbtdCkvtO44bFojVk9e3VHLtu7Xfe8vlnPO60gAAOAEKGEFbZgjTb5Umni+tHWh12lOyTmtauqec1vo40VbNX7mOq/jAACAE6CEFdSgh3TJc9LuddL4ftInd0iHdnudqshu7ddEF7arrf/7YqVmrEr1Og4AADgOSlhBYWFSp2uk0clS91uk+a9JzyRKc1+W8oL/Wisz038Ht1eLmhU1ZsoCrUtL9zoSAAAoBCXseGIqSec/LN08W6rZVpp6tzT+LGnjD14nO6ny5SL00rVJiggzjZo8Twcysr2OBAAACqCEnUzN1tLvP5GunOg7LTnxfOmDUdKB7V4nO6H6VcrrueGJWr/zoO58e6Hy8rhQHwCAYEIJKwozqe3l0ui5Up97pGUfSs90luY8JeVkeZ3uuHo2qaa/X9hKX69I1ZNfr/Y6DgAAyIcSdirKVZDO+bt0209SQh/pq39IL/SU1nztdbLj+n3PBA3uXE9Pf7tGny/Z5nUcAADgRwk7HVUaS8Pekoa9K7lc6fUrpLeGS3s2eJ3sGGamBy9rq04NKunudxdpxbb9XkcCAACihJ2Z5udKt/4onfNP3wSvz3WTpj8kZR3yOtlvREWEa9w1nRUbFaFRk5O152DwnkIFAKCsoISdqYgoqc9dvuvFWl4offcfXxlb/rEURLPW14yL1osjOmvHvkzd9uZ85eSG1ooAAACUNpSw4hJfV7pygjRyqhRVUXpnhG/m/bRVXic7olODyvr3ZW31/dpdeuizlV7HAQCgTKOEFbeE3tJNM6UL/ittXeC7cH/aX6WM4LgWa3BSfY3smaAJc9brvXkpXscBAKDMooQFQniE1G2UNGa+1HGY9MNz0rNJ0sIpQbEw+F8vbKWeTarqLx8u0YJNe7yOAwBAmUQJC6QK1aRBz0g3fiPF15f+d7M04TzPFwaPDA/Ts8MSVaNilG5+fZ5S92d4mgcAgLKIElYS6naWbvjKtzD4nvVBsTB4lQrl9NK1Sdp/OEc3vT5PmTnBvy4mAAClCSWspPy6MPiYeUcXBn+6k6cLg7eqHafHruqgBZv26h//WyYXRHdzAgBQ2lHCSlp0vG9h8FvmSLXaeb4w+MB2tTX67KZ6O3mzXvthoycZAAAoiyhhXqnRyrcw+OBJ0qE9voXB379R2l/ySwvdNaC5fteqhh74dLl+WLurxD8fAICyiBLmJTOpzWXS6J+lvvdKyz/y3UVZwguDh4WZnhjSUQlVy+vWN+Zp8+7gmvEfAIDSiBIWDMpVkPr/TbrtR88WBq8YHamXrk1STp7TqMnzdCgrp8Q+GwCAsogSFkx+XRh8+HuSy/MtDD5lWIktDN64eqyeGdpJK7fv173vLuZCfQAAAogSFoyaDZBu/UH63f3SuhnSs11LbGHwfi1q6I/ntdTUJdv0/Iy1Af88AADKKkpYsIqIknrfKY1Jllpd7F8YvGuJLAx+81mNdXGHOnr0y1X6duWOgH4WAABlFSUs2MXVka58RRr5mW96ixJYGNzM9MgV7dW6dpxun7JQa1LTA/ZZAACUVZSwUJHQSxr1nTTw0RJZGDymXLjGX5ukchFhGvVasvYdzg7I5wAAUFZRwkJJeITU9Ub/wuDDfQuDP9M5YAuD160Uo+eHJ2rT7kO6460Fys3jQn0AAIoLJSwUVagmDXpauvFbqVKDgC4M3q1xVf1zUBtNX5Wmx74M3ClQAADKGkpYKKub6F8Y/Pl8C4PfLh0s3lnvr+nWQEO71tfzM9bqk0Vbi/XYAACUVZSwUBcWJnUa7l8Y/FZp/mTpmUTp55eKbWFwM9O/BrVV54aVde97i7Rs675iOS4AAGUZJay0iI6Xzn/ItzB47fbSZ/dILxbfwuDlIsL0wjWJqhRTTqNem6dd6ZnFclwAAMoqSlhpU6OVdO3H0uBXpcPFuzB4jYrRGn9tZ6WlZ+q6SXO1fV9GMQQGAKBsooSVRmZSm0ul0XOlvn88ujD47CfPeGHw9vUq6blhiVqTmq6Lnpmln9YV7/VnAACUFZSw0qxcean/X6XbfpIa9ZW+/qf0Qo8zXhh8QOua+ui2XoqLjtSwl3/ShNnrWWcSAIBTRAkrC6o0koZO8S8M7oplYfBmNSvqf6N7qX/LGnrg0+W64+2FOpxVPDcCAABQFlDCypLCFgb/9t+nvTB4XHSkXryms+45t7k+XrRVlz0/Rxt3HSzWyAAAlFaUsLIm/8LgrQdJMx/xLwz+0WktDB4WZhrdv5kmXddV2/Zl6OJnZmv6qtQABAcAoHShhJVVcXWkK17OtzD4tdJrl0ipK0/rcGc1r65PRvdWvcrldf2kuXr6m1+UxzJHAAAcFyWsrMu/MPi2hdK4Xqe9MHiDquX1/i09dWnHunr8q9UaNTlZ+zNY+BsAgMJQwnCChcHfPOWFwWPKhevxqzroX4PaaMaqNF3y7Byt3nEgQMEBAAhdlDAclX9h8MoNpf/dcloLg5uZft8zQVNGdVd6Zo4ufW6OPl3MmpMAAORHCcOx6iZK138pXfqCbxqL01wYvEtCFX06prda1Y7T6DcX6KHPVign99RG1gAAKK0oYShcWJjUcZjvLsqCC4Pn5hT5MDXjojXlxu66tkdDjZ+5TiNe+Zl1JwEAECUMJ3NkYfDvpdodfAuDj+8nrf22yFNalIsI0wOXtNWjgzto/qY9uviZ2Vq0eW9AYwMAEOwoYSiaGi2laz/yLQyesVeafJlvPcrvn5UO7S7SIa7sXE/v39JTZqbB437Q23M3BTYzAABBzEJtzb+kpCSXnJzsdYyyLTvDN7lr8gRp849SeJTU5jIp6XqpflffAuInsOdglsa+tUCzftmpoV0b6P5BrRUVEV5C4QEAKDlmNs85l1Toa5QwnJEdy6TkidLit6XM/VKNNlLSdVL7q3ynMo8jN8/psS9X6fkZa9WhfiWNuyZRteNjSjA4AACBRwlD4GUdlJa+L819xTfpa2R5qd2VvtGxOp2O+7Yvlm7T3e8sUnRkuJ4dlqgeTaqWXGYAAAKMEoaStWW+71Tl0vel7ENSnURfGWt7uVSuwjG7r0k9oJsmz9OGXYf05wta6obejWQnOaUJAEAooITBG4f3Sovf8RWytBVSVLzUYYjU+TqpZuvf7HogI1v3vLtI05bt0MUd6ug/V7RT+XIR3uQGAKCYUMLgLeekTT9K8yZKyz6UcrOkBj18o2OtBkmR0f7dnF74bq0enbZKzWpU1IsjOiuh2rEjZwAAhApKGILHwV3Sojd9o2O710kxVaROw32jY1WbSJJmrk7T2LcWKDfP6amrO6p/y5oehwYA4PRQwhB88vKkDTN9ZWzlVCkvR2rczzc61mKgNu/L1s2vz9Oyrft1x++aaWz/ZgoL4zoxAEBo8aSEmVl9Sa9JqinJSRrvnHuqwD79JH0kab1/0wfOuQdOdFxKWCl0YLu0YLI071Vp32YptqaUeK0y2o/QX77dow/mb9E5LWvo8SEdFR8T6XVaAACKzKsSVltSbefcfDOrKGmepEudc8vz7dNP0j3OuYuKelxKWCmWlyut+do3OrZ6mmQm12yApsdepJt/rKLalSvoxRGd1bJWnNdJAQAokhOVsIDdfuac2yZpm//5ATNbIamupOUnfCPKrrBwqfl5vsfeTdL812TzX1P/9GlaUrmOJhw+S6Oe2657rjxLgzrU8TotAABnpESuCTOzBEkzJbV1zu3Pt72fpPclpUjaKt+o2LJC3j9K0ihJatCgQeeNGzcGPDOCRG62tOoz3+jYuhnKUbim5XbW3lbDNeSqaxQRwTQWAIDg5emF+WYWK+k7Sf92zn1Q4LU4SXnOuXQzGyjpKedcsxMdj9ORZdiutcqdO0GZcyerfO4+bQuvo7jeN6pC199LFZhpHwAQfDwrYWYWKelTSdOcc48XYf8NkpKcczuPtw8lDMrO0NzPJ8nmTVCSrVJeeDmFHVlAvNtJFxAHAKCknKiEhQXwQ03SK5JWHK+AmVkt/34ys67+PLsClQmlRGS0ugy6WdGjvtKIqCf1RtbZylo+VZpwnvR8D+mn8VLGPq9TAgBwQoG8O7K3pFmSlkjK82/+i6QGkuScG2dmoyXdIilH0mFJdznnvj/RcRkJQ357D2Vp7FsLNXf1Zv2/Jqt0ed6XCtu2wLeAeNsrfKNjdRO9jgkAKKOYrBWlWm6e0xNfrdaz09eoQ714vTwgXNVXvSktec+3gHjtjr4y1u7KQhcQBwAgUChhKBOmLduuu99ZpKiIMD0zrJN61o08uoB46nIpKk5qP0RKuk6q2cbruACAMoAShjJjbVq6bpo8T+vS0vXnC1rpD30aySRp80++Mrbsf1JuplS/u290rPUlRxYQBwCguFHCUKakZ+bo3ncX6fOl23Vh+9p65Ir2qhDln0/smAXEK0sd/QuIV2vqbXAAQKlDCUOZ45zTizPX6ZEvVqppjVi9OCJJjarlux6ssAXEG53lGx1reaEUzhqVAIAzRwlDmTX7l50aM2W+cnKdnhjSUb9rXfPYnQpbQLzTCKnz76VKDUo+NACg1KCEoUxL2XNIt7w+X0u27NPYc5rpjnOaKSyskAldCy4gLknNzvWNjjUb4FvbEgCAU0AJQ5mXkZ2rv/9vqd6dl6KzW1TXk0M6Kb78CU45+hcQ1/zXpPQdUlw9qfNIKXGEVLFWieUGAIQ2Shgg33Vib/y0Sf/6ZJlqx8foxRGd1ap23InfVGABcVm41HKgb3SsUT8pLGCLTgAASgFKGJDP/E17dMvr87TvcLb+c0V7XdKxbtHeuGutNG+StOB16fBuqXIj35xjHYdLFaoFNDMAIDRRwoACUg9kaPSbC/Tz+t26vlcj/XlgS0WGF3FUKztDWvGxb3Rs0w9SeDnffGNJ10sNerCAOADgCEoYUIjs3Dw9/NlKTZizXl0bVdFzwxJVvWLUqR1kx3Jp3kRp0VtS5n6pektfGWs/RIqpFJDcAIDQQQkDTuB/C7boTx8sVnxMpF64prMSG1Q+9YNkHZSWvi8lT5S2zpcion3zjjUb4LvDsnLD4g8OAAh6lDDgJJZv3a+bX5+nbfsO6/5BbTSsawPZ6Z5W3LpAWjhF+mWatGeDb1u1FkcLWYMeUkS5YssOAAhelDCgCPYdytbtby/QjFVpuiqpnh64pK2iI89gbjDnfBfz//Kl77FxjpSbJZWLlRr38xWyZgOkuDrF9jsAAIILJQwootw8p6e+Xq2nv12jdnXjNW5EZ9WtFFM8B89Ml9bP9Jeyr6T9Kb7tNdsdHSWr10UKjyiezwMAeI4SBpyir5fv0J1vL1RkRJieGdpJvZoW8xQUzkmpK3yFbM3Xvrss83Kk6HipyTm+Qtb0d1Js9eL9XABAiaKEAadhXVq6bn59ntakpuuP57fUTX0bn/51YieTsc83Geyvo2TpO3zb63Tyn7Y81/ecpZMAIKRQwoDTdDAzR398f7GmLt6mge1q6ZErOyg2KsCnC/PypB1LjhaylLmSy5PKV/WNjjU7V2rSXypfJbA5AABnjBIGnAHnnF6etV4Pf75CTarHatyIzmpSPbbkAhzaLa399uipy0O7JAvzXT/267VktdozSSwABCFKGFAMvl+zU6OnLFB2Tp4eu6qDzm3jwULeebm+KTB+veNy6wLf9thaUjP/KFnjfr5rywAAnqOEAcVky97DuvX1eVqUsk9j+jfVHb9rrvAwD0eg0lN9o2O/fCmt+VbK3CeFRUj1ux8dJavRilEyAPAIJQwoRhnZufrnR8v0dvJmndW8up66uqMqlQ+CyVdzc3zXj/16LdmOJb7tcfWOFrJGfaWoEjyVCgBlHCUMCIApP2/SPz9apprxURp3TWe1qRNkpwD3bTk6SrZuhpSV7ltsvGGvo3dcVm3CKBkABBAlDAiQBZv26JbX52vv4Sw9fHk7XdapnteRCpeT5ZuL7NdRsp2rfNsrNzpayBJ6SZHFNDEtAEASJQwIqLQDmRr95nz9tH63RvZM0F8vbKXI8DCvY53Yng2+MvbLV75Z/HMOSxExvtOVzQb4HpUTvE4JACGPEgYEWE5unv7v85V6efZ6dUmorOeGJ6pGxWivYxVN9mHfupa/fCWtnibtWe/bfmTR8QFSg54sOg4Ap4ESBpSQjxdt1X3vLVbF6Ag9NzxRXRJCcELV/IuOb5hdYNHxAVLTAVJ8Xa9TAkBIoIQBJWjl9v26efI8bd5zWPed30I39gngckeBlnXwt4uO79vs216zbb5Fx7uy6DgAHAclDChhBzKydd/7i/XZku0a0LqmHh3cQfExkV7HOjPOSWkrjxay3yw63j/fouM1vE4KAEGDEgZ4wDmnSd9v0L+nrlDtStF6flhntasXZNNYnImM/QUWHd/u286i4wBwBCUM8ND8TXs0+o352pmepX9c3FrDuzUI3dOTx+OctD3/ouM//3bR8aYDpKbnsOg4gDKHEgZ4bPfBLN359kJ9tzpNl3aso39f1k4VokrxdVRHFh3/Slrz1dFFx+sm+UfJBvgWHQ8L8qk8AOAMUcKAIJCX5/T8jDV6/KvValw9Vi8MT1SzmhW9jhV4eXkFFh2f79seFSfVavfbR/WWUkSUt3kBoBhRwoAg8v2anRr71gIdzMzVw5e306Wdyth0D+mp0ppvpC3JvlOY25dK2Qd9r4VF+IpY/mJWsy2nMQGELEoYEGR27M/QmDcX6OcNuzWsWwP946LWio4soxew5+X5JojdvthfyvyPA9uO7hNf/9hRs0oNWfcSQNCjhAFBKCc3T49+uVrjvlurtnXj9PywzmpQtbzXsYJHepq0Y8lvi9nO1b4L/iUpKl6q1ZbTmQCCGiUMCGJfL9+hu95ZKCfpscEddG6bWl5HCl7Zh6XU5b8tZpzOBBDEKGFAkNu8+5BufWO+lmzZp1F9G+ve81oE/yLgweKUT2e295/ObMDpTAABRwkDQkBmTq4e/HSFJv+4UV0SKuuZoYmqFR8ii4AHo/S0Y4vZrl8KnM4s7O5MFioHUHwoYUAI+WjhFv35gyWKiQzXU1d3Uu9m1byOVHpkHZJSV/y2nO1YKmUf8r0eFnns6cxabaWYyt7mBhCyKGFAiFmTmq5b35inX1LTdcc5zTWmf1OFhXHqLCDycqXdhZzO/HUZJkmKb1DI3ZmczgRwcpQwIAQdysrR3z5cqg8WbFGfZtX05JCOqhrLnX8lJj21wA0AnM4EcOooYUCIcs7prbmb9c+Pl6lK+XJ6bngndW7InX6e4XQmgFNECQNC3NIt+3Tbm/O1Zc9h/emClrqhd6OQXwS836R+XkcoFmHOqU5OpppmHc73OKRquTlH9tkeXk5rysX85rE9ohynMwGPzRg5I+CfcaISVopXEAZKj7Z14/XJmN66991FenDqCiVv2KNHBrdXXHSk19HKvDwzpURGKyUyWjMqHB3xqpybrSZZh9XMX8qaZh1Wz8P79OvEIwfCwrU28rfFbEO5aOUYU5MAZQUjYUAIcc7pldnr9X+fr1TdyjF6fnii2tSJ9zoWiirrYCGnM5cVfjqzZhspvq5UsY5UsZbvwWoAQMg549ORZna7pImSDkh6WVInSX9yzn1ZnEGLghIGSMkbdmv0mwu0+1CWHhjURkO61A/505NlVl6utHtdIXdn7jh235gqUsXavkIWV/vo8/z/rFBDCuckBxAsiqOELXLOdTCz8yTdJOnvkiY75xKLN+rJUcIAn13pmbrj7YWa9ctOXZ5YVw9e2lbly/Ef31Lj0G7frP8Htkn7t0kHtvt/zvfP9B2Sy/3t+yzMV8QKlrNf//lreYupIoVx6hMItOK4JuzXP7EHyle+lhl/dgOeqhobpUnXddUz3/6ip775RUu37NPzwzuraY1Yr6OhOJSv4nvUbHP8ffJypYNpx5azX4vbvhQpZa50aOex7w2LPHqa80hRK2R0LTqeGwiAACnqSNhESXUlNZLUQVK4pBnOuc6BjXcsRsKAY836JU23v7VQmdm5eviK9hrUoY7XkRBMcrJ8o2YHtksHthY+qnZgm5Sx79j3RsT4T3/WOf7oWsVaUrkKJf97ASGgOE5HhknqKGmdc26vmVWRVM85t7hYkxYBJQwo3PZ9GRr95nwlb9yja3s01F8vbKWoiHCvYyGUZB30F7LjlLRfR9hyDh/73qj4AqNqBU5/Vqwlxdbk5gKUOcVxOrKHpIXOuYNmdo2kRElPFVdAAGeuVny0pozqrv9OW6XxM9dp0ea9enZYoupXKe91NISKchWkqk18j+NxTsrc/9vTngUL28bvfc/zso99f/mqBUbRChlZi60hhfEHBArhnJST6bujOCdDyj7se56dkW9bvp+zD/v+aMg+XMg+h6Vm50pdb/Ts1ylqCXtBUgcz6yDpbvnukHxN0lmBCgbg1EWGh+kvA1upc8PKuufdRbromdl6/KoOOqdVTa+jobQw810nFh0vVW9x/P3y8qTDu49/vdqBbdL2pdLB1KNLQR35jDDfqFmhpz/znRaNipXCInz7c92ad5yTcrPzlZ18j4LbjvxcsDjl369gmSpwHJ3G1FoWJkWWlyJjfKfYI/2PrIPF/nWcUqwino6c75xLNLN/SNrinHvl122Bj/hbnI4EimbjroO69Y35WrZ1v24+q4nuObe5IsK5Gw5BJjcn380FhYyq/fr80K4TH8fCfYUsLMI3ihYWXmBb2NHnR7YX3Bae7/0RRwveb7YVPG5hn5XvWBZetG2/yVDYtpPlyr/Nv13mLy+FjAAdKUUnGjkquE9hZcr/WsG7dIsqsrwUEX20IEVGF9iW77WC237zvphjC1b+beGRnhX14jgdecDM/ixphKQ+/mvEmKobCGINq1bQ+7f01AOfLte479Zq/qY9enZoJ9WIi/Y6GnBUeITvurG42ifeLyezwPVq23yjGHm5vgKQl+N/5BayLe/o8yPbC27zb8/JPHZb/n+6E23LOXZULxSFR/kLTMHCE+M7Vfzra78pRfkLUGFFqZAyFRFV5kcwizoSVkvSMElznXOzzKyBpH7OudcCHbAgRsKAU/fhghT95YOlqhAVoaeHdlTPJtW8jgSUTs4dvxj+pgSexrbflMPCtuX89v3OHS1Pxx0pKlCUImKYP66YFcsC3mZWU1IX/48/O+dSiynfKaGEAafnlx0HdPPr87R+50HdNaC5bu3XVGFhZfuvUAAItBOVsCLVXTO7StLPkgZLukrST2Z2ZfFFBBBozWpW1Meje+viDnX06Jerdf2rc7XnYJbXsQCgzCryskWSBvw6+mVm1SV97ZzrEOB8x2AkDDgzzjm98dMmPfDJclWLLafnhieqU4PKXscCgFLpjEfCJIUVOP246xTeCyCImJmu6d5Q79/SU+Hhpqte/EET56xXUS9NAAAUj6IWqS/MbJqZjTSzkZKmSvoscLEABFq7evH6dHQfndW8hv71yXKNfnOBDmQUMrkmACAgilTCnHP3Shovqb3/Md45d18ggwEIvPjykXrp2s768wUt9cWy7Rr07Byt2Lbf61gAUCYU+e7IYME1YUBg/Lx+t0a/OV/7Dmfr/13aVlcl1fc6EgCEvNO+JszMDpjZ/kIeB8yMP5eBUqRroyr67PY+SkqorD++t1j3vrtIh7NOcxZsAMBJnbCEOecqOufiCnlUdM7FlVRIACWjWmyUXru+m8b2b6r35qfosufnaF1autexAKBU4g5HAL8RHma669wWmjiyi3bsz9CgZ+do6uJtXscCgFKHEgagUP1a1NDUsX3UvGasbntzvu7/eJmyckrBungAECQoYQCOq06lGL01qoeu79VIk77foKte/EFb9h72OhYAlAqUMAAnVC4iTP+4uLVeGJ6otanpuvDpWZq+ypOlYwGgVKGEASiSC9rV1idjeqt2fIyumzhXj05bpdy80JriBgCCCSUMQJElVKugD2/tqau71Nez09fompd/UuqBDK9jAUBIooQBOCXRkeH6vyva69HBHbRg8x5d+PRs/bhul9exACDkUMIAnJYrO9fT/27rpYpRERr20o96fsYa5XF6EgCKjBIG4LS1rBWnj8f01sB2tfXIF6t042vJ2nsoy+tYABASAlbCzKy+mU03s+VmtszMbi9kHzOzp81sjZktNrPEQOUBEBixURF6ZmgnPXBJG838JU0XPj1bizbv9ToWAAS9QI6E5Ui62znXWlJ3SbeZWesC+1wgqZn/MUrSCwHMAyBAzEzX9kjQuzf3lCQNHveDXvthg5zj9CQAHE/ASphzbptzbr7/+QFJKyTVLbDbJZJecz4/SqpkZrUDlQlAYHWsX0lTx/ZW72bV9I+PlmnsWwuVnpnjdSwACEolck2YmSVI6iTppwIv1ZW0Od/PKTq2qMnMRplZspklp6WlBSwngDNXqXw5vXxtkv54fgtNXbxVg56drVXbD3gdCwCCTsBLmJnFSnpf0h3Ouf2ncwzn3HjnXJJzLql69erFGxBAsQsLM93ar6nevLG7DmTk6JLnZuv9eSlexwKAoBLQEmZmkfIVsDeccx8UsssWSfXz/VzPvw1AKdC9cVVNHdtbHetX0t3vLtKf3l+sjOxcr2MBQFAI5N2RJukVSSucc48fZ7ePJV3rv0uyu6R9zrltgcoEoOTVqBit12/optvObqK35m7W5c9/rw07D3odCwA8F8iRsF6SRkjqb2YL/Y+BZnazmd3s3+czSeskrZH0kqRbA5gHgEciwsN073ktNXFkF23dd1gXPzNbny3h7y0AZZuF2i3kSUlJLjk52esYAE5Typ5DGv3mAi3cvFeXJ9bV/YPaKC460utYABAQZjbPOZdU2GvMmA+gRNWrXF7v3txDY89ppo8WbtUFT85i7UkAZRIlDECJiwwP010Dmuu9m3uoXESYhr70ox76bAUX7QMoUyhhADzTqUFlTR3bW8O7NdD4met06XNztGLbac1kAwAhhxIGwFPly0XowUvbaeJ1XbTrYJYGPTtb475bq9y80LpeFQBOFSUMQFA4u0UNTbujr37Xqqb+7/OVGjr+R23efcjrWAAQMJQwAEGjSoVyen54oh6/qoNWbNuv85+cqXeSN7MQOIBSiRIGIKiYmS5PrKfP7+ijtnXj9cf3FuumyfO0Kz3T62gAUKwoYQCCUr3K5TXlxu7668BWmrEqTec9OVPfrNjhdSwAKDaUMABBKyzMdGPfxvp4TC9Vi43SDa8m688fLNHBzByvowHAGaOEAQh6LWvF6aPRvXTzWU301txNGvj0LM3buNvrWABwRihhAEJCVES4/nRBS709qody85wGj/tBj05bpaycPK+jAcBpoYQBCCldG1XR57f30RWJ9fTs9DW6/IU5+mXHAa9jAcApo4QBCDkVoyP138Ed9OKIztq6N0MXPTNbE+esVx4TvAIIIZQwACHrvDa1NO2OvurdtJr+9clyjZjwk7btO+x1LAAoEkoYgJBWvWKUXv59kh6+vJ0WbNqr856YqY8WbvE6FgCcFCUMQMgzMw3t2kCfje2jpjVidftbCzVmygLtPZTldTQAOC5KGIBSI6FaBb1zUw/de14Lfb5km857cqZm/ZLmdSwAKBQlDECpEhEeptvObqr/3dZLFaMjNeKVn3X/x8t0OCvX62gA8BuUMAClUtu68fp0TG9d1ytBk77foIuemaXFKXu9jgUAR1DCAJRa0ZHh+ufFbfT6Dd10KCtXlz//vZ7+5hfl5DLBKwDvUcIAlHq9m1XTF7f31YXta+vxr1brynE/aP3Og17HAlDGUcIAlAnx5SP11NWd9PTQTlqXlq6BT83SGz9tlHNM8ArAG5QwAGXKoA519OWdZykpobL++uFSXT9prlIPZHgdC0AZRAkDUObUio/Wq9d11f0Xt9b3a3fpvCdm6oul27yOBaCMoYQBKJPCwkwjezXS1LF9VK9yed38+nzd/c4i7c/I9joagDKCEgagTGtaI1Yf3NpTY/s31YcLUnTBk7P047pdXscCUAZQwgCUeZHhYbrr3BZ675aeigw3DX3pRz302Qpl5jDBK4DAoYQBgF9ig8qaOraPhnZtoPEz1+mSZ+doxbb9XscCUEpRwgAgnwpREXrosnaaMDJJO9OzdMmzc/Tid2uVm8dUFgCKFyUMAArRv2VNfXlnX53dsroe/nylhr70ozbvPuR1LAClCCUMAI6jSoVyGndNZz06uIOWb92vC56apXeTNzPBK4BiQQkDgBMwM13ZuZ4+v72PWteJ073vLdbNr8/TrvRMr6MBCHGUMAAogvpVymvKjd31l4EtNX1lms57cpa+XbnD61gAQhglDACKKDzMNKpvE300upeqxZbT9ZOS9ecPluhgZo7X0QCEIEoYAJyiVrXj9NHoXrqpb2O9NXeTBj49S/M27vE6FoAQQwkDgNMQFRGuPw9spbdu7K6cXKfB477XY1+uUnZuntfRAIQIShgAnIFujavqizv66PLEenrm2zW67Pk5WpN6wOtYAEIAJQwAzlDF6Eg9OriDxl3TWVv3ZujCp2dr4pz1ymOCVwAnQAkDgGJyftta+uKOPurVtJr+9clyXTvhZ23bd9jrWACCFCUMAIpRjYrReuX3SXrosnaat3GPzntipj5etNXrWACCECUMAIqZmWlYtwb6/PY+alIjVmOnLNCYKQu071C219EABBFKGAAESEK1Cnr3ph66e0Bzfb5km857cqZm/ZLmdSwAQYISBgABFBEepjHnNNOHt/ZShahwjXjlZ93/8TJlZOd6HQ2AxyhhAFAC2tWL19SxfTSyZ4Imfb9BFz49S0tS9nkdC4CHKGEAUEKiI8N1/6A2mnxDVx3MzNVlz8/RM9/8ohwmeAXKJEoYAJSwPs2qa9odfXVBu9p67KvVGvziD9qw86DXsQCUMEoYAHggvnyknhnaSU9d3VFrU9N1wVOz9MZPG+UcE7wCZQUlDAA8dEnHupp2Z18lNqykv364VNdPmqvUAxlexwJQAihhAOCx2vExmnx9N/3z4tb6fu0unffETH2xdJvXsQAEGCUMAIJAWJjpul6N9OmY3qpbOUY3vz5fN0yaq3Vp6V5HAxAglDAACCLNalbUB7f00p8uaKmf1u/WeU/O1EOfrdD+DGbbB0obShgABJlyEWG6+awm+vaes3RZp7p6adY69X90ht6eu0m5eVy4D5QWlDAACFI1KkbrkSs76KPbeqlh1Qq67/0luuS52Zq7YbfX0QAUA0oYAAS59vUq6b2be+ipqztqV3qWBo/7QWOmLNCWvYe9jgbgDFDCACAEmJku6VhX39x9lsae00xfLtuucx6boSe/Xq3DWaxDCYQiShgAhJDy5SJ014Dm+ubus3ROq5p68utfdM5jM/TJoq1M9AqEGEoYAISgepXL67lhiXp7VHdVKl9OY6Ys0FUv/qClW1gUHAgVlDAACGHdGlfVJ2N66+HL22ld2kFd/Oxs/en9xUo7kOl1NAAnQQkDgBAXHmYa2rWBvr2nn27o1UjvzUtR/0dnaPzMtcrKyfM6HoDjoIQBQCkRHxOpv13UWtPu7Ksujarooc9W6rwnZ+qbFTu4XgwIQpQwAChlmlSP1YSRXTTxui4yk254NVm/nzhXa1IPeB0NQD6UMAAopc5uUUPT7uirv1/UWgs27dF5T87Svz5Zpn2HWAIJCAaUMAAoxSLDw3RD70aacU8/DelSX5O+36B+j07X6z9uZAkkwGOUMAAoA6rGRumhy9rp0zG91bxmRf3tf0t14dOz9P3anV5HA8osShgAlCFt6sTrrVHd9fzwRB3IyNGwl37SLa/P0+bdh7yOBpQ5EV4HAACULDPTwHa11b9lDb00c52en7FW36xM1ag+jXVLvyaqEMV/GoCSwEgYAJRR0ZHhGnNOM317z1ka2LaWnp2+Rv0fm6EPF6Qoj+vFgICjhAFAGVc7PkZPXt1J79/SQzXjonXn24t0xbjvtXDzXq+jAaUaJQwAIEnq3LCK/ndrLz06uINS9hzWpc/N0d3vLFLq/gyvowGlEiUMAHBEWJjpys71NP2efrr5rCb6ZNFWnf3oDD0/Y40ysnO9jgeUKpQwAMAxYqMi9KcLWurLO/uqZ9NqeuSLVTr3iZmatmw7SyABxYQSBgA4roRqFfTStUmafENXRUWE6abJ83TNKz9p1XaWQALOFCUMAHBSfZpV1+e399G/BrXR0i37dcFTM/WPj5Zqz8Esr6MBIStgJczMJphZqpktPc7r/cxsn5kt9D/+EagsAIAzFxEept/3TNCMe/ppRPeGeuOnTer36AxNmrNe2bl5XscDQk4gR8ImSTr/JPvMcs519D8eCGAWAEAxqVyhnP51SVt9NraP2taN0/2fLNfAp2Zp1i9pXkcDQkrASphzbqak3YE6PgDAWy1qVdTrN3TT+BGdlZmTpxGv/Kw/vJqsDTsPeh0NCAleXxPWw8wWmdnnZtbmeDuZ2SgzSzaz5LQ0/tICgGBhZjq3TS19dVdf3Xd+S/2wdqcGPPGdHv58hdIzc7yOBwQ1C+StxmaWIOlT51zbQl6Lk5TnnEs3s4GSnnLONTvZMZOSklxycnLxhwUAnLHU/Rl6ZNoqvTcvRdUrRumP57XQFYn1FBZmXkcDPGFm85xzSYW95tlImHNuv3Mu3f/8M0mRZlbNqzwAgDNXIy5ajw7uoI9u66V6lWN073uLdenzczRvI1enAAV5VsLMrJaZmf95V3+WXV7lAQAUnw71K+mDW3rqySEdtWN/hq544Qfd/tYCbdt32OtoQNCICNSBzWyKpH6SqplZiqR/SoqUJOfcOElXSrrFzHIkHZZ0tWMaZgAoNcxMl3aqqwGta2rcd2v14sx1+nLZDt3Sr4lG9W2s6MhwryMCngroNWGBwDVhABCaNu8+pIc/X6HPlmxX3Uox+svAVhrYrpb8J0WAUikorwkDAJQt9auU1/PDO+utUd0VFxOp296cryHjf9Syrfu8jgZ4ghIGAChR3RtX1adjeuuhy9ppTWq6Lnpmtv78wRLtSs/0OhpQoihhAIASFx5mGtatgabf00/X92qkd5M3q9+jM/TyrHXKymEJJJQNlDAAgGfiYyL194ta64s7+iqxQWU9OHWFzn9qpqavSvU6GhBwlDAAgOea1ojVq9d31cSRXSQnXTdxrq6b+LPWpqV7HQ0IGEoYACBonN2yhr64o6/+dmErJW/Yo/OemKn/9+ly7Tuc7XU0oNhRwgAAQaVcRJj+0Kexpt/bT4OT6mnCnPXq/+gMTfl5k3LzQmtaJeBEKGEAgKBULTZKD1/eXp+M7q0m1WP15w+W6OJnZuundSyugtKBEgYACGpt68br7Zu669lhnbT3UJaGjP9Rt70xXxt3HfQ6GnBGArZsEQAAxcXMdFH7OjqnZU2Nn7lOL3y3Rp8t3aYBrWrq+t6N1K1RFWbeR8hh2SIAQMhJ3Z+hyT9u1Bs/bdLug1lqVTtO1/dK0MUd6rAmJYLKiZYtooQBAEJWRnauPlq4RRNmb9CqHQdULbachndrqOHdG6hGxWiv4wGUMABA6eac0/drd2nC7PX6ZmWqyoWH6eIOdXRdrwS1rRvvdTyUYScqYVwTBgAIeWamXk2rqVfTalq/86Be/X6D3knerPfnp6hroyq6vlcjDWhdU+FhXDeG4MFIGACgVNp3OFvvJm/WxDkbtGXvYdWrHKORPRN0VZf6iouO9DoeyghORwIAyqyc3Dx9vWKHJszeoJ837FaFcuEanFRfI3smKKFaBa/joZSjhAEAIGnpln2aMGe9Plm0VTl5Tue0rKHrezVSjyZVmeICAUEJAwAgn9QDGXr9x01648eN2nUwSy1rVdT1vRppUEemuEDxooQBAFCIjOxcfbxoqybMXq+V2w+oaoVyGt6tga7p3lA14pjiAmeOEgYAwAk45/Tjut2aMGe9vl6xQxFhvhn6r+/VSO3qMcUFTh9TVAAAcAJmph5NqqpHk6rauOugJn2/Qe8mp+jDBVvUJaHykSkuIsJZchnFh5EwAAAKcSAjW+8mp2jS9xu0afch1a10dIqL+BimuEDRcDoSAIDTlJvn9M2KHZowZ71+XLdb5cuF68rO9TSyZ4IaV4/1Oh6CHCUMAIBisGzrPk2cs0EfL9yqrNw89fdPcdGrKVNcoHCUMAAAilHagUy9+dMmTf5xo3amZ6p5zVhd16uRLutUlyku8BuUMAAAAiAzJ1efLtqmCXPWa9nW/apcPlLDujXQiO4JqhXPFBeghAEAEFDOOf28frcmztmgL5dvV5iZLmxfW9f1aqSO9St5HQ8eYooKAAACyMzUrXFVdWtcVZt3H9Kr32/Q23M366OFW5XYoJKu791I57epxRQX+A1GwgAACID0zBy9l7xZE7/foI27DqlOfLSu7Zmgq7vUV6Xy5byOhxLC6UgAADySl+c0fVWqJsxZrzlrdikmMlxXdK6rkT0bqWkNprgo7ShhAAAEgZXb92vi7A36cOEWZeXk6azm1XV970bq26waU1yUUpQwAACCyK70o1NcpB7IVNMasbquV4Iu71RPMeWY4qI0oYQBABCEsnLy9NmSbXpl9not2bJP8TGRGtq1ga7t0VB1KsV4HQ/FgBIGAEAQc85p3sY9mjBnvb5Yul1mpgva1tL1vRspsUFlr+PhDDBFBQAAQczMlJRQRUkJVZSy55Be+2Gjpvy8SZ8u3qaO9X1TXFzQtpYimeKiVGEkDACAIHQwM0cfzE/RxDkbtG7nQdWKi9aIHg01rGsDVa7AFBehgtORAACEqLw8p+9Wp2nCnPWa9ctORUeG6bJO9XR9rwQ1q1nR63g4CU5HAgAQosLCTGe3rKGzW9bQ6h0HNHHOBn0wP0VTft6kPs2q6fpejXRW8+oKC2OKi1DDSBgAACFm98EsTfl5k177YYN27M9U42oVfFNcJNZThSjGV4IJpyMBACiFsnN9U1xMmLNBizbvVVx0hG+Ki54JqssUF0GBEgYAQCk3f9MeTZi9Xp8v3S5JGtCqps5rW1NnNa+hKlzI7xmuCQMAoJRLbFBZicMqa+vew3rth416b95mfbFsu8ykTvUr6ewWvuvK2tSJY4mkIMFIGAAApVBentOSLfs0fVWqpq9M1aKUfZKkGhWj/IWsuno3q65YriELKE5HAgBQxqUdyNR3q9M0fVWqZq5O04GMHEWGm7okVFH/ljXUr0UNNalegVGyYkYJAwAAR2Tn5mn+xj36dlWqZqxM06odByRJDaqU19ktquvsljXUvXFVRUeymPiZooQBAIDjStlzSDNWpWn6ylTNWbtTGdl5io4MU68m1dSvZQ31b1mDuy1PEyUMAAAUSUZ2rn5ct0szVqXp25Wp2rT7kCSpec1Y36SxLWqoc8PKrGNZRJQwAABwypxzWrfzoKavTNX0Van6ef1uZec6VYyOUN9mvtOWZzWvruoVo7yOGrQoYQAA4IwdyMjWnDW7jpSy1AOZkqQO9eLVr4XvtGW7uvEsoZQPJQwAABQr55yWbd2vGatS9e3KVC3YvFfOSdViy+ms5r4pMPo0q674mEivo3qKEgYAAAJq98EszfRPgfHd6jTtPZSt8DBTUsPKOtt/cX+zGrFlbgoMShgAACgxObl5Wrh5r3+i2DQt37ZfklS3UozOblldZ7eooZ5NqimmXOmfAoMSBgAAPLN9X8aR05az1+zUoaxclYsIU4/GVdXff8dlg6rlvY4ZEJQwAAAQFDJzcjV3/Z4jyymt23lQktSkegWd7b+4PymhispFlI4pMChhAAAgKG3YedBXyFal6ce1u5SVm6fYqAj1blrtyKnLGnHRXsc8bZQwAAAQ9A5l5fimwPCPkm3blyFJalMn7sj6lh3rV1J4CE2BQQkDAAAhxTmnVTsO6NuVvvUt523ao9w8p8rlI3VW86MTxVYqX87rqCdECQMAACFt36FszfzFt77ljNVp2n0wS2EmJTaofGQ5pVa1KwbdFBiUMAAAUGrk5jktTtmr6f5Fx5ds2SdJqhUXrbNbVle/FjXUu2k1VYiK8DgpJQwAAJRiqQcyNGNVmmasStWs1Tt1IDNH5cLD1LVRlSMTxTaqVsGTbJQwAABQJmTn5il5w9EpMH5JTZckJVQtf+S0ZbfGVRQVUTITxVLCAABAmbR596EjE8V+v3aXMnPyFBMZrl5Nq+nKznV1ftvaAf38E5Uw70+WAgAABEj9KuU1okeCRvRIUEZ2rn5Y65sC49uVqVqUEhvwEnYijIQBAIAyxzmnrNy8gJ+WPNFIWOlYEwAAAOAUmFmJXRd2PJQwAAAAD1DCAAAAPEAJAwAA8AAlDAAAwAOUMAAAAA9QwgAAADxACQMAAPAAJQwAAMADASthZjbBzFLNbOlxXjcze9rM1pjZYjNLDFQWAACAYBPIkbBJks4/wesXSGrmf4yS9EIAswAAAASVgJUw59xMSbtPsMslkl5zPj9KqmRm3q2iCQAAUIK8vCasrqTN+X5O8W87hpmNMrNkM0tOS0srkXAAAACBFBIX5jvnxjvnkpxzSdWrV/c6DgAAwBnzsoRtkVQ/38/1/NsAAABKPS9L2MeSrvXfJdld0j7n3DYP8wAAAJSYiEAd2MymSOonqZqZpUj6p6RISXLOjZP0maSBktZIOiTpukBlAQAACDYBK2HOuaEned1Jui1Qnw8AABDMQuLCfAAAgNKGEgYAAOABShgAAIAHKGEAAAAeoIQBAAB4gBIGAADgAUoYAACAByhhAAAAHqCEAQAAeIASBgAA4AFKGAAAgAcoYQAAAB6ghAEAAHiAEgYAAOABShgAAIAHKGEAAAAeoIQBAAB4gBIGAADgAUoYAACAByhhAAAAHqCEAQAAeIASBgAA4AFKGAAAgAcoYQAAAB6ghAEAAHiAEgYAAOABShgAAIAHKGEAAAAeoIQBAAB4gBIGAADgAUoYAACAByhhAAAAHqCEAQAAeIASBgAA4AFKGAAAgAcoYQAAAB6ghAEAAHiAEgYAAOABShgAAIAHKGEAAAAeoIQBAAB4gBIGAADgAUoYAACAByhhAAAAHqCEAQAAeIASBgAA4AFKGAAAgAcoYQAAAB6ghAEAAHiAEgYAAOABShgAAIAHKGEAAAAeoIQBAAB4gBIGAADgAUoYAACAByhhAAAAHqCEAQAAeIASBgAA4AFKGAAAgAcoYQAAAB6ghAEAAHiAEgYAAOABShgAAIAHKGEAAAAeoIQBAAB4gBIGAADgAUoYAACAByhhAAAAHqCEAQAAeIASBgAA4AFKGAAAgAcoYQAAAB6ghAEAAHiAEgYAAOCBgJYwMzvfzFaZ2Roz+1Mhr480szQzW+h//CGQeQAAAIJFRKAObGbhkp6TNEBSiqS5Zvaxc255gV3fds6NDlQOAACAYBTIkbCuktY459Y557IkvSXpkgB+HgAAQMgI2EiYpLqSNuf7OUVSt0L2u8LM+kpaLelO59zmgjuY2ShJo/w/ppvZquIOW4hqknaWwOeEKr6fE+P7OTm+oxPj+zk5vqMT4/s5uZL4jhoe74VAlrCi+ETSFOdcppndJOlVSf0L7uScGy9pfEkGM7Nk51xSSX5mKOH7OTG+n5PjOzoxvp+T4zs6Mb6fk/P6Owrk6cgtkurn+7mef9sRzrldzrlM/48vS+ocwDwAAABBI5AlbK6kZmbWyMzKSbpa0sf5dzCz2vl+HCRpRQDzAAAABI2AnY50zuWY2WhJ0ySFS5rgnFtmZg9ISnbOfSxprJkNkpQjabekkYHKcxpK9PRnCOL7OTG+n5PjOzoxvp+T4zs6Mb6fk/P0OzLnnJefDwAAUCYxYz4AAIAHKGEAAAAeoIQVYGYTzCzVzJZ6nSUYmVl9M5tuZsvNbJmZ3e51pmBiZtFm9rOZLfJ/P//yOlMwMrNwM1tgZp96nSUYmdkGM1viX84t2es8wcbMKpnZe2a20sxWmFkPrzMFEzNrkW85wIVmtt/M7vA6VzAxszv9/45eamZTzCzakxxcE/Zb/olj0yW95pxr63WeYOO/o7W2c26+mVWUNE/SpYUsR1UmmZlJquCcSzezSEmzJd3unPvR42hBxczukpQkKc45d5HXeYKNmW2QlOScY6LNQpjZq5JmOede9t99X945t9fjWEHJv4TgFkndnHMbvc4TDMysrnz/bm7tnDtsZu9I+sw5N6mkszASVoBzbqZ8d2qiEM65bc65+f7nB+SbVqSut6mCh/NJ9/8Y6X/wl04+ZlZP0oXyzQ0InBIzi5fUV9IrkuScy6KAndA5ktZSwI4RISnGzCIklZe01YsQlDCcNjNLkNRJ0k8eRwkq/lNtCyWlSvrKOcf381tPSvqjpDyPcwQzJ+lLM5vnX7YNRzWSlCZpov+U9stmVsHrUEHsaklTvA4RTJxzWyQ9KmmTpG2S9jnnvvQiCyUMp8XMYiW9L+kO59x+r/MEE+dcrnOuo3yrRHQ1M05r+5nZRZJSnXPzvM4S5Ho75xIlXSDpNv9lEvCJkJQo6QXnXCdJByX9ydtIwcl/qnaQpHe9zhJMzKyypEvkK/R1JFUws2u8yEIJwynzX+v0vqQ3nHMfeJ0nWPlPkUyXdL7HUYJJL0mD/Nc8vSWpv5m97m2k4OP/S13OuVRJH0rq6m2ioJIiKSXfCPN78pUyHOsCSfOdczu8DhJkfidpvXMuzTmXLekDST29CEIJwynxX3j+iqQVzrnHvc4TbMysuplV8j+PkTRA0kpPQwUR59yfnXP1nHMJ8p0m+dY558lfoMHKzCr4b3qR/zTbuZK4W9vPObdd0mYza+HfdI4kbgwq3FBxKrIwmyR1N7Py/v+mnSOPlk2khBVgZlMk/SCphZmlmNkNXmcKMr0kjZBvBOPX258Heh0qiNSWNN3MFsu3fupXzjmmYcCpqClptpktkvSzpKnOuS88zhRsxkh6w///Zx0lPeRtnODjL/AD5BvlQT7+UdT3JM2XtES+LuTJ8kVMUQEAAOABRsIAAAA8QAkDAADwACUMAADAA5QwAAAAD1DCAAAAPEAJA1CqmFluvulTFppZsc2mbmYJZsacXQCKRYTXAQCgmB32LxsFAEGNkTAAZYKZbTCzR8xsiZn9bGZN/dsTzOxbM1tsZt+YWQP/9ppm9qGZLfI/fl3WJNzMXjKzZWb2pX9lBAA4ZZQwAKVNTIHTkUPyvbbPOddO0rOSnvRve0bSq8659pLekPS0f/vTkr5zznWQb23CZf7tzSQ955xrI2mvpCsC+tsAKLWYMR9AqWJm6c652EK2b5DU3zm3zr8I/XbnXFUz2ymptnMu2799m3OumpmlSarnnMvMd4wE+Zaiaub/+T5Jkc65B0vgVwNQyjASBqAsccd5fioy8z3PFdfWAjhNlDAAZcmQfP/8wf/8e0lX+58PlzTL//wbSbdIkpmFm1l8SYUEUDbwFxyA0ibGzBbm+/kL59yv01RUNrPF8o1mDfVvGyNpopndKylN0nX+7bdLGm9mN8g34nWLpG2BDg+g7OCaMABlgv+asCTn3E6vswCAxOlIAAAATzASBgAA4AFGwgAAADxACQMAAPAAJQwAAMADlDAAAAAPUMIAAAA88P8BIKgKUDb/XAcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### AIFFEL 요구사항에서는 val_loss를 2.2아래로 맞춰보라고 했는데, 이정도면 그래도 조금 낮게 나온 것 같아요:)\n",
    "\n",
    "#### 지금까지 나온 코드에서 batch_size, embadding_size, hidden_size를 조절해가며, 어떤 값에따라 val_loss가 달라지는지(새로운 노래가사에서 뒤에 내용을 비슷하게 맞추는지)를 확인해볼게요.\n",
    "\n",
    "#### 여러가지 실험을 해본 결과는 다음과 같아요.\n",
    "\n",
    "|구분|batch_size|embadding_size|hidden_size|epochs|loss / val_loss|비고|\n",
    "|---|---:|---:|---:|---:|---|---|\n",
    "|test1|256|256|1024|10|2.2335/ 2.5371|AIFFEL제시값, 학습시간: 53분|\n",
    "|test2|512|256|1024|10|2.4980/ 2.6593|학습시간: 42분|\n",
    "|test3|512|256|2048|10|2.2654/ 2.5407|학습시간: 105분|\n",
    "|test4|512|512|2048|10|1.8706/ 2.3590|학습시간: 135분|\n",
    "|test5|256|512|2048|10|1.0427/ 2.2050|특징: val_loss가 2.1862까지 떨어져서 다시 상승, 학습시간: 137분|\n",
    "|test6|256|512|2048|10|1.2702/ 2.2055|지현님의 아이디어로 drop-off추가, 학습시간: 103분|\n",
    "|test7|512|512|2048|10|1.6553/ 2.2763|지현님의 아이디어로 drop-off추가, dropout=0.05|\n",
    "|test8|256|800|2048|10|0.9866/ 2.1858|특징: 초반에 val_loss가 6번째에 이미 2.1731에 도달 이후 조금 내려갔다가 다시 상승, 학습시간: 109분|\n",
    "|test9|256|512|1024|10|2.1131/ 2.4764|학습시간: 65분|\n",
    "|test10|256|1024|2048|10|0.9712/ 2.1796|학습시간: 111분|\n",
    "|test11|256|1024|2048|8|1.1064/ 2.1310|학습시간: 70분(구글코랩)|\n",
    "|test12|256|1400|2048|8|1.0631/ 2.1280|학습시간: 70분(구글코랩)|\n",
    "\n",
    "\n",
    "#### 미친듯이 맨땅에 해딩을 하다보니, 변수에 따른 추세가 조금 눈에 들어오는 것 같아요. 일단 대략적인 추세는 batch_size에는 학습에 영향이 크게 없고, embadding_size,\thidden_size과 val_loss가 음의 상관관계를 보이네요. \n",
    "> #### test5 의 loss graph\n",
    "![그래프](model_data/test5.png)\n",
    "#### 또 test 5 이후로는 epochs가 7까지는 잘 내려가다가 다시 올라가는 듯한 모습이 확인되요. 그 이상의 학습은 과적합을 유도할 뿐이라는 생각이 듭니다.\n",
    "\n",
    "#### 과적합을 방지하기 위한 dropout은 크게 의미있는 결과로 느껴지지 않았습니다. 하지만 작사 결과는 달라질 수 있다는 생각도 들어요.\n",
    "\n",
    "#### 결과를 종합하여, 가장 이상적이라고 생각하는 embadding_size = 1024,\thidden_size = 2048 모델로, epochs = 8로 학습한 결과입니다!\n",
    "> #### test12 의 loss graph\n",
    "![그래프](model_data/test12.png)\n",
    "#### 목표 점수?에 도달했으니, 한번 실제로 평가를 해보겠습니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[목차](#to-make-ai-writer)\n",
    "## 4) 모델 평가\n",
    "---\n",
    "\n",
    "#### 글을 쓰는 모델은 사람이 평가할 수 밖에 없어요. 생각하기로는 분명 loss값을 더 줄일 수도 있을 것이지만, AIFFEL에서 2.2만 요구한 이유가 무엇일까요? 일단 줄이기 어렵기 때문일 수도 있죠. 하지만 그 이상 줄이려고 노력하는 것이 의미가 없기 때문이 아닐까 하는 생각이 들었습니다. 그 이유는 다음과 같아요. \n",
    "#### 먼저 모델을 평가하기 위해서는 글을 만들게 시켜서 내가(사람이) 평가하는게 가장 의미있다고 생각합니다. 정답이 없기 때문이죠.\n",
    "#### 모델을 이용해서 글을 만드는 함수를 만들어보겠습니다!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "generate_text(mywriter, tokenizer, init_sentence=\"<start> hi\")\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'<start> hi ! my name is huh ? <end> '"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "test_word = ['man', 'i love', 'is it','it' ,'it was', 'how', 'how nice', 'how to kill', 'safety', 'beautiful','lielfsdf']\n",
    "result_dict = {}\n",
    "for word in test_word:\n",
    "    result = generate_text(mywriter, tokenizer, init_sentence= ' '.join([\"<start>\", word]))\n",
    "    print(\"- \",word,': ', ' '*(12-len(word)), result, sep= \"\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- man:          <start> man i m the mocho like randy <end> \n",
      "- i love:       <start> i love you for your pink cadillac <end> \n",
      "- is it:        <start> is it worth it , let me work it <end> \n",
      "- it:           <start> it s all right we got you <end> \n",
      "- it was:       <start> it was a perfect illusion perfect illusion <end> \n",
      "- how:          <start> how do you <end> \n",
      "- how nice:     <start> how nice is the little stone <end> \n",
      "- how to kill:  <start> how to kill you for e so blue <end> \n",
      "- safety:       <start> safety for your love <end> \n",
      "- beautiful:    <start> beautiful people don t stress stress stress <end> \n",
      "- lielfsdf:     <start> <unk> <unk> <unk> <unk> <end> \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 위와같이 시작단어 여러개를 받아서 해당하는 문장을 받아보겠습니다. \n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "test4 작품 loss = 1.8706 / val_loss = 2.3590\n",
    "- man:          <start> man i m a survivor <end> \n",
    "- i love:       <start> i love you so much <end> \n",
    "- it:           <start> it s a new day , it s a new day <end> \n",
    "- it was:       <start> it was a perfect illusion <end> \n",
    "- how:          <start> how many times i gotta tell that ass to come over ? <end>\n",
    "- how nice:     <start> how nice to be <end> \n",
    "- how to kill:  <start> how to kill you <end>    \n",
    "- safety:       <start> safety out of my head <end> \n",
    "- beautiful:    <start> beautiful <end> \n",
    "- lielfsdf:     <start> <unk> <unk> <unk> <unk> <end> \n",
    "\n",
    "```\n",
    "```\n",
    "test5 작품 loss = 1.0427 / val_loss = 2.2050\n",
    "- man :         <start> man i m , i m andr <end> \n",
    "- i love :      <start> i love you mom , you are my favorite girl . <end> \n",
    "- is it :       <start> is it any wonder they re spitting at the sun <end> \n",
    "- it :          <start> it s a beautiful kind of pain <end> \n",
    "- it was :      <start> it was a <unk> place to me , <end> \n",
    "- how :         <start> how do you do , neighbour ? <end> \n",
    "- how nice :    <start> how nice the sound <end> \n",
    "- how to kill : <start> how to kill you crazy <end> \n",
    "- safety :      <start> safety away <end> \n",
    "- beautyful :   <start> <unk> <unk> <unk> <unk> en <unk> <end> \n",
    "- lielfsdf :    <start> <unk> <unk> <unk> <unk> en <unk> <end> \n",
    "```\n",
    "```\n",
    "test6 작품 loss = 1.2702 / val_loss = 2.2055\n",
    "- man:          <start> man , i m a voodoo child <end> \n",
    "- i love:       <start> i love you <end> \n",
    "- is it:        <start> is it just me ? <end> \n",
    "- it:           <start> it s like the darkness is the light <end> \n",
    "- it was:       <start> it was a perfect illusion <end> \n",
    "- how:          <start> how many times i gotta tell that ass to come over ? <end>  \n",
    "- how nice:     <start> how nice s the water , papa ? <end> \n",
    "- how to kill:  <start> how to kill the <unk> , <end> \n",
    "- safety:       <start> safety , hotel , so much more <end> \n",
    "- beautyful:    <start> <unk> <unk> <unk> <unk> , lighting the <unk> up <end> \n",
    "- lielfsdf:     <start> <unk> <unk> <unk> <unk> , lighting the <unk> up <end> \n",
    "```\n",
    "```\n",
    "test7 작품 - loss = 1.6553 / val_loss = 2.2763\n",
    "- man:          <start> man i m in the mood to find <end> \n",
    "- i love:       <start> i love you , i love you <end> \n",
    "- is it:        <start> is it scary for you baby <end> \n",
    "- it:           <start> it s a new art form showing people how little people care <end> \n",
    "- it was:       <start> it was a perfect illusion perfect illusion <end> \n",
    "- how:          <start> how many times i gotta tell that ass to come over ? <end> \n",
    "- how nice:     <start> how nice can you go ? how low can you go ? <end> \n",
    "- how to kill:  <start> how to kill my body <end> \n",
    "- safety:       <start> safety off , i m tore up my phone <end> \n",
    "- beautyful:    <start> <unk> <unk> <unk> <end> \n",
    "- lielfsdf:     <start> <unk> <unk> <unk> <end>\n",
    "```\n",
    "\n",
    "```\n",
    "test8 작품 -   loss = 0.9866 / val_loss = 2.1858\n",
    "- man:          <start> man i m , i m andr <end> \n",
    "- i love:       <start> i love you so , so , i do <end>\n",
    "- is it:        <start> is it too late to say i m sorry now ? oh whoa <end> '\n",
    "- it:           <start> it s a beautiful kind of pain <end> '\n",
    "- it was:       <start> it was a narrow time , <end> '\n",
    "- how:          <start> how can we just give up ? <end> '\n",
    "- how nice:     <start> how nice is the mystery <end> '\n",
    "- how to kill:  <start> how to kill a man so they would just just hit her <end> \n",
    "- safety:       <start> safety , <unk> , <unk> <end> '\n",
    "- beautiful:    <start> beautiful <end> '\n",
    "- lielfsdf:     <start> <unk> <end> '\n",
    "```\n",
    "\n",
    "```\n",
    "test10 작품  loss = 0.9712 / val_loss = 2.1796\n",
    "- man:          <start> man i m on that lean , liquor for the bitches <end> \n",
    "- i love:       <start> i love you <end> \n",
    "- is it:        <start> is it too much to ask you keep your diamonds up <end> \n",
    "- it:           <start> it s a celebration and everyone should invite me <end> \n",
    "- it was:       <start> it was a black tube , he felt himself disintegrate <end> \n",
    "- how:          <start> how many times must a man look up <end> \n",
    "- how nice:     <start> how nice the sound <end> \n",
    "- how to kill:  <start> how to kill a bird , it s gonna cost him <end> \n",
    "- safety:       <start> safety leaves to try <end> \n",
    "- beautyful:    <start> <unk> <end> \n",
    "- lielfsdf:     <start> <unk> <end> \n",
    "```\n",
    "```\n",
    "test11작품 loss = 1.1064 / val_loss = 2.1310\n",
    "- man:          <start> man i swear i dont need <unk> i need fan patrol <end> \n",
    "- i love:       <start> i love you , i m not gonna crack <end> \n",
    "- is it:        <start> is it just me ? <end> \n",
    "- it:           <start> it s a new day , it s a new day <end> \n",
    "- it was:       <start> it was a perfect illusion perfect illusion <end> \n",
    "- how:          <start> how can you stop the sun from shining ? <end> \n",
    "- how nice:     <start> how nice do the words have be <end> \n",
    "- how to kill:  <start> how to kill the game <end> \n",
    "- safety:       <start> safety , don t worry bout that <end> \n",
    "- beautiful:    <start> beautiful <end> \n",
    "- lielfsdf:     <start> <unk> <unk> <end> \n",
    "```\n",
    "```\n",
    "test12 작품 -  loss = 1.0631 / val_loss = 2.1280\n",
    "- man:          <start> man i m , i m andr <end> \n",
    "- i love:       <start> i love you , <end> \n",
    "- is it:        <start> is it worth it , let me work it <end> \n",
    "- it:           <start> it s like the darkness is the light <end> \n",
    "- it was:       <start> it was just plane shadow to train shadow <end> \n",
    "- how:          <start> how many times i gotta ? <end> \n",
    "- how nice:     <start> how nice is the little load <end> \n",
    "- how to kill:  <start> how to kill the game <end> \n",
    "- safety:       <start> safety , it was something i ve been told <end> \n",
    "- beautiful:    <start> beautiful <end> \n",
    "- lielfsdf:     <start> <unk> <unk> <unk> <unk> , lighting the old trail <end> \n",
    "```\n",
    "\n",
    "#### val_loss가 낮을 수록 무조건 좋은 게 아니라고 생각하고 했는데... 일단 여기서는 실제로 제시해준 만큼 val_loss가 2.2정도 되어야, 더 잘 기능을 하는 것 같군요.\n",
    "#### test12모델이 없는 단어에서 문장을 출력해주었어요..!! 말 그대로 자기가 하고 싶은 말을 한 것인가.. 또 is it으로 만든 문장을 보면, 나름 라임을 맞추고 있습니다.ㅋㅋ 그래도 지금까지 본 중에는 만족스러운 모델이 아닌가 싶습니다.\n",
    "\n",
    "[목차](#to-make-ai-writer)\n",
    "---\n",
    "# 5. 아쉬운 점\n",
    "## 1. 가장 먼저 한글로 시도해보지 않아서 아쉬웠습니다. 물론 이건 순전히 제 잘못이죠ㅜㅜ 어서 해봐야겠습니다.\n",
    "## 2. 여기서 Loss의 의미는 무엇이었을까요? 많은 사람들이 loss를 낮추는 것에 중점을 맞추고 시간을 보냈는데, 아직도 그 내용을 잘 모르겠습니다. 어서 알게되기를 소망합니다!"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('Working': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "026aceb1435085fcef523649cdfc9385a4a55dbc5c65435142607853821fa50a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}