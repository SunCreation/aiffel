{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "AI_Translator\n",
    "=\n",
    "\n",
    "### 오늘을 번역기를 만들어볼 것 입니다.\n",
    "### 그나저나, 너무 놀랍네요. 번역기를 만들 수 있다니.. 사실 지금까지 배운내용이면, 분명 만들 수 있어야하긴 한데;; 혼자서는 너무 자신이 없네요. 한번 교육과정의 도움을 받아 만들어보도록 하겠습니다.\n",
    "\n",
    "# 목차\n",
    "## 1. 목적 및 의의\n",
    "## 2. 이론\n",
    "## 3. 실습\n",
    "## 4. 회고\n",
    "\n",
    "# 1. 목적 및 의의\n",
    "## 1) Seq2seq 구조를 이해하고 이를 토대로 번역기를 만들어본다. \n",
    "## 2) Attention 을 구현하여, 성능을 높여보고, 이를 이해한다.\n",
    "\n",
    "# 2. 이론\n",
    "\n",
    "# 3. 실습"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "# fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "# font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "# mpl.font_manager.findfont(font)\n",
    "print(\"글꼴이 없다면 terminal에\")\n",
    "print(\"sudo apt -qq -y install fonts-nanum\")\n",
    "print(\"를 하세요!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "글꼴이 없다면 terminal에\n",
      "sudo apt -qq -y install fonts-nanum\n",
      "를 하세요!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "\n",
    "print(tf.__version__)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip',\n",
    "    origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
      "2646016/2638744 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "with open(path_to_file, \"r\") as f:\n",
    "    raw = f.read().splitlines()\n",
    "\n",
    "print(\"Data Size:\", len(raw))\n",
    "print(\"Example:\")\n",
    "\n",
    "for sen in raw[0:100][::20]: print(\">>\", sen)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data Size: 118964\n",
      "Example:\n",
      ">> Go.\tVe.\n",
      ">> Wait.\tEsperen.\n",
      ">> Hug me.\tAbrázame.\n",
      ">> No way!\t¡Ni cagando!\n",
      ">> Call me.\tLlamame.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    if s_token:\n",
    "        sentence = '<start> ' + sentence\n",
    "\n",
    "    if e_token:\n",
    "        sentence += ' <end>'\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "print(\"슝~\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "enc_corpus = []\n",
    "dec_corpus = []\n",
    "\n",
    "num_examples = 30000\n",
    "\n",
    "for pair in raw[:num_examples]:\n",
    "    eng, spa = pair.split(\"\\t\")\n",
    "\n",
    "    enc_corpus.append(preprocess_sentence(eng))\n",
    "    dec_corpus.append(preprocess_sentence(spa, s_token=True, e_token=True))\n",
    "\n",
    "print(\"English:\", enc_corpus[100])   # go away !\n",
    "print(\"Spanish:\", dec_corpus[100])   # <start> salga de aqu ! <end>"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "English: go away !\n",
      "Spanish: <start> salga de aqu ! <end>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# 토큰화하기\n",
    "enc_tensor, enc_tokenizer = tokenize(enc_corpus)\n",
    "dec_tensor, dec_tokenizer = tokenize(dec_corpus)\n",
    "\n",
    "# 훈련 데이터와 검증 데이터로 분리하기\n",
    "enc_train, enc_val, dec_train, dec_val = \\\n",
    "train_test_split(enc_tensor, dec_tensor, test_size=0.2)\n",
    "\n",
    "print(\"English Vocab Size:\", len(enc_tokenizer.index_word))\n",
    "print(\"Spanish Vocab Size:\", len(dec_tokenizer.index_word))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "English Vocab Size: 4931\n",
      "Spanish Vocab Size: 8893\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.w_dec = tf.keras.layers.Dense(units)\n",
    "        self.w_enc = tf.keras.layers.Dense(units)\n",
    "        self.w_com = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, h_enc, h_dec):\n",
    "        # h_enc shape: [batch x length x units]\n",
    "        # h_dec shape: [batch x units]\n",
    "\n",
    "        h_enc = self.w_enc(h_enc)\n",
    "        h_dec = tf.expand_dims(h_dec, 1)\n",
    "        h_dec = self.w_dec(h_dec)\n",
    "\n",
    "        score = self.w_com(tf.nn.tanh(h_dec + h_enc))\n",
    "        \n",
    "        attn = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vec = attn * h_enc\n",
    "        context_vec = tf.reduce_sum(context_vec, axis=1)\n",
    "\n",
    "        return context_vec, attn\n",
    "\n",
    "print(\"슝~\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(enc_units,\n",
    "                                       return_sequences=True)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.gru(out)\n",
    "        \n",
    "        return out\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, h_dec, enc_out):\n",
    "        context_vec, attn = self.attention(enc_out, h_dec)\n",
    "\n",
    "        out = self.embedding(x)\n",
    "        out = tf.concat([tf.expand_dims(context_vec, 1), out], axis=-1)\n",
    "        \n",
    "        out, h_dec = self.gru(out)\n",
    "        out = tf.reshape(out, (-1, out.shape[2]))\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, h_dec, attn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# 코드를 실행하세요.\n",
    "\n",
    "BATCH_SIZE     = 64\n",
    "SRC_VOCAB_SIZE = len(enc_tokenizer.index_word) + 1\n",
    "TGT_VOCAB_SIZE = len(dec_tokenizer.index_word) + 1\n",
    "\n",
    "units         = 1024\n",
    "embedding_dim = 512\n",
    "\n",
    "encoder = Encoder(SRC_VOCAB_SIZE, embedding_dim, units)\n",
    "decoder = Decoder(TGT_VOCAB_SIZE, embedding_dim, units)\n",
    "\n",
    "# sample input\n",
    "sequence_len = 30\n",
    "\n",
    "sample_enc = tf.random.uniform((BATCH_SIZE, sequence_len))\n",
    "sample_output = encoder(sample_enc)\n",
    "\n",
    "print ('Encoder Output:', sample_output.shape)\n",
    "\n",
    "sample_state = tf.random.uniform((BATCH_SIZE, units))\n",
    "\n",
    "sample_logits, h_dec, attn = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                     sample_state, sample_output)\n",
    "\n",
    "print ('Decoder Output:', sample_logits.shape)\n",
    "print ('Decoder Hidden State:', h_dec.shape)\n",
    "print ('Attention:', attn.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Encoder Output: (64, 30, 1024)\n",
      "Decoder Output: (64, 8894)\n",
      "Decoder Hidden State: (64, 1024)\n",
      "Attention: (64, 30, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "print(\"슝~\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "@tf.function\n",
    "def train_step(src, tgt, encoder, decoder, optimizer, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_out = encoder(src)\n",
    "        h_dec = enc_out[:, -1]\n",
    "        \n",
    "        dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
    "\n",
    "        for t in range(1, tgt.shape[1]):\n",
    "            pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "            loss += loss_function(tgt[:, t], pred)\n",
    "            dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss\n",
    "\n",
    "print(\"슝~\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝~\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# eval_step() 정의하기\n",
    "# train_step() 이후 eval_step() 진행하도록 소스 수정하기\n",
    "# Define eval_step\n",
    "\n",
    "@tf.function\n",
    "def eval_step(src, tgt, encoder, decoder, dec_tok):\n",
    "    bsz = src.shape[0]\n",
    "    loss = 0\n",
    "\n",
    "    enc_out = encoder(src)\n",
    "\n",
    "    h_dec = enc_out[:, -1]\n",
    "    \n",
    "    dec_src = tf.expand_dims([dec_tok.word_index['<start>']] * bsz, 1)\n",
    "\n",
    "    for t in range(1, tgt.shape[1]):\n",
    "        pred, h_dec, _ = decoder(dec_src, h_dec, enc_out)\n",
    "\n",
    "        loss += loss_function(tgt[:, t], pred)\n",
    "        dec_src = tf.expand_dims(tgt[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tgt.shape[1]))\n",
    "    \n",
    "    return batch_loss\n",
    "\n",
    "\n",
    "# Training Process\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                                dec_train[idx:idx+BATCH_SIZE],\n",
    "                                encoder,\n",
    "                                decoder,\n",
    "                                optimizer,\n",
    "                                dec_tokenizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "    \n",
    "    test_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_val.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (test_batch, idx) in enumerate(t):\n",
    "        test_batch_loss = eval_step(enc_val[idx:idx+BATCH_SIZE],\n",
    "                                    dec_val[idx:idx+BATCH_SIZE],\n",
    "                                    encoder,\n",
    "                                    decoder,\n",
    "                                    dec_tokenizer)\n",
    "    \n",
    "        test_loss += test_batch_loss\n",
    "\n",
    "        t.set_description_str('Test Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Test Loss %.4f' % (test_loss.numpy() / (test_batch + 1)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch  1: 100%|██████████| 375/375 [01:49<00:00,  3.41it/s, Loss 0.1651]\n",
      "Test Epoch  1: 100%|██████████| 94/94 [00:23<00:00,  4.02it/s, Test Loss 0.6735]\n",
      "Epoch  2: 100%|██████████| 375/375 [01:50<00:00,  3.41it/s, Loss 0.1477]\n",
      "Test Epoch  2: 100%|██████████| 94/94 [00:09<00:00,  9.58it/s, Test Loss 0.6707]\n",
      "Epoch  3: 100%|██████████| 375/375 [01:50<00:00,  3.40it/s, Loss 0.1344]\n",
      "Test Epoch  3: 100%|██████████| 94/94 [00:09<00:00,  9.61it/s, Test Loss 0.6850]\n",
      "Epoch  4: 100%|██████████| 375/375 [01:50<00:00,  3.40it/s, Loss 0.1228]\n",
      "Test Epoch  4: 100%|██████████| 94/94 [00:09<00:00,  9.59it/s, Test Loss 0.6961]\n",
      "Epoch  5: 100%|██████████| 375/375 [01:50<00:00,  3.41it/s, Loss 0.1179]\n",
      "Test Epoch  5: 100%|██████████| 94/94 [00:09<00:00,  9.59it/s, Test Loss 0.6968]\n",
      "Epoch  6: 100%|██████████| 375/375 [01:50<00:00,  3.40it/s, Loss 0.1179]\n",
      "Test Epoch  6: 100%|██████████| 94/94 [00:09<00:00,  9.59it/s, Test Loss 0.7128]\n",
      "Epoch  7: 100%|██████████| 375/375 [01:50<00:00,  3.41it/s, Loss 0.1070]\n",
      "Test Epoch  7: 100%|██████████| 94/94 [00:09<00:00,  9.58it/s, Test Loss 0.7181]\n",
      "Epoch  8: 100%|██████████| 375/375 [01:50<00:00,  3.40it/s, Loss 0.0998]\n",
      "Test Epoch  8: 100%|██████████| 94/94 [00:09<00:00,  9.59it/s, Test Loss 0.7126]\n",
      "Epoch  9: 100%|██████████| 375/375 [01:50<00:00,  3.41it/s, Loss 0.0946]\n",
      "Test Epoch  9: 100%|██████████| 94/94 [00:09<00:00,  9.59it/s, Test Loss 0.7321]\n",
      "Epoch 10: 100%|██████████| 375/375 [01:50<00:00,  3.41it/s, Loss 0.0908]\n",
      "Test Epoch 10: 100%|██████████| 94/94 [00:09<00:00,  9.58it/s, Test Loss 0.7456]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def evaluate(sentence, encoder, decoder):\n",
    "    attention = np.zeros((dec_train.shape[-1], enc_train.shape[-1]))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = enc_tokenizer.texts_to_sequences([sentence.split()])\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    enc_out = encoder(inputs)\n",
    "\n",
    "    dec_hidden = enc_out[:, -1]\n",
    "    dec_input = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(dec_train.shape[-1]):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0]).numpy()\n",
    "\n",
    "        result += dec_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if dec_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention\n",
    "\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def translate(sentence, encoder, decoder):\n",
    "    result, sentence, attention = evaluate(sentence, encoder, decoder)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention = attention[:len(result.split()), :len(sentence.split())]\n",
    "    plot_attention(attention, sentence.split(), result.split(' '))\n",
    "\n",
    "\n",
    "translate(\"Can I have some coffee?\", encoder, decoder)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input: can i have some coffee ?\n",
      "Predicted translation: me das un poco ? <end> \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:45: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "interpreter": {
   "hash": "026aceb1435085fcef523649cdfc9385a4a55dbc5c65435142607853821fa50a"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}