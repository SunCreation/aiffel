{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager.findfont(font)\n",
    "\n",
    "print(\"슝=3\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "!nvidia-smi"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fri Jan  7 01:11:54 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   40C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import random\n",
    "\n",
    "import seaborn # Attention 시각화\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def positional_encoding(pos_len, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i) / d_model)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos_len)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:,0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:,1::2])\n",
    "    return sinusoid_table\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scale_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        # scaled qk 구하기\n",
    "\n",
    "        QK_T = tf.matmul(Q, K, transpose_b=True)\n",
    "        scaled_qk = QK_T / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)\n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "\n",
    "\n",
    "    def split_heads(self, *xs): # num_heads는 self에 있으니까 받을 필요 없음\n",
    "        # MultiHead에 넣을려고 분할\n",
    "        # x: [ batch x length x embedding_dimension ]\n",
    "        # return: [ batch x heads x length x embedding_dimension]\n",
    "        split_xs = []\n",
    "        for x in xs:\n",
    "            a,b,c = x.shape\n",
    "\n",
    "            split_x = tf.reshape(x,(a,b,self.num_heads,self.depth))\n",
    "            split_x = tf.transpose(split_x, (0,2,1,3))            \n",
    "            split_xs.append(split_x)\n",
    "            \n",
    "        return split_xs\n",
    "\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        # 분할 계산을 마치고, 임베딩을 다시 결합한다.\n",
    "        # x: [ batch x heads x length x depth ]\n",
    "        # return: [ batch x length x emb ]\n",
    "        x = tf.transpose(x,(0,2,1,3))\n",
    "        a,b,c,d = x.shape\n",
    "\n",
    "        concat_x = tf.reshape(x, (a,b,c*d))\n",
    "\n",
    "        return concat_x\n",
    "\n",
    "\n",
    "    def call(self, Q, K, V, mask=None): #[batch x len x 512 ]\n",
    "        # 1: Linear_in(Q,K,V) -> WQ, WK, WV\n",
    "        wq = self.W_q(Q)\n",
    "        wk = self.W_k(K)\n",
    "        wv = self.W_v(V)\n",
    "\n",
    "        # 2: split heads\n",
    "        W_qkv_split = self.split_heads(wq,wk,wv)\n",
    "\n",
    "        # 3: scaled dot product attention\n",
    "        out, attention_weights = self.scale_dot_product_attention(*W_qkv_split, mask)\n",
    "\n",
    "        # 4: Combine Heads(out) -> out\n",
    "        out = self.combine_heads(out)\n",
    "\n",
    "        # 5: Linear_out(out) -> out\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out, attention_weights\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "class Position_wise_FFN(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(Position_wise_FFN, self).__init__()\n",
    "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self,x):\n",
    "        out = self.w_1(x)\n",
    "        out = self.w_2(out)\n",
    "        return out\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = Position_wise_FFN(d_model,d_ff)\n",
    "\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        # Multi-Head Attention\n",
    "        residual = x\n",
    "\n",
    "        out = self.norm1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out,out,out, mask)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        # position wise FFN\n",
    "        residual2 = out\n",
    "        out = self.norm2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual2\n",
    "\n",
    "        return out, enc_attn\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, dff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.dec_attn = MultiHeadAttention(d_model, n_heads)\n",
    "\n",
    "        self.ffn = Position_wise_FFN(d_model,dff)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, x,y, causality_mask, padding_mask):\n",
    "        residual = x\n",
    "        out = self.norm1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out,out,out, padding_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        residual = out\n",
    "        out = self.norm2(out)\n",
    "        out, dec_enc_attn = self.dec_attn(out,y,y, causality_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        residual = out\n",
    "        out = self.norm3(out)\n",
    "        out = self.ffn(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 dff,\n",
    "                 dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model,n_heads,dff,dropout) for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "\n",
    "        enc_attns = []\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "\n",
    "        return out, enc_attns\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, n_layers, d_model, n_heads, dff, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model,n_heads, dff, dropout) for i in range(n_layers)]\n",
    "\n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "        \n",
    "        dec_attns = []\n",
    "        dec_enc_attns = []\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = self.dec_layers[i](out,enc_out, causality_mask, padding_mask)\n",
    "            \n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, n_layers,d_model,\n",
    "                 n_heads,dff,src_vocab_size,\n",
    "                 tgt_vocab_size, pos_len,\n",
    "                 dropout=0.2, shared=True):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        self.enc_embedding = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        self.dec_embedding = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.positional = positional_encoding(pos_len,d_model)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, dff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, dff, dropout)\n",
    "        \n",
    "        self.out_linear = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if shared: self.out_linear.set_weights(tf.transpose(self.dec_embedding.weights))\n",
    "\n",
    "    \n",
    "    def embedding(self, emb, x):\n",
    "        # share?\n",
    "        seq_len = x.shape[1]\n",
    "        out = emb(x)\n",
    "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.positional[np.newaxis, ...][:, :seq_len, :]\n",
    "\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        # 1 embedding\n",
    "        enc = self.embedding(self.enc_embedding, enc_in)\n",
    "        dec = self.embedding(self.dec_embedding, dec_in)\n",
    "\n",
    "        # 2 encoder, decoder\n",
    "        enc_out, enc_attns = self.encoder(enc, enc_mask)\n",
    "\n",
    "        dec_out, dec_attns, dec_enc_attns = self.decoder(dec, enc_out, causality_mask, dec_mask)\n",
    "\n",
    "        logits = self.out_linear(dec_out)\n",
    "\n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch, length = 16, 20\n",
    "src_padding = 5\n",
    "tgt_padding = 15\n",
    "\n",
    "src_pad = tf.zeros(shape=(batch, src_padding))\n",
    "tgt_pad = tf.zeros(shape=(batch, tgt_padding))\n",
    "\n",
    "sample_data = tf.ones(shape=(batch, length))\n",
    "\n",
    "sample_src = tf.concat([sample_data, src_pad], axis=-1)\n",
    "sample_tgt = tf.concat([sample_data, tgt_pad], axis=-1)\n",
    "\n",
    "enc_mask, dec_enc_mask, dec_mask = \\\n",
    "generate_masks(sample_src, sample_tgt)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax3 = fig.add_subplot(133)\n",
    "\n",
    "ax1.set_title('1) Encoder Mask')\n",
    "ax2.set_title('2) Encoder-Decoder Mask')\n",
    "ax3.set_title('3) Decoder Mask')\n",
    "\n",
    "ax1.imshow(enc_mask[:3, 0, 0].numpy(), cmap='Dark2')\n",
    "ax2.imshow(dec_enc_mask[0, 0].numpy(), cmap='Dark2')\n",
    "ax3.imshow(dec_mask[0, 0].numpy(), cmap='Dark2')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1UAAAGhCAYAAACJY57gAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAABYlAAAWJQFJUiTwAABQg0lEQVR4nO3defz95Zz/8cdTizah0oJWlUqYsow1JCQ0MyUZDbINRpZBTFoUFWpkN6ZJMki2pKGfJWmEiCJEi6UQU9rQouXb6/fH9T51+nTOZ/mez/553G+3c3t/P+/rut7v65zz+X6/53Wu63pdqSokSZIkScvnLnPdAUmSJElayAyqJEmSJGkEBlWSJEmSNAKDKkmSJEkagUGVJEmSJI3AoEqSJEmSRmBQJUmSJEkjMKiSJEmSpBEYVEmSJEnSCAyqJEmSJGkEBlWSJEmSNAKDKkmSJEkagUGVJEmSJI3AoErSkpLkuCSXJ9lkrvuy0HSvXSU5eK77ovH5Xo2me+3KfyckTZZBlaQFLcl9krw9yU+T/CXJX5P8MskxSe4/oMm/dscTk6y0nPe8uO9D10SPvZf7yWm5JNlkwPtwc5Irkpyf5JNJ/iXJPea6r4vdmL8rr59km7WS3NTX7vEz20tJGt2Kc90BSVpeSfYF3gKsAlwNnA0EeCDwIuA5SZ5RVV/vtamqq5McAPwnsD9w8Ahd+DZwxQR1fjPC9TW6L3THFYG1gM2AZ3ePI5IcBRxSVcvmqH9LybOBf59Evd2B5frCQ5LmikGVpAUpySrAEbSgZX/g01V1U1e2BnAc7cPZMUk2H/Oh+cPAvwGvS/LBqrp8ObtxQFWdvpxtNQuq6u/HnkuyDfBK4CXAgcCjkuzS+/3RjLgMeEiSLarqognq/mN3/D9g/ZntliRND6f/SVqobgU+DWxbVR/v/0BcVdcCLweWAZsAD+lv2AVY7wTWAN40Wx3W/FBVP6uqlwM7A9cBTwTeNbe9WvTO7I7PHq9Skg2Ax9FGgC+Y6U5J0nQxqJK0IFXVTVW1Z1X9ZUj5H7l96t0mA6p8HLgBeFmStWeml5rPqupU2ogVwEuTbD6X/VnkTuqO4wZVwJ60zyYnTVBPkuYVgypJi9kq3fFO62Wq6k/AV4G7MvEHvWnRt2j/oUnWS/Ke7tyNSX7XJdfYYJz2myR5d5KfJbk2yQ3dn/89yfpj6q6Y5KVJvpXkqq7uL5O8P8nG49zjvkn+I8klXdKP33T9nDDwTLJrki922RVvSnJpkk8lediAur3sdO9PslGS45Nc2Z07bqJ7TaPjgAuBFYCXDejnXZI8P8lpXf9u7N6zDw9JhNJr53t1R98Efgdsk+RB49TrTf07foL+PzTJ+5Kcm+TP3XO4JMnRw/4OpSW1eW/3PlzXtTszyb5J7jaZJ5Hmo91zPzfJWpNpJ2nxM6iStCgl+RtgA9o0we8Pqfb/uuOus9GnPg8EfkIbJbkcOB1YnZZc44y0NWF3kOR5wPnAq4F7057T/wKrAq8DTu6re0/gDOBDwEOB87q6KwOvAH6e5BkD7vEQ4Me04GL1rs1lXT9/BGw66Ml0QcHHaEkhngpc0rW9FXgWcGaSFwx5LTbonsvu3T2+17WbFVVVwAndj4/vL+veh6/QAq/H0F7/bwOrAS8Ezkmy89hr+l4NVMAnuz//46AKSTYDHg78vuvTQEne2PVjH2Dtrh/fAe5BWyf3rbFBUpL7AefSXp+70YK8c4EH09ZmDr3fGB8Engf8HNipqq6aZDtJi11V+fDhw8eiewBfon2Q+8w4dR7Y1bkeWGEK1764a/f4Kfap1+462ofuB/aV3ZP2Qa2A145ptzPtw2sBbwdWGVO+Q//zpH1gLuAbwHp950P7oL6MNvXx/n1lqwG/7dod138PYEfgj11ZAQePuf+R3fnzgIeMud+/dGU3Alv2lR3Xd73zgU37yu464nu/Se/ak6y/S1f/ZiB95z/Tnf8WsHnf+ZWAw7qyq4B7+l5N+Du/CfA33Z9/NaTum7ryo7qfT2fA3zPg/bTg9nFjzq9F+7KigFeMKfuP7vyX6fu73r2WrwN+NKZ+7/lu0nfuqO7cRcAGo/yO+vDhY/E95rwDPnz48DHdD+CfuT142XKcenft+wC8xRSuf3Hfh67xHicNaXcDsNmA676sKz+979xdug9xBbxvnD6lOz6yq3sNsPaQuh/s6nyi79xrunM/ZUCACfzdoA/qtBTlt9BS2m8y5H7/3bV7V9+53gf1W4EHD2m3LW1tzUSPo8e026TX10m+n9v1Pbe7d+ce1/38a+AeQ9r9b1fn1Uv9vZrE35VNup/P635+xIC6vYDood3PpzM4qNoCuMuQ+72ua3P8mPOndOf3H9JunTE/15h+94LoXwMbTuU18OHDx9J4mFJd0qKS5IHAu7sfX1tVFw6rW1U3JrmKNoXovrQPxFMx0T5V3xty/r1V9asB58/ujlv3ndsB2Jw2evDmYTeqqur++KzueGJVXTmk+tG07Ij/kGSlqroZ2KMr+88asGdTVX0hyc+AbcYUPY+2Hun4qrp4yP2+BjyXNoVurP+tqnOHtFuHFiBM5JJJ1BlPf7KT1YE/Ab0pcB+sqmuGtDuV9v48BngPS/u9mqzjgUNp6xi/2zuZZFtaEH1RVf1gvAvU+CnZe38f7zXm/M9p0x2fkeSoqrphzDWH/j1Osj9tFO13wI5V9dvx+idpaTKokrRodOsoPkNbu/LxqvrPSTTrfbhafTluubz7VH1hyPne+ox79p17dHf8Vk1u/cb23fHscer8hPbBf1XgAUl+TButgbY2ZZjzuPMH9V7/HpHkpCHteh9w7zOgbGg/u9c24/Rnuty978+94Kb3vHZN8mgG27g79p7Xkn2vpqAXVD0ryWurqrcmq7fO6pODm91RkgCPoj2nrYEtu8c6XZWxmwe/E3g+8LfABUkOof0bceMEt3oNbW3c9cATq+rXk+mfpKXHoErSopBkBdq+VfcHzqFNAZyMVbvjdTPRryH+b8j53qhD/wfCe3fHX0zy2ut1xz8Oq1BVy5JcTdtYdT3aWpTe63DpONcetDlur3/bc3uQMMyqA85dO0Gb2XDf7vinvg/Zvec1aMRmrN7z8r2aQFX9OsmZtKmPjwdO64p6GTjHzfoHtyXp+CjwgO7UMtoo0k9oz/spA+77+yQPBz5GC8aOAQ5PchTwgWp72w3y6u64GvBYWqZISboTs/9JWizeT0sS8Fvg6WOn9wyS5K60D6nQPpTNlqlkt1uhO9a4te5sovr95av0/fnmKd6n1789qioTPO457pXmTm8Epz8DXO95PWwSz2u7MW18r8bXC5yeDdAFO5sBP6yqcTf8TbIpLRB7AG2q4uOB1apqk6rakZYcZKCq+lVVPRp4Gi3737pd/fOSPGpIs28Df0/7O/v+LquoJN2JQZWkBS/J62lJHv5CC6j+MMmmW9Kml90ADFrjNB/0RjE2nGT93ijY2DUlt+lG9XrB5GXAn/uKx9vj6E6p3rv20D6gLjhJVgae0/3YPy1zeZ6X79XkfIqWMGP3JCsxyb2pOvsCa9IC4J2r6n+rqn9Ubuy0vzupqlOq6nHAI2ip2TcCTkqyzoDqz6+qL9ASVawCfDbJ3QfUk7TEGVRJWtCS7EbbZ+YW2jfwP55C80d2xzMGLfifJ87qjo9Jstok6vcW+d9pE9c+D6JlPrwBOK+q/sztH7gfOqhBkrsADxlQ1EvGscMk+jYfvYG2fuiXwMf7zi/P8/K9moSq+iMtycdawJNoiTeK2/cLG09vOuYn+9Zj9ZtoWmN/P75HG+n6Ay2wfdqAar1/Fw6hjVrdjzb1UJLuwKBK0oLVTRv6OG20aZ+q+soUL/HU7njyuLXm1qm0DYLvTvuWfqBuKiO0UQBo2eIGffMObVQPWta53hSyr3XHYWvRnsfta4/69QKRf0iy9YDyXv/ukmR5koHMmCQvoX1YvgV4+ZgRj491xxcnWe9OjW+/xl270S7wvZqK3qjU62lB7RlVNZkpuL2RqDtNmUyyPi1IHnt+xUEbagNU1fXcniBm6Drz7kuXvWjp7/8uyZ3uI2lpM6iStCAl2YQWDK0KHDnJTH/97dcEnkzLrDaZb8jnRLc27I3dj29OcmCS/nU1JHks7Vt0qur7wOdpH+w/133Q7NVLklcCL6GNfBzcd5n30NaNPC7J27vRjl67J9A2Ph3Uvx8DHwFWBr6S5A6JHbp77kQbJXnsFJ/+tOsChkcn+QItXfky4EVV9bUxVb8IfJ02xe6rXcrv/uus0I2S/oS2Hsj3amo+T8uo94Tu58lM/QP4YXd8ZZLbpk0meQDwVe6YybHnvsAvk7w+yVr9BUl2p2VJvJW2L9ZQVXUJtweyhyd53CT7LGkJMPufpIXqAFo2tGXA/cdJEQ1wWlW9d8y5f6Jl9HrvOHsETeTQJOPtU0V3/dMmqDOuqjqu+wD5NuAtwBuSnEPLWLg5bTPUi/uavID22uwAXJzk+7TMbdvSPmDeQJsq+Yu+e/wgyZtoC/ffCDwnyU+7+g+kZT27BPibAV18BS342BU4I8mFtOl0q3T3vBdtNGgyacanVd/vxUq06WZbc/sH77OBf66qc8a2q6pK8mzgf2hrb37cvR6/Be5Gm5Z3d1pgcG1fO9+rSaiqa5P8D7AnLeHGZyfZ9DDgGbS+/irJD2hB4t/S9hd7C230sd8NtL/rRwJvT/Ij2ojiRtyeQfBNVfXLSfT7M0mOAV4MnJBku6oals1T0lIymR2Cffjw4WO+PYDjaFOAJvM4bkzbFWgfJK8F1luOe188hXvvPaDdJkOuu0mv3ZDyrYEP0jYyvQ74K3AB8C5g/QHP8V9oexld3dX9FfAhYLNxntvOwJdp+zXdRPtw/h+05Aand/07eEC70NbGnEL7wHoLLXHIeV37bYe8f3e61jT8btz2OvY9bqQlhvgObc+iR0/yWivSPkB/o3tNbqF9eP9Rd52Nfa8m9XflTr/ztOCogC8Oadt7Do8fc35z2vTMi/teq/fQ0s4/s2tz+pg26wMHAWd2r/EttMQiXwSePODevd+bQf1eDfhZV/6/wArT/Tvsw4ePhfdI1VQzv0rSwtatpTkaeGtVHTTX/ZEkSQubQZWkJSXJPWgjBr8H/rbumJxAkiRpykxUIWmpeTdt+tNuBlSSJGk6OFIlSZIkSSNwpEqSJEmSRmBQJUmSJEkjMKiSJEmSpBEYVEmSJEnSCAyqJEmSJGkEBlWSFq0kuyf5XpLrkvwxyfFJNp7rfkmSpMXFlOqSFqUkrwLeA/wU+BRwL+CFwA3Aw6rqkuW45q+BNYGLp6+nkka0CfDnqtp0rjsiaekyqJK06CS5L/BL4MfADlV1Q3f+kcAZwClVtetyXPdKVl5xrZU2WHvcene/btnUOy1puVx99dUsW7bsqqoa/y+mJM2gFee6A5I0A14CrAwc2AuoAKrqzCSfA56VZOPlGK26eKUN1l5r3TfvPW6lp3336qn2V9JyOvHEE7niiisunut+SFraXFMlaTF6Em2a36kDyk7ujk+eve5IkqTFzKBK0mL0AOC8qrplQNm53XGbWeyPJElaxJz+J2lRSbImLZnEpUOq9M5vNM41zh5StNUIXZMkSYuUI1WSFps1uuN1Q8p751efhb5IkqQlwJEqSYtN78uiYSn4eudXGHaBqnrIoPPdCNb2y981SZK0GDlSJWmxub47rjKkvHd+2EiWJEnSlBhUSVpsrgFuBNYbUr5+d7xsVnojSZIWPaf/SVpUqurWJL9geFKJXta/C2aqD196xD0nrONeVpIkLR6OVElajE4D1k2y3YCyXfrqSJIkjcygStJidAxQwOFJbhuRT7ItsDdwVlX9aG66JkmSFhun/0ladKrqx0mOBN4AnJnkJGBt4AXALcBL57B7kiRpkXGkStKiVFVvBF5C+/LoAOD5tCl/D3OUSpIkTSdHqiQtWlV1DG0qoCRJ0oxxpEqSJEkkOS7J5Uk2meu+LFRJ9k5SSU6f674sRElO716/vee6L1NlUCVJkrQIJXliko8m+UWS67vHz5K8N8mmA5r8a3c8MclKy3nPi7sPxb3HrUmuSfLrJF9KckCS+y3/s9JkdAFy7z344hTa/aCv3cEz2MVFx6BKkiRpEUlylyRfBk4FngesDHwb+BGwIfBK4KdJntjfrqqupq1B3Q7Yf8RufBv4AvA/wLnAMtqWFm8FLkzyqSRrj3gPTc6Tk6w1UaUkWwAPmYX+LEquqZKkOTCZDYLBTYIlLZeVgafQApq3VNUPegXdh+v/AnYDPp5ks6q6oa/th4F/A16X5INVdfly9uGAqjq9/0SS9YAXAvsCzwIeleQxVXXJct5DE7sMWA/Ynfa+j+cfu+P/AevPZKcWI0eqJEmSFpdbgBdX1a79ARVAVV1FG726jvbBeacx5cuAdwJrAG+azk5V1WVV9TbaaMgFwH2Bk5Z3qqEm5czu+OxJ1O0FVd+eob4sagZVkiRJi0hV3VJVHx6n/Drg/O7H+w6o8nHgBuBlMzFFr6p+DfwD8Ffgb4DnTvc9dJuv0QLoxycZOvqU5G+ArYCLgJ/OTtcWF4MqSZKkpedu3fGysQVV9Sfgq8BdmdwIx5RV1c+Bj3U//sugOkl2SPLpJL9PclOSy5KcnORJw66b5G5J/i3Jd5Nc3bW7JMl/J9l+QP2nJDkpyf8lubG716eTPHace6zSJdw4r0v+8cckn03ywImed5IHdUkkftPd78okpyZ51oC6vUyCP02yapK3de1uTXLxRPfqXE9b23YX2pTLYXqjVJ+coP8bJjkwybe6vt/cPf8vJHnYkDarJXldkrOTXJXkhi5hyjunkmkyyYv7Ep/Mu7VfBlWSJElLSJLHA1vSAqqvDqn2/7rjrjPYld4H+O2S3L2/IMnbgP8F9gCuAL4BXAs8A/hqkoPGXqwLms4HelMMz6eN1FwD7AWcleRuXd0k+SDwZdpz/APwdeDK7p7fTHLogHvcE/guLeHG/YDvAz8Bng78AHjasCeb5BXAObTN6P9K25D+MmBH4FNJho0u3gU4hbbW7f+6dtcNu88An+iO/zioMEmAPbsfjx+n/zvQRrLeAjyINqL1DeBG2mt4xtjAtZvaeTrw78AWtOf/HWAd4LXA+UnuNdETSLIX8J+05/3Uqjp7ojazzaBKkiRpkUty926U5FDgi7QPwi+pqmuHNPlOd3xskhVmqFtnAUX7PHrbKE8XfPwbcCnwpKp6UFU9paruR0u4cCNwSBcc9trcB/gKcG9aoLRRVT2yqp5WVQ+mfaD/Grd/9n0N8PLuHg+tqu2qapeqeiCwA3AVsH+S543p84eBB9OCg/tV1eOqakfg/rQg45mDnmiSpwHvpwUFz66qLavqqVW1DfB4WuD4wiTPH9B8a+BhwJOr6uFVtRNwp1G3cXy1u/4jhowMPRLYGPhhVV0wznXWBS6nrclbu3vuTwY2Bf6bNrK535g2u3V9/z9gs6raqaqeSFvPtxstmL3reJ1PshvwUVog+rSqOnO8+nPFoEqSJGkRS7IPbbTmXFqq9K8Dj6iq/xmn2YW0gGdVYLOZ6Fe3tusv3Y9rd329G3AYcDPwD1V16pg2JwJHdD++uq/orbTRj7OBv6uqP4xp9ytgl6r6U5JVgd5I1/Or6pwxdc+gBVwAhya5S9e3v6GtBbsR2K2qLu1rcwltFO1OI0hd+/f03e9TY+73TeCN3Y+vGdu+s19Vfa2vzY1D6t1JVd0CfLr7cdB0zt4I1tBRqs63gW2r6mNVdXPf9W8G3tv9+OgxbTbujj+tqiv62txaVZ+njXgNzTCZZBfaiOYtwN93r9W8ZFAlSZK0uP0K+BJtdOUWYGfgDeMloeg+tF/V/TgomcV06QVVq3fH3YG7A1+rqu8PadMLLh4DbY0TtwcGB1XVTYMaVVV1f3wycA/g11X19SH3+BxtKuCGtJEcaNMCAb40KA18Vf2eNqIy1g60qYI/q6qThtyv95we3Jui2OcG4Jgh7SarFzDdIajqRiH3oAXQJ4x3gar6Q1X9eUhxL2AaO5Xv593xYRmw4XRV/WXY+5W2j9rnuh937w8q5yP3qZIkSVrEquoU2pqc3l5R76EFIY9I8qBxpgD29q9afUj5dOitpbqyO/ZGOjZLctKQNr3+rJNkZdr6qVVo08Mm88G7N3Vu6LqcqlqW5EfAE2nT174NPLQr/s6wdsB5A871ntMa4zyn9B034PZgE1owdsOdm0zJd4CLaUHb1l2iEGjrudYDvllVv5vMhZLcv2u3LW1t3pa04BPuHFt8ifbaPZq24fRRwHur6o8T3ObRtN/RVYB/qqovTaZvc8mgSpIkaYmoqsu6Rf9b0IKL19ISDwyyanecSlKESeuSU6zR/djLQnjv7rhV95jIqn1tLumfljaO9brjRB/se+W9+vfpjpcOqNszaNSl17+NusdEVh3z87Cgd9KqqpJ8krbm6R+5ffrjZKf+kWQd4CO0pBw9lwG/Br4FPGfAfW9N8hTgfbQEHQcAr0/yEeDtVfWbIbd7cd+fd+b2ZBvzlkGVJM1jX3rEPSes87TvXj0LPZG0WHSjMJ+gBVUDU4cnuSuwVvfjpEYwlkNvBOcqWgY9gF5SjH2r6t8nc5G+RBo1bsU7m6j+2PJVuuNkArd+vf59oKr2mWLb6XQ8Lah6NnBQN8r3D7Tn89nxGiZZkZYIZHtaBsD9ga926fd7de4UVMFta+de2I1S7Uebbvhy4PlJ/rWqjh7Q7P+Af6Kl3f+nJN+uqg9N5cnONtdUSZIkLT2/7Y4bDinfkjYV7QbamqyZ8ILu+KWqWtb9uTdite4UrtMbUbpPlx58Iv/XHSdK5d3rQ69PvfVE422IvMaAc8vznKZdVf0U+DGwRbfP01Npa8u+WlVXjteWlqlve9raqcdW1WfGBFQrTeb+VbUXbX3Zx4HVgA8lecKA6gd0692eRwtu3z0f96bqZ1AlSZK09KzfHYd9mO4lZzijL+CZNkkeR/ugfgst21/P97rjDlO43NnAMtqGxo+coC60/aSgrZUa1r8Vge3G1L+wOz70zi1uM+iavef06BlMTz9ZvWl+z+L2zYDH3fC385jueGpV3WnDaKaQ4r2qfltVzwVOpgXuY9PWQ3s/6bI/HkFLu/7Zbp+wecmgSpIkaRFJ8uokjxmnfGXgpd2Ppw2p9tTuePJ09q27/98Cn6F9Dj18zN5In6UlnPjbLvvbeNe5G0BVXUOXiAN4ay8F+oD6d+lGVL5Gm3K4SZInDbn8HrTpj7/l9sQUvSQYz0yy1tgGSTbn9kCl39dp+zHdG9h7gue05njl0+CTtJGfp9OScFwPnDSJdr2RqDtNmexe74FTNScIgnqjpRMtRzqQtqfZJsDHJjkaOesMqiRJkhaXTYFvJHl/ko37C7o06p8AHkALLN43tnH3wf7JtP2Yxk2zPRVJtkjybuCbtKl3/1lVb+6vU1WXA2/rfvxMkr8bcJ2HJ/kKsFff6f1oCTV2BD6dZP0xbTalBV7bdOniD+mKjhs7rSzJDsAHuh//rapu7f78KeD3wD2BE5LcY8z1P82AAKG73791P74/yYvHBn5JtulLJDFjusQQ3wK2oSXgOLlb8zSRH3bHXZPcNlLXBU2fZvgI4ZlJ3ptki/6TSbbk9gB0WFr7Xp9vpiXU+AvwNOBNk+jvrDNRhSRJ0uLy37SRiFcAr0hyAfAbWsKEh9PW/VxJ2yR30Mar/0Rb7/LeSay1GebQJFfQvsC/B20D4V72vN/TElEMyzh3aFf3n4GTkvyGtt/RCrSMgPeljZjcluCgqs5L8ve0wGd34O+S/JC23mo92lS+ZdyeyfB9tAyI+wDfT3Ju16+NaKnCAQ7t72NVXdtlTjwFeBJwSZLv0l7Ph9MSPvwPbRPgO6iq/06yES3T4n91r8+Pu+dxv+4B8Lohr8l0Op7bE5RMZuoftIQRr6YFY99L8n1akPMIWrbC1wHvHtDuL8ArgVcmuZC2Pu8etCmUK9Jey49NdPOq+lWSl9PWYr0lyXfH2WNsTjhSJUmStIhU1TnA1sBzaZunrkr7EP0I2l5FbwO2rqpvj23brfl5HS34OHyEbjwa+DtgF9oH8auADwPPBDYeJ6Ciqm6tqpfSRstOpE09eyLwKFrijI8Bj6mqz41pdypwf+Bg2sjKlt011qcFW4+oql90dauqXtn170u0qXlPAtYBPg88oaoOHNC302kB2idoqc6f0N3nS91zPmec53UoLfj6OG0U8HG0tWMr0KY9Pq2qjhrWfhp9hhYAXg18eTINun2yHkX73bkQeBDwQFpQ9LcMT3n+WNpU06/S9iTbiTZK+n1aBsBdJ7tmr6o+QfvC4C7AJ5PcZ4Imsyq3by4tSRpPkrNX2ni97dd9895z3ZU7MKW6lrITTzyRK6644pyqmteZwRaKJC+hjQC9taoOmqi+pMaRKkmSJNGtEToU+FF3lDRJrqmSpAXODYIlTZN301Jc71ZVN81xX6QFxaBKkiRJVNXec90HaaFy+p8kSZIkjcCgSpIkSZJGYFAlSZIkSSMwqJIkSZKkERhUSZIkjSPJ7km+l+S6JH9McnySjee6X5LmD4MqSYtKkk2S1DiPK+a6j5IWjiSvAj4LrAa8DTgeeAbwfQMrST2mVJe0WH0SOGvA+RtmuyOSFqYk9wWOBH4A7FBVN3TnTwDOAN4H7Lqc1/41sCZw8bR0VtJ02AT4c1VtOtWGBlWSFquvVtVxc92J+cINgqXl8hJgZeDAXkAFUFVnJvkc8KwkG1fVJctx7TVZecW1Vtpg7bUGFd79umXL12NJy+3qq69m2bLl+7tnUCVJkjTYk2ij26cOKDsZeBbwZOC/luPaF6+0wdprrfvmvQcW+iWHNPtOPPFErrjiiouXp61BlSRJ0mAPAM6rqlsGlJ3bHbcZ7wJJzh5StNUoHZM0vxhUSVq0kqxFW1x+TVVdO4V2fgiSlrgka9LWPF06pErv/Eaz0yNJ85lBlaTF6lggvR+S/BT4APCfVVVz1itJC8Ua3fG6IeW986uPd5Gqesig892XN9svX9ckzTcGVZIWm+uBDwLnAVfQvmneBngB8B/AY4G9xruAH4Ikcfu2M8NWrffOrzALfZE0zxlUSVpUqupy4BVjzyc5BPgK8Jwkn6yqL8565yQtJNd3x1WGlPfODxvJkrSEGFRJWhKq6k9JXgt8G3gmYFAlaTzXADcC6w0pX787XjYTNx+2DYJZAaX56S4TV5GkReOc7rjBnPZC0rxXVbcCv2B4gppe1r8LZqdHkuYzR6okLSW9BeVXzWkv5ik3CJbu5DTglUm2q6ofjinbpa+OpCXOkSpJS8ke3fF/57QXkhaKY4ACDk9y2xfRSbYF9gbOqqofzU3XJM0nBlWSFpUk706y6YDz2wOH09Y/fGLWOyZpwamqHwNHAjsDZybZP8lRwBnALcBL57J/kuYPp/9JWmyeAuyT5FTg+8CfaWsingvcAOxRVX+Zw/5JWkCq6o1JLqJlFT2AlhXwNGD/qjp/Tjsnad4wqJK02DweeA3w1O54V+APwIeBt1fVJXPVMUkLU1UdQ5sKOOfGW/vomkdp7hhUSVpUquoyYL/uIUmSNONcUyVJkiRJIzCokiRJkqQRGFRJkiRJ0ghcUyVJmrTJbBAMLpiXJC0tjlRJkiRJ0ggcqZIkSVoEho0kO3IszTxHqiRJkiRpBAZVkiRJkjQCgypJkiRJGoFBlSRJkiSNwKBKkiRJkkZg9j9JkqRFbLz95cwMKE0PR6okSZIkaQSOVEmSpt1434z3+A25JGmxcKRKkiRJkkZgUCVJkiRJIzCokiRJkqQRGFRJkiRJ0ghMVCFJkrREDUsqYyIZaWocqZIkSZKkERhUSZIkSdIIDKokSZIkaQSuqZIkzQk3CJYkLRaOVEmSJEnSCBypkiRJ0h2MN5LsCLJ0Z45USZIkSdIIDKokSZIkaQQGVZIkSZI0AoMqSZIkSRqBQZWkBSXJg5JcnqSSPH5InRWT7JfkwiR/TXJJknckWXV2eytJkpYCgypJC0aS5wDfAO41Tp0AJwCHAxcBhwDfAfYFvpZkpVnoqiRJWkJMqS5pQUjyeuBI4PPApcA+Q6ruAewOfKCqbquT5BzgCOCVwFEz21tNFzcIluYf061Ld+ZIlaSF4kJgp6raDbhynHqvAG4EDhhz/ijg9wwPxiRJkpaLQZWkBaGqTq6qr49XJ8nqwKOAb1bVNWPaLwNOATZNssWMdVSSJC05Tv+TtJhsSft37dwh5b3z29DWWw2U5OwhRVstf9ckSdJi5UiVpMVkw+546ZDy3vmNZqEvkiRpiXCkStJiskZ3vG5Iee/86uNdpKoeMuh8N4K1/fJ1TZIkLVaOVElaTHr/pi0bUt47v8Is9EWSJC0RjlRJWkyu746rDCnvnR82kiVJGsGwdOumWtdi50iVpMXksu643pDy9cfUkyRJGpkjVZIWkwu647AsfduMqadFwA2CJUlzzZEqSYtGVV0B/ATYMcnKA6rsQts4eFjKdUmSpCkzqJK02BwNrAPs238yyYtoI1jHdhsBS5IkTQun/0labI4GngUcmmR74CzgAcBewHnAYXPYN0mStAgZVElaVKrqpiQ7AwcCewJPBy4HPgAcVFV/msv+SdJSNN7aR9c8ajEwqJK04FTVwcDB45RfD+zXPSRJkmaUa6okSZIkaQQGVZIkaclJ8qAklyepJI8fUmfFJPsluTDJX5NckuQdSVad3d5Kmu8MqiRJ0pKS5DnAN4B7jVMnwAnA4cBFwCHAd2iZRb+WZKVZ6KqkBcI1VZKkRW8yGwSDC+aXgiSvB44EPg9cCuwzpOoewO7AB6rqtjpJzgGOAF4JHDWzvZW0UDhSJUmSlpILgZ2qajfaZuDDvAK4EThgzPmjgN8zPBiTtAQ5UiVJkpaMqjp5ojpJVgceBXyjqq4Z035ZklOAFyfZoqoumpmeLh3DRpIdOdZC4kiVJEnSHW1J++L53CHlvfPbzE53JM13jlRJkiTd0Ybd8dIh5b3zG010oSRnDynaaqqdkjR/OVIlSZJ0R2t0x+uGlPfOrz4LfZG0ABhUzZE0pyW5IMnk0lLpNklO7/YW2Xuu+7LQJNmke+1qrvsiSfNU7/PRsiHlvfMrTHShqnrIoAdw/nR0VNL8YFA1A5Jsl+SP3QfX4wbVqaoCXgJsDHxshHvVFB6PX977aLAxr+8zJ9lm2zHtNpnhbkqSpub67rjKkPLe+WEjWZKWGNdUTbMkOwOfBO4xUd2q+mWSo4D9kuxdVceNcOuvcft/AsNcMcL1NbFnA5+dRL1/nOmOSJJGcll3XG9I+fpj6mkGjLe/nJkBNd8YVE2Tbmf1E4DdgGuAbwGPmUTTI2h7YbwlySer6sbl7MI/V9XFy9lWo7sMeFqSu1XVXyao+2zgFtrvyToz3TFJ0pRd0B2HJZPYZkw9SUucQdX0WR34B+BE4DXAi5hEUFVV1yQ5Gng98HLg3TPXRc2gM4G/7x5Dp3Mm+VtgM+BsWkBlUCXNI+N9M97jN+SLX1VdkeQnwI5JVq6qm8ZU2YW2cfCwlOuSlhjXVE2fa4Ftqmr3qvrtFNv+V3f8tyQGugvTSd1xoql9vfLPz1xXJEnT4GjaF1/79p9M8iLaCNaxVTUskYWkJcagappU1S1VtVyZfKrqQtq3XesBT5nWjg3RlyRhnSSbJzk2yaVJ/prkV0mOSnL3cdo/MMnRSX6R5Pok1yX5YZKDkqw5pu6qSd6Q5AdJ/tTV/XmStycZOlKTZOskH0vy+65fFyV5S5LVJnhud0ny/C674pVJbkxycZIPJ7n/gPq9TIKv757X/yT5c3fu4Em8nNBGKP8K7JRk7WH9Ap7V/Xj8BM/hCUmO6V6n67rncFGSf09ytyFttkxyXJILk9yQ5Ook30jy0iQrT+ZJJLlrkq91z/3UJMMWaUvSYnc0cAZwaJLPJXljkv/uzp8HHDanvZM0rxhUzR//rzvuOsv3fSLwQ+C5wK9oa8HWA/4VOKULBO4gyZuAH9GyF64JfBv4Dm3h7iHAMX11N+rqvgO4P3BOd4+1gTcC53dT4sbe42ld3X8CCjidFrQcCHwXWGvQk0myBvAV4Dja9Mvzu/6tBrwQOKdLJjLItt21H0+bzvej7t4T6tZR/Q+wEjAsC+DjgA2A71bVr4ddK8l/AKfRppCuTPtP/fvAfYHXAV9LssKYNo+gBebPp/29/gZtrv+jgQ/R1vuNq1sX+FlgJ+CbwK5V9deJ2knSYtRN+dsZeDuwHfAW4AnAB4DHVNWf5rB7kuYZg6r54zvd8fGzfN9jgZ8Am1fVY6tqJ2Br4I/Ao2hrhG6T5KW0b+eKtnbs3lX1pKp6EnBv2rqyq7q6K9KmuW0JfBq4T1U9oaqe0tU9nBZcndw/YpXk3rQgYJWuzkZVtXNVPZA2fe5+wAOHPJ+P0IKCb9OmYz66qnYE7tNdazXg+AzeG+z5tABzs6p6SlVtR/vPdLJ6o0/PHlLem/r3yQmusyHwRWD7qrpf99wfQwtKLwP+lvYffb83016vY6pq86rapaoeQQuQDwdWHe+GXZB2PPB0WmD5tKqaKJukJC1oVXVwVaWqTh9Sfn1V7VdVm1XVXatqw6p6VVVdM7s9lTTfuX5n/uhlENo8ySrLMULw6yTjlb+nql4z4Px1wC79/0FU1W+SHEsbSdqVNrWNbtrZO7pqb6yq9/RfqNt766QkX+hO7QFsTxsBe27/Qt+qugXYP8l2wFNpI2P7d8VvoO1m/5Wq6p3rtTshyXoMSOiR5HG0UaKLgaePeU43d/d7DLAD8DzgPWMucR2wR1X9sa/dVLIxngJcDeyQ5N5V9fu+vq0E7E7bMPJTE1zndVV1p4xS3fvyGWAf2gjUl/qKN+6Op49pczXteY83zfIutGD0mbTRwZ2r6toJ+ihJ0pwZllTGRDKaK45UzR+9D+B3oU0Rm6qvAV8Y5/GTIe3ePOQbt7O749Z953YH7g78gTsHJLfpgiu4ff3QRwdkTuo5ekxdaMEYtCkWg3wQGDTt4gW98nG+RTy1Ow7KzPiZqvrDkHYT6p7j52jv4bPGFD+FNmXxG1U17r4mgwKqPr2A715jzv+8O+4+KNlJVY23R9l/0KZ//gR4slNaJEmSpsaRqvnjhr4/r74c7Zd3n6ovDDl/VXfs/yro0d3xlG6kaSLbd8ezx6nzg+64eZJ70Kap3bs7951BDarq5iQXAg8bU9Tr365JHs1gvRGd+wwoG6+fk3U88GLaVL93953/x77yCXWB0eNpU/22ok2hvD8tqIW2dqvfW2gpfv8B+HGSg4DPT5SZKsm7gX+mBfU7VdWVk+mfJEmSbmdQNX/0r3m5bhbv+39Dzvc+jPdnjesFO7+Y5LV7O9H/cZw6/WXrAb3MdjdO8AF/0MhXr3+T2XR50Bqj6Zjy9r/ApcDDk2xWVb/qshXuCtxIN5VyPEmeTEuzv1F36mbgN8BZXb/v9Pyq6twukPxv4AHAZ2hTQt8BfGSckcJXd8f1gQfTRjwlSZI0BQZV80cvILiVNr1uVlTVrVOo3ss4N6mMeP23mUJZL4X3zVO8B9zev4dV1Q/GrTlDqurWJCfQsvQ9m5Yk4um0NWKfn2hqXZcJ8Yu0kahP0ka7zu6NOCXZmyFBY1Wdk+RB3X33Bf6GlvlvnyR7DEn5/3na2qxjaAk8tquq303lOUtLjRsES5LGck3V/NHbP+kX8ziNdW9UacNJ1u+Ngo1d/9Nv3b4/Xwb8ufvz6knuOk67NQac661VWndA2Wz6RHf8xzHHyUz9ezMtoPpYVT2nqs4aM4Vv7LS/O6iqW6vq+C5z4VOAi2ip4k8aslfVHlX1YeBjtE0uP90l1ZAkSdIkOVI1fzyyO54+l52YwFm0faOeNMn6P6CtYXoYLTPeIL11Ub+sqmuS3EQbrbsL8BAGrKvqshBuNeBa36NNmdthnPvNuKr6YZLzgW2TPJyW3fAvtBGoifRGoT4xpHz7IecH9eOrSXYALqEF7Y+kTU/sr9ML2P6lK38k8O/cPi1QkqQFY7yRZEeQNZMcqZo/ntodT57TXozvc7R1QVsmef6wSn0jTL3U4c8fZ9TpZd3xBGh7gnB7IPXSIW1eBwy63se644u7tOtD+zdk1GY69Ual3k7r6+cnOQLZGyW605TJJNvSNjAee361cZ7PZbT3DMb5EqVLof6PtGmXr0oyNnuhJEmShjComgeSbEFb/3IZ8JW57c1w3b5Lvc1w/zPJS7tNY2+T5O+4PTA8kTZatSnw8SRr9tVbMcnbgCfTnvc7+y5zVHd8XpJXjLn+nsC/DeniF4Gv0zYU/moXhPS3XSHJbrTU4ZtN4imPohdUPWHMzxP5YXd8Q5Lbpjh2+2t9idvXjfV7OHB+kn/ub9N5NS35x7W0kcahunVovX3BPpxk0GigJEmSxnD63/zwku74jkmmKh/k6CTXT1DngKr66XJev+cQ4B60D+sfAg5Lci5thGMb2nqr06FNLUvyD7S9oZ4JPDXJWV3d7Whrra4EntFtUkvX7vNJ/gN4OfD+JK+mZRzcAtgc+DYtUOsl9+i1qyTPBv4HeAQttfhPgd/SAosH0VKSX8/0ZPobqqp+meR7tJTol9OCvck4EPgy8ETgkiTn0NLab0/b1PjdtJG6fn8C7gv8J/DeJD/szm0O3I82nfJlVfWXSdz/34GdaMHu55I8vKpmMxulJEnSguNI1Rzr9mZ6KfA72qa2y+tJwN9N8FhnlL5CC1yq6jW0oOWjtA/vjwIeB1wDvLW7V6/+72gB1JuAC4GHAo8FrqaNSG1TVd8fcJ9/AfYCzqAlnnhiV3QEbarkwOyA3Sa3j6UFqv9L24/qKbR04Rf33XM2Mtz11kV9ZrLBclV9nTby9AXa3mWPoe1bdjhtNPNOKfCr6oe0NWZHAD+jpVR/IrAa8GngkVU1bI3W2GsV8DxaILgNt2/OLEmSpCHSPkNpriQ5jBZwvKiqjp3r/kjzXZc2/lTaSOcTqur0MeV7Ax8Z5xKfq6pnLue9z15p4/W2X/fNey9Pcy0hLoifPSeeeCJXXHHFOVX1kLnuy1T478ns8++lJjLKvydO/5tDSTYDXgucYkAlTSzJc4D3AWtNovpbgasGnL9oWjslSZKWPIOqOZIktA1Xf0tLUy5pHEleDxxJ27D4UmCfCZocW1UXz3S/pEHcIFiaf0y3rpnkmqo50q1N2rGqtuxP0iBpqAuBnapqN1qCE0mSpHnBkSpJC0JVzec93CRJ0hJmUCVpsVohybq0f+euqKqbJtswydlDity7S5Ik3YnT/yQtVhfRNpa+FLg2yWlJdprjPkmSpEXIkSpJi83FtD27LgL+TNvn7BHAnsBXk7ysqsbdf2tYKtVuBGv7ae2tJEla8AyqJC0q3b5Vp485/f4kh9M2k35XkpOq6vLZ7pskSVqcpi2oSrI78AZgW+B64GvAflV1ySTbrwYcTPs2eT3gEtoGnkdW1bLp6qekpamqfpbkncBhwC7AcXPbI0nSfDEs3bqp1jVZ0xJUJXkV8B7gp8DbgHsBLwR2SvKwiQKrJHcFvg78LfAp4MfAY7prbUcLtEbp36+BNWnTgiTND5sAf66qTWfxnud0xw1m8Z6SJGmRGzmoSnJf2oacPwB2qKobuvMn0KbavA/YdYLLvJq25mHfqvr3vmt/APiXJJ+qqhNH6OaarLziWittsPZaI1xDmrfuft3CG8y9+uqrWbZs1vu9ene8arZvLI3lBsGStHhMx0jVS4CVgQN7ARVAVZ2Z5HPAs5JsPMFo1b8AvwfeNeb8AcCLgH2AUYKqi1faYO211n3z3iNcQpq/FuIHrxNPPJErrrji4lm+7R7d8ZuzfF9JkrSITUdK9ScBNwCnDijrbdb55GGNk2wJbAx8aezaqaq6mjba9ZhuzZUkDZVkgyRHJLnbgLIX0KYSn1JVP5/93kmSpMVqOkaqHgCcV1W3DCg7tztuM0H7/rqDrrETsMU4dSQJIMBrgZcmOQU4D7gFeBywM/Bz2ui3JEnStBkpqEqyJi0BxKVDqvTObzTOZTYcU3e8a4wbVHV7yAyy1XjtJC0OVfX7JA8FXgXsAPx9V/QL4EDg3VV17Rx1T5K0wIy39nEhTr3XzBl1pGqN7njdkPLe+dWHlE/XNSQtIVV1MG0LhkFlP6JlH5UkSZoVowZVvTVZw1J49c6vMMPXAKCqHjLofDeCtf1E7SVJkiRpqkZNVHF9d1xlSHnv/LBRqOm6hiRJkiTNiVGDqmuAG4H1hpSv3x0vG+cavbJRriFJkiRJc2Kk6X9VdWuSXzA8EUQv698F41ymVzbRNS6cYvckSVrQJrNBMLhgXpLm2nTsU3UasG6S7QaU7dJXZ5gfAlfT0h3fQZJVgScA51bVlaN2VJIkSZKm23TsU3UMsA9weJJn9ParSrItsDdwVpeNiyRHAY8AXl5V5wJU1bIkxwKvS7JXVX2i79pvAu4JHDAN/ZQkSZKmxbCRZEeOl6aRg6qq+nGSI4E3AGcmOQlYG3gBbdPNlwIkuRfwr12zl9ACsZ5DgacDH03yJNoGnY+g7THzDeC/Ru2nJEmSJM2E6Zj+R1W9kRYorUgbVXo+bcrfw3qjVMAVwFdoyS1OHtP+GuDRwNHATsBbgAcBbwV2qaqbp6OfkiRJkjTdpmP6HwBVdQxtKuCw8mLAuqm+8iuBf+kekiRJkrQgTMtIlSRJkiQtVQZVkiRJkjSCaZv+J0mSJC114+0vZ2bAxcuRKkmSJEkagSNVkiQtcON9M97jN+SSNHMcqZIkSZKkEUxLUJVktSQHJTkvyQ1J/pLkzCTPm2T7vZPUOI/PTkc/JUmSJGm6jTz9L8mDgS8A9wZOAY4H7gE8B/hokg2r6rBJXu6twFUDzl80aj8lSZIkaSZMx5qq7YDfAU+pqgt6J5McCZwPvCnJO6vqr5O41rFVdfE09EmSJEmSZsV0BFWnAp+oqpv7T1bV5Um+Ajwb2Br44TTcS5IkSVqQhiWVMZHMwjdyUFVVvxun+IZRry9JkiRJ89mMpVRPsiKwIy2wumCC6j0rJFm369cVVXXTTPVPkiRJkqbDTO5TtQ+wMfC+qrp+km0uAtL9+eYk3wIOr6pTJ9M4ydlDih588x+u5PJDjptkN6SF5cTrls11F6bs6quvBthkjrshaYlJshrwemBPYDPgFuCnwH9U1X+PqbsisC/wAmAj4DLgBODgqnI2jqTbzEhQlWRr4DDgt8BBk2hyMXAELaj6M7Au8AjaP3hfTfKyqjp6hC4t46Zb/nTzJZdd3P28VXc8f4RravJ8vWfYFXf8caG83pvQ/r5LmgVuEDy1jMVJQgugdu/qfgR4EC3IenSSJ4xdTy5p6Zr2oCrJqsCngZWBvarqmonaVNXpwOljTr8/yeHAGcC7kpxUVZdPcJ2HTLKPZ0+lvkbj6z27fL0laaipZCzegxZQfaCq9umrew7ti+BXAkfNZuclzV/TsvlvT/etzkeAbYE3VNUZo1yvqn4GvBNYDdhl9B5KkqQl7FTgCf0BFbSMxcBXaJ83tu5OvwK4EThgzDWOAn5PW+YgScA0B1W0zXv3pO039a5puuY53XGDabqeJElagqrqd+NM2bttjVSS1YFHAd8cO+OmqpbRpgNummSLmeqrpIVl2qb/JXkusD9tGt/Lpuu6wOrd8appvKYkSRIwMGPx/Wmfkc4d0qR3fhvaevDxrj0sidZWQ85LWoCmZaQqyWOBY4ALgd2meeHmHt3xm9N4TUmSpJ5exuJjuozFG3bnLx1Sv3d+o5numKSFYeSgKsnmwOeBa4GnV9XQ1EFJ9k3y/SRP7Du3QZIjktxtQP0X0KYTnlJVPx+1r5IkSf2GZCxeozteN6RZ7/zqQ8pvU1UPGfRg/mdolTQF0zH97xPA2sBngae1XBV38t2q+i5wMG0R6L8CX+/KArwWeGmSU4DzaHtGPA7YGfg58KJp6OdtzIo2u3y9Z9difL3dV0bSTBgnY3HvS+dhmwD2zq8wc72TtJBMR1C1Xnd8ZvcY5BDgu8AnaR+KPtsrqKrfJ3ko8CpgB+Dvu6JfAAcC766qa6ehn5IWIPeVkTQTxmQsfu2YjMXXd8dVhjTvnR82kiVpiRk5qKqqTaZQ98XAiwec/xHwwlH7ImlRcl8ZSTNhvIzFl3XH9Rhs/TH1JC1x051SXZKmm/vKSJpWk8hY3Pv3ZliGvm3G1JO0xBlUSZrX3FdG0nSaTMbiqroC+AmwY5KVB1xmF+BKhqdcl7TETNs+VZI0m9xXRtJUTSVjMXA08D7amszD+q7xItq/BUd2X9hIkkGVpAWrt6/M+6rq+iTuKyNpIlPJWHw08Czg0CTbA2cBDwD2omUqPmxQY0lLk0GVpAVnNvaVGXLfs4HtJ99TSfPMpDMWV9VNSXamZSLeE3g6cDnwAeCgqvrTTHdW0sKx5NZUJdk9yfeSXJfkj0mOT7LxXPdrMUjyoCSXJ6kkjx9SZ8Uk+yW5MMlfk1yS5B3dXiGahCSrJTkoyXlJbkjylyRnJnnegLqL7vV2XxlJy6uqNqmqTPA4uK/+9VW1X1VtVlV3raoNq+pVY9dtStKSCqqSvIo25L8a8DbafjfPAL5vYDWaJM8BvgHca5w6vT2EDqetaTkE+A5tvvrXkqw0C11d0Lo9m35Gy253EXAo8CHalLaPJtm/r+6ie73H7CvzBveVkSRJ88GSmf6X5L7AkcAPgB2q6obu/AnAGbTFqLvOXQ8XriSvp722n6etWxmWtto9hEa31Pdscl8ZSZI07yylkaqX0KYLHdgLqACq6kzgc8AzHK1abhcCO1XVbrQUs8O4h9DoluyeTe4rI0mS5qulFFQ9iZZ6+dQBZSd3xyfPXncWj6o6uaq+Pl4d9xCaHkt1zyb3lZEkSfPZUgqqHgCcV1W3DCjr379GM2NLJr+HkKZowJ5Ni+b1Xo59ZdahrRvrv0ZvX5lj3VdGkiRNtyWxpirJmsCauH/NXHIPoZm1mPdscl8ZSZI0ry2JoIpp3L9Gy833YIbM9J5N84D7ykiSpHltqQRV7l8z93wPZsBS2LOpqjaZYv3rgf26hyRJ0oxbKkGV+9fMPd+DaTZmz6bXumeTJEnS3FgqiSquoaWWdv+aueMeQtPPPZskSZLmgSURVFXVrcAvcP+aueQeQtPIPZskSZLmjyURVHVOA9ZNst2Asl366mgGuIfQ9HHPJkmSpPllKQVVxwAFHN7t6QNAkm2BvYGzqupHc9O1JcM9hEbknk2SJEnzz1JJVEFV/TjJkcAbgDOTnETb++YFwC3AS+ewe0uFewiNzj2bJEmS5pklE1QBVNUbk1wEvAI4gJYh7TRg/6o6f047twS4h9C0cM8mSZKkeWZJBVUAVXUMbSqgZkBVHQwcPE65ewiNwD2bJEmS5p+ltKZKkiRJkqadQZUkSZIkjcCgSpIkSZJGYFAlSZIkSSMwqJIkSZKkERhUSZIkSdIIDKokSZIkaQQGVZIkSZI0AoMqSZIkSRqBQZUkSZIkjcCgSpIkSZJGYFAlSZIkSSMwqJIkSZKkERhUSZIkSdIIDKokSZIkaQQGVZIkSZI0AoMqSZIkSRqBQZUkSZIkjcCgSpIkSZJGYFAlSZIkSSMwqJIkSZKkERhUSZr3kqyW5KAk5yW5IclfkpyZ5Hlj6u2dpMZ5fHaunoMkSVq8VpzrDkjSeJI8GPgCcG/gFOB44B7Ac4CPJtmwqg4b0+ytwFUDLnfRDHZVkiQtUQZVkua77YDfAU+pqgt6J5McCZwPvCnJO6vqr31tjq2qi2e3m5Ikaaly+p+k+e5U4An9ARVAVV0OfAVYDdh6LjomSZIEjlRJmueq6nfjFN8wax2RJEkawqBK0oKUZEVgR1pgdcGY4hWSrEv7N+6Kqrppitc+e0jRVlPuqCRJWvSc/idpodoH2Bg4pqquH1N2EXAZcClwbZLTkuw02x2UJElLgyNVkhacJFsDhwG/BQ7qK7oYOIIWVP0ZWBd4BLAn8NUkL6uqoye6flU9ZMh9zwa2H6nzkiRp0TGokrSgJFkV+DSwMrBXVV3TK6uq04HTxzR5f5LDgTOAdyU5qUtyIUmSNC2c/idpwUgS4CPAtsAbquqMybSrqp8B76RlCtxl5nooSZKWIoMqSQvJW2lT+Y6tqndNse053XGD6e2SJEla6gyqJC0ISZ4L7E+b3vey5bjE6t3xqunqkyRJEhhUSVoAkjwWOAa4ENitqm5ejsvs0R2/OW0dk7TgJNkuyYeT/DLJX5Nck+QbSfYcUHfFJPslubCre0mSd3RrOyXpNgZVkua1JJsDnweuBZ5eVVcPqbdBkiOS3G1A2Qto0wZPqaqfz2iHJc1bSZ4C/AD4e9oXLAcDxwLbACckeXNf3QAnAIfTMooeAnwH2Bf4WpKVZrPvkuY3s/9Jmu8+AawNfBZ4WvuccyffBX4DvBZ4aZJTgPOAW4DHATsDPwdeNBsdljRvrQ+8Fziwqq7tnewyhJ4LHJDkQ1V1GW10e3fgA1W1T1/dc2hbN7wSOGo2Oy9p/jKokjTfrdcdn9k9Bjmkqg5O8lDgVcAOtG+iAX4BHAi8u/9DlKQl6RNV9dGxJ6vqiiQn09Zrbg/8P+AVwI3AAWOqHwW8hrYBuUGVJMCgStI8V1WbTKHuj4AXzlhnJC1oVXXLOMXXdce/JFkdeBTwjf698LprLOtGw1+cZIuqumhmeitpITGokiRJS1q3FvMZwB+BHwJb0j4jnTukSe/8NrT1VuNd++whRVtNvaeS5iuDKkmStOQkWQPYDHgQbT3mxsCeVXVdkg27apcOad47v9HM9lLSQmFQJUmSlqJnAh/p/nwZsHNVnd79vEZ3vG5sozHnVx9Sfpuqesig890I1vaT6qmkec+U6pIkaSk6Dfgn4CDgeuDUJPt2Zb3PR8uGtO2dX2HmuidpIXGkSpIkLTlV9Rvalg0keTtwBnBEku/RgiyAVYY0750fNpIlaYlxpEqSJC1pVXUzcFj34+606YBw+5YOY63fHS8bUi5piTGokiRJanvaAdwHuKD787AMfdt0xwuGlEtaYgyqJEnSkpBknXGKN++Ov6+qK4CfADsmWXlA3V2AKxmecl3SEmNQJUmSloqTk7w8yR0STCRZCziy+/GE7ng0sA6w75i6L6KNYB1bVcMSWUhaYkxUIUmSlopzgQ8Cb0xyCnAJcG9gT9r6qbdV1Xe6ukcDzwIOTbI9cBbwAGAv4DxuX4MlSQZVkiRpaaiqlyf5AvBC4Om0QOoG4GzgpVX1hb66NyXZGTiQFnQ9Hbgc+ABwUFX9abb7L2n+MqiSJElLRlV9GfjyJOteD+zXPSRpKNdUSZIkSdIIDKokSZIkaQQGVZIkSZI0AoMqSZIkSRqBQZUkSZIkjcCgSpIkSZJGYFAlSZIkSSMwqJIkSZKkERhUSZIkSdIIDKokSZIkaQQGVZIkSZI0AoMqSZIkSRqBQZUkSZIkjcCgSpIkSZJGYFAlSZIkSSMwqJIkSZKkERhUSZIkSdIIDKokzXtJtkvy4SS/TPLXJNck+UaSPQfUXTHJfkku7OpekuQdSVadi75LkqTFb8W57oAkjSfJU4BTgGuAk4ELgHWBvYATkmxVVYd0dQOcAOzetfkI8CBgX+DRSZ5QVTfP+pOQpDvb5OY/XMnlhxw31/3QPHDidcvmugsCrr76aoBNlqetQZWk+W594L3AgVV1be9kksOBc4EDknyoqi4D9qAFVB+oqn366p4DHAG8EjhqNjsvSUP8mZtu4eZLLrsY2Ko7d/4c9kdz6Io7/ujvw9zZBPjz8jQ0qJI0332iqj469mRVXZHkZOBlwPbA/wNeAdwIHDCm+lHAa4B9MKiSNA9U1aa9Pyc5uzv3kLnrkeYLfx8WJtdUSZrXquqWcYqv645/SbI68Cjgm1V1zZhrLKNNB9w0yRYz0lFJkrRkOVIlaUFKcjfgGcAfgR8CW9L+TTt3SJPe+W2Aiya49tlDirYacl6SJC1hBlWSFowkawCb0ZJPvBbYGNizqq5LsmFX7dIhzXvnN5rZXkqSpKXGoErSQvJMWkY/gMuAnavq9O7nNbrjdWMbjTm/+kQ3GTaPvRvB2n5SPZUkSUuGa6okLSSnAf8EHARcD5yaZN+urPfv2bC8tL3zK8xc9yRJ0lLkSJWkBaOqfgN8AiDJ24EzgCOSfI8WZAGsMqR57/ywkSxJmhNmeVM/fx8WJkeqJC1I3Sa+h3U/7k6bDgiw3pAm63fHy4aUS5IkLReDKkkL2S+6432AC7o/D8vQt013vGBIuSRJ0nIxqJI0ryVZZ5zizbvj76vqCuAnwI5JVh5QdxfgSoanXJckSVouBlWS5ruTk7w8yR0STCRZCziy+/GE7ng0sA6w75i6L6KNYB3bbQQsSZI0bUxUIWm+Oxf4IPDGJKcAlwD3BvakrZ96W1V9p6t7NPAs4NAk2wNnAQ8A9gLO4/Y1WJIkSdPGoErSvFZVL0/yBeCFwNNpgdQNwNnAS6vqC311b0qyM3AgLeh6OnA58AHgoKr602z3X5IkLX4GVZLmvar6MvDlSda9Htive0iSJM0411RJkiTNoSS7J/lekuuS/DHJ8Uk2nut+afolWS3JQUnOS3JDkr8kOTPJ8wbUXTHJfkkuTPLXJJckeUeSVeei7xqfQZUkSdIcSfIq4LPAasDbgOOBZwDfN7BaXJI8GPgZcABwEXAo8CFgI+CjSfbvqxtaEqbDu7qHAN+hJWL6WpKVZrf3mojT/yRJkuZAkvvSspj+ANihqm7ozp8AnAG8D9h17nqoabYd8DvgKVV1256JSY4EzgfelOSdVfVXYA/axvYfqKp9+uqeAxwBvBI4ajY7r/E5UiVJkjQ3XgKsDBzYC6gAqupM4HPAMxytWlROBZ7QH1ABVNXlwFdoo5Vbd6dfAdxIG9XqdxTwe2AfNK8YVEmSJM2NJ9GymZ46oOzk7vjk2euOZlJV/a6qbh5SfFtQnWR14FHAN6vqmjHXWAacAmyaZIuZ6qumzqBKkiRpbjwAOK+qbhlQdm533GYW+6M5kGRFYEdaYHUBsCVtic65Q5r4uzEPGVRJkiTNsiRrAmsClw6p0ju/0ez0SHNoH2Bj4JhuW5ANu/P+biwgBlWSJEmzb43ueN2Q8t751WehL5ojSbYGDgN+CxzUnfZ3YwEyqJIkSZp9vc9gy4aU986vMAt90Rzo9pv6NC1ZyV5966f83ViATKkuSZI0+67vjqsMKe+dHzZaoQWs24fqI8C2wGur6oy+Yn83FiBHqiRJkmbfNbSU2esNKV+/O142K73RbHsrsCdwbFW9a0xZ7z33d2MBMaiSJEmaZVV1K/ALYKshVXqZ3S4YUq4FKslzgf2B04GXDajSe8/93VhADKokSZLmxmnAukm2G1C2S18dLRJJHgscA1wI7DZo36qqugL4CbBjkpUHXGYX4EqGp1zXHDCokiRJmhvHAAUc3u1VBECSbYG9gbOq6kdz0zVNtySbA58HrgWeXlVXj1P9aGAdYN8x13gRbQTr2G4jYM0TJqqQJEmaA1X14yRHAm8AzkxyErA28ALgFuClc9g9Tb9P0N7fzwJPa7kq7uS7VfVdWlD1LODQJNsDZ9E2i94LOI+Whl3ziEGVJEnSHKmqNya5CHgFcAAt89tpwP5Vdf6cdk7TrZd44pndY5BDaIHVTUl2Bg6kJbR4OnA58AHgoKr600x3VlNjUCVJkjSHquoY2lRALWJVtckU618P7Nc9NM+5pkqSJEmSRmBQJUmSJEkjMKiSJEmSpBEYVEmSJEnSCAyqJEmSJGkEBlWSJEmSNAKDKkmSJEkagUGVJEmSJI3AoEqSJEmSRmBQJUmSJEkjMKiSJEmSpBEYVEmSJEnSCAyqJEmSJGkEqaq57oMkLQhJrmTlFddaaYO157or0oy4+3XL5roLU3b11VezbNmyq6rKv5iS5oxBlSRNUpJfA2sCF/ed3qo7nj/rHVqafL1n10J4vTcB/lxVm851RyQtXQZVkjSCJGcDVNVD5rovS4Gv9+zy9ZakyXFNlSRJkiSNwKBKkiRJkkZgUCVJkiRJIzCokiRJkqQRGFRJkiRJ0gjM/idJkiRJI3CkSpIkSZJGYFAlSZIkSSMwqJIkSZKkERhUSZIkSdIIDKokSZIkaQQGVZIkSZI0AoMqSZIkSRqBQZUkLackuyf5XpLrkvwxyfFJNp7rfi0GSR6U5PIkleTxQ+qsmGS/JBcm+WuSS5K8I8mqs9vbhSnJakkOSnJekhuS/CXJmUmeN6Cur7UkjcPNfyVpOSR5FfAe4KfAp4B7AS8EbgAeVlWXzGH3FrQkzwHeB6zVnXpCVZ0+pk6AzwC7A6cA3wIeBOwJfKdrc/Ns9XmhSfJg4AvAvWmv3/eBewDP6c4dUFWHdXV9rSVpAgZVkjRFSe4L/BL4MbBDVd3QnX8kcAZwSlXtOoddXLCSvB44Evg8cCmwD4ODqmfRgtkPVNU+fef3BY4AXldVR81WvxeaJHsDLwZeVFUX9J1fFzgfuCuwdlX91ddakibm9D9JmrqXACsDB/YCKoCqOhP4HPAMpwEutwuBnapqN+DKceq9ArgROGDM+aOA39OCMQ13Ki1YvaD/ZFVdDnwFWA3Yujvtay1JEzCokqSpexJtmt+pA8pO7o5Pnr3uLB5VdXJVfX28OklWBx4FfLOqrhnTfhltitqmSbaYsY4ucFX1u3Gm7N32RYGvtSRNjkGVJE3dA4DzquqWAWXndsdtZrE/S82WwIrc/lqP5XuwnJKsCOxIC6wuwNdakibFoEqSpiDJmsCatPU+g/TObzQ7PVqSNuyOvgfTbx9gY+CYqroeX2tJmhSDKkmamjW643VDynvnV5+FvixVvgczIMnWwGHAb4GDutO+1pI0CQZVkjQ1vX83lw0p751fYRb6slT5Hkyzbr+pT9MSsOzVt37K11qSJmHFue6AJC0w13fHVYaU984P+2Zfo/M9mEbdPlQfAbYFXltVZ/QV+1pL0iQ4UiVJU3MNLb30ekPK1++Ol81Kb5am3mvrezA93krbyPfYqnrXmDJfa0maBIMqSZqCqroV+AWw1ZAqvSxoFwwp1+h6r63vwYiSPBfYHzgdeNmAKr7WkjQJBlWSNHWnAesm2W5A2S59dTQDquoK4CfAjklWHlBlF9rGwcPSgAtI8ljgGNqGy7sN2rfK11qSJsegSpKm7higgMO7fX0ASLItsDdwVlX9aG66tmQcDawD7Nt/MsmLaKMqx3ab02qAJJsDnweuBZ5eVVePU93XWpImkKqa6z5I0oKT5B3AG4AfACcBawMvoCUAeqxB1eiSHAy8GXhCVZ0+pmxl4FTgscCJwFm0TZn3An4OPLqq/jSb/V1IknwPeDjwWeDbQ6p9t6q+62stSRMzqJKk5ZTkxcAraN/WX09bl7J/VZ0/l/1aLMYLqrry1YADaUkW7gNcTht9OagvJbgGSHIxbZPf8RxSVQd39X2tJWkcBlWSJEmSNALXVEmSJEnSCAyqJEmSJGkEBlWSJEmSNAKDKkmSJEkagUGVJEmSJI3AoEqSJEmSRmBQJUmSJEkjMKiSJEmSpBEYVEmSJEnSCAyqJEmSJGkEBlWSJEmSNAKDKkmSJEkagUGVJEmSJI3AoEqSJEmSRmBQJUmSJEkjMKiSJEmSpBEYVEmSJEnSCAyqJEmSJGkE/x9rv6Z6euticwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 504x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "width": 426,
       "height": 208
      },
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "learning_rate = LearningRateScheduler(512)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                     beta_1=0.9,\n",
    "                                     beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "now_path = \"aiffel/Data/kor_en/\"\n",
    "path_to_enfile = \"data/kor_en/korean-english-park.train.en\"\n",
    "path_to_kofile = \"data/kor_en/korean-english-park.train.ko\"\n",
    "kor_path = now_path + path_to_enfile\n",
    "eng_path = now_path + path_to_kofile"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "\n",
    "# 데이터 정제\n",
    "def clean_corpus(kor_path, eng_path):\n",
    "    with open(kor_path, \"r\") as f: kor = f.readlines()\n",
    "    with open(eng_path, \"r\") as f: eng = f.readlines()\n",
    "    assert len(kor) == len(eng)\n",
    "    print(len(kor))\n",
    "    \n",
    "    dataset = set()\n",
    "    for i,j in zip(kor, eng):\n",
    "        i = preprocess_sentence(i)\n",
    "        j = preprocess_sentence(j)\n",
    "        dataset.add((i,j))\n",
    "    print(len(dataset))\n",
    "    cleaned_corpus = list(dataset)\n",
    "    return cleaned_corpus"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import re\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'([?!,.\"])', r' \\1 ',sentence)\n",
    "    sentence = re.sub(r'[^A-zㄱ-ㅎㅏ-ㅣ가-힣0-9?!,.\"]', ' ', sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', ' ',sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "cleaned_corpus = clean_corpus(kor_path, eng_path)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "94123\n",
      "78966\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "\n",
    "def generate_tokenizer(corpus,\n",
    "                       vocab_size,\n",
    "                       lang=\"ko\",\n",
    "                       pad_id=0,\n",
    "                       bos_id=1,\n",
    "                       eos_id=2,\n",
    "                       unk_id=3):\n",
    "    path = 'aiffel/Data/Model/transformer/'\n",
    "    temp_file = f'{path}corpus_{lang}.temp'\n",
    "    \n",
    "    with open(temp_file, 'w') as f:\n",
    "        for row in corpus:\n",
    "            f.write(str(row) + '\\n')\n",
    "    \n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f'--input={temp_file} --pad_id={pad_id} --bos_id={bos_id} --eos_id={eos_id} \\\n",
    "        --unk_id={unk_id} --model_prefix={path}spm_{lang} --vocab_size={vocab_size} --model_type=bpe'\n",
    "    )\n",
    "    \n",
    "    s = spm.SentencePieceProcessor()\n",
    "    s.Load(f'{path}spm_{lang}.model')\n",
    "    print(f\"{lang}-dict_num: {20000}\")\n",
    "\n",
    "    return s"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "eng, kor = zip(*cleaned_corpus)\n",
    "print(kor[0])\n",
    "ko = generate_tokenizer(kor,20000)\n",
    "en = generate_tokenizer(eng,20000, lang=\"en\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "올해 50세의 베어백 코치는 2002년 한일 월드컵에서 거스 히딩크 감독을 도와 대표팀의 4강 신화를 일궈낸 주역으로 , 잠시 휴식을 취한 후 업무를 시작할 예정이다 .  \n",
      "ko-dict_num: 20000\n",
      "en-dict_num: 20000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "def tokenize(corpus, tensorlen,voca_size):  # corpus: Tokenized Sentence's List\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=voca_size,filters='',)\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post',maxlen=tensorlen)\n",
    "\n",
    "    return tensor, tokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "\n",
    "path = 'aiffel/Data/Model/transformer/'\n",
    "temp_file = f'{path}corpus_ko.temp'\n",
    "ko_seq = []\n",
    "with open(temp_file,'r') as f:\n",
    "    for i in f.readlines():\n",
    "        ko_seq.append(ko.SampleEncodeAsPieces(i,1, 0.0))\n",
    "ko_tensor, ko_tokenizer = tokenize(ko_seq,50,20000)\n",
    "print(ko_seq[0])\n",
    "en_seq = []\n",
    "temp_file = f'{path}corpus_en.temp'\n",
    "with open(temp_file,'r') as f:\n",
    "    for i in f.readlines():\n",
    "        en_seq.append(en.SampleEncodeAsPieces(i,1, 0.0))\n",
    "en_tensor, en_tokenizer = tokenize(en_seq,50,20000)\n",
    "print(en_seq[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['▁올해', '▁50', '세의', '▁베어', '백', '▁코', '치는', '▁2002', '년', '▁한일', '▁월드컵', '에서', '▁거', '스', '▁히', '딩', '크', '▁감독을', '▁도와', '▁대표팀', '의', '▁4', '강', '▁신', '화를', '▁일', '궈', '낸', '▁주', '역', '으로', '▁,', '▁잠시', '▁휴식을', '▁취한', '▁후', '▁업무를', '▁시작할', '▁예정이다', '▁.']\n",
      "['▁ver', 'bee', 'k', '▁will', '▁start', '▁his', '▁new', '▁job', '▁after', '▁a', '▁short', '▁break', '▁from', '▁this', '▁weekend', '▁.']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "print(f\"ko dict voca: {len(ko_tokenizer.index_word)}\")\n",
    "print(f\"en dict voca: {len(en_tokenizer.index_word)}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ko dict voca: 20288\n",
      "en dict voca: 19065\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "print(len(ko_seq), len(en_seq))\n",
    "print(ko_seq[1], en_seq[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "78966 78966\n",
      "['▁내', '▁블로그에', '▁저장', '▁가상', '▁세계', '▁결혼', '관계가', '▁현실', '로'] ['▁she', '▁was', '▁about', '▁to', '▁meet', '▁someone', '▁she', '▁had', '▁been', '▁chatting', '▁with', '▁online', '▁since', '▁february', '▁.']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "en_tensor.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(78966, 50)"
      ]
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BUFFER_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = \\\n",
    "train_test_split(en_tensor, ko_tensor, test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train,dec_train))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)\n",
    "val_dataset = val_dataset.shuffle(BUFFER_SIZE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "val_dataset"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<BatchDataset shapes: ((64, 50), (64, 50)), types: (tf.int32, tf.int32)>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 50), (64, 50)), types: (tf.int32, tf.int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "train = dataset.__iter__()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "next(train)[0].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([64, 50])"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "transformer = Transformer(2,512,4,2048,20289,20001,50,shared=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 와... 위대하다.\n",
    "### 여기서 오류가 얼마나 떴는지 모르겠다.\n",
    "### super은 init이라는 메소드가 없다는 부분부터, pos가 정의되지 않았다는 내용 등등. 아주 뿌듯하다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "learning_rate = LearningRateScheduler(512)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "# ex = '''오바마는 대통령이다.\n",
    "# 시민들은 도시 속에 산다.\n",
    "# 커피는 필요 없다.\n",
    "# 일곱 명의 사망자가 발생했다.'''\n",
    "# ex = ex.split('\\n')\n",
    "# corpus = []\n",
    "# for i in ex:\n",
    "#     corpus.append(ko.SampleEncodeAsPieces(i,1, 0.0))\n",
    "# for i in corpus:\n",
    "#     print(i)\n",
    "# tensor = ko_tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "# tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post',maxlen=50)\n",
    "# print(tensor)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "\n",
    "examples = [\n",
    "            \"오바마는 대통령이다.\",\n",
    "            \"시민들은 도시 속에 산다.\",\n",
    "            \"커피는 필요 없다.\",\n",
    "            \"일곱 명의 사망자가 발생했다.\"\n",
    "]\n",
    "\n",
    "# Attention 시각화 함수\n",
    "\n",
    "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
    "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
    "        import seaborn\n",
    "        seaborn.heatmap(data, \n",
    "                        square=True,\n",
    "                        vmin=0.0, vmax=1.0, \n",
    "                        cbar=False, ax=ax,\n",
    "                        xticklabels=x,\n",
    "                        yticklabels=y)\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Encoder Layer\", layer + 1)\n",
    "        for h in range(4):\n",
    "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
    "        plt.show()\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Decoder Self Layer\", layer+1)\n",
    "        for h in range(4):\n",
    "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Decoder Src Layer\", layer+1)\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        for h in range(4):\n",
    "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
    "        plt.show()\n",
    "\n",
    "# 번역 생성 함수\n",
    "\n",
    "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
    "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "\n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tgt_tokenizer.eos_id() == predicted_id:\n",
    "            result = tgt_tokenizer.decode_ids(ids)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = tgt_tokenizer.decode_ids(ids)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "# 번역 생성 및 Attention 시각화 결합\n",
    "\n",
    "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    if plot_attention:\n",
    "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 문장이 짧아서 오히려 잘 안될지도 모른다는 걱정이 들지만, 논리적이지 않은 걱정인 것 같습니다..ㅎㅎ"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "        \n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "\n",
    "\n",
    "# def evaluate(tgt, model):\n",
    "#     ids = []\n",
    "#     output = tf.expand_dims([en.bos_id()], 0)\n",
    "\n",
    "#     for i in range(tgt.shape[-1]):\n",
    "#         enc_padding_mask, combined_mask, dec_padding_mask = generate_masks(corpus, output)\n",
    "    \n",
    "#         predict, _1, _2, _3 = model(corpus, output, enc_padding_mask, combined_mask, dec_padding_mask)\n",
    "\n",
    "#         predicted_id = tf.argmax(tf.math.softmax(predict, axis=-1)[0,-1]).numpy().item()\n",
    "\n",
    "#         if en.eos_id()== predicted_id:\n",
    "#             result = en.decode_ids(ids)\n",
    "#             return result, _1, _2, _3\n",
    "\n",
    "#         ids.append(predicted_id)\n",
    "#         output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "#     result = en.decode_ids(ids)\n",
    "\n",
    "#     return result, _1, _2, _3\n",
    "\n",
    "def eval_step(src,tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src,tgt)\n",
    "\n",
    "    predictions, enc_attns, dec_attns, dec_enc_attns = model(src,tgt,enc_mask, dec_enc_mask, dec_mask)\n",
    "    val_loss = loss_function(gold, predictions[:, :-1])\n",
    "    \n",
    "    \n",
    "    return val_loss, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    val_loss = 0\n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))[:-4]\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "    train = dataset.__iter__()\n",
    "    val = val_dataset.__iter__()\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(*next(train),\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "\n",
    "\n",
    "    idx_list = list(range(0, enc_val.shape[0], BATCH_SIZE))[:-4]\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "            eval_step(*next(val),\n",
    "                       transformer,\n",
    "                       optimizer)\n",
    "        \n",
    "        val_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (val_loss.numpy() / (batch + 1)))\n",
    "\n",
    "    for ex in examples:\n",
    "        translate(ex, transformer, ko, en)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78d34b61f22d45e0b7756e879dd5a4a5"
      },
      "text/plain": [
       "  0%|          | 0/984 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0fa130184454e55b7163a6110ba34b9"
      },
      "text/plain": [
       "  0%|          | 0/243 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: \n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: \n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: \n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f24580f4e20a481cbbef054de596bb04"
      },
      "text/plain": [
       "  0%|          | 0/984 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b412d69d56542ee8211bcec6edca917"
      },
      "text/plain": [
       "  0%|          | 0/243 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: were former\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: outr spreadreare medu wereity pydu a\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: were former\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: were former\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc212799d11d487390dcd297b42ab35c"
      },
      "text/plain": [
       "  0%|          | 0/984 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff9e04e7e3b048a89580b0c9ddda5371"
      },
      "text/plain": [
       "  0%|          | 0/243 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: were factare were factare were factareare py\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: were\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: were wereencencencencencencencenc tim sept sept sept were factare wereenc py\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: investments\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26803188a50b4b5eb319461203a793c5"
      },
      "text/plain": [
       "  0%|          | 0/984 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-2c0754707c0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m         train_step(*next(train),\n\u001b[1;32m     70\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                     optimizer)\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "interpreter": {
   "hash": "026aceb1435085fcef523649cdfc9385a4a55dbc5c65435142607853821fa50a"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}