{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 저번시간에 한 형태소 분석기를 잘 설치했다면 아래와 같은 내용은 쉽게 확인할 수 있을겁니다.\n",
    "### 클라우드에서는 어렵지 않으니, 해봐도 좋을 것 같아요ㅎㅎ\n",
    "### 신기하게도 맞춤법 오류등에 따라 서로 다른 성능을 보이는 것을 확인할 수 있습니다!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from konlpy.tag import Mecab, Hannanum\n",
    "hannanum = Hannanum()\n",
    "mecab = Mecab()\n",
    "text = '자연어처리가 너무재밌어서밥먹는것도가끔까먹어요'\n",
    "print(mecab.morphs(text))\n",
    "print(hannanum.morphs(text))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['자연어', '처리', '가', '너무', '재밌', '어서', '밥', '먹', '는', '것', '도', '가끔', '까먹', '어요']\n",
      "['자연어처리', '가', '너무재밌어서밥먹는것도가끔까먹어요']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### khaiii는 아래와 같이 만들어줘야 편하게 쓸 수 있어요!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from konlpy.tag import Hannanum,Kkma,Komoran,Mecab,Okt\n",
    "import khaiii\n",
    "import time\n",
    "\n",
    "api = khaiii.KhaiiiApi()\n",
    "api.open()\n",
    "\n",
    "class Khaiii():\n",
    "    def pos(self, phrase, flatten=True, join=False):\n",
    "        \"\"\"POS tagger.\n",
    "\n",
    "        :param flatten: If False, preserves eojeols.\n",
    "        :param join: If True, returns joined sets of morph and tag.\n",
    "\n",
    "        \"\"\"\n",
    "        sentences = phrase.split('\\n')\n",
    "        morphemes = []\n",
    "        if not sentences:\n",
    "            return morphemes\n",
    "\n",
    "        for sentence in sentences:\n",
    "            for word in api.analyze(sentence):\n",
    "                result = [(m.lex, m.tag) for m in word.morphs]\n",
    "                if join:\n",
    "                    result = ['{}/{}'.format(m.lex, m.tag) for m in word.morphs]\n",
    "\n",
    "                morphemes.append(result)\n",
    "\n",
    "        if flatten:\n",
    "            return sum(morphemes, [])\n",
    "\n",
    "        return morphemes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 여러가지 형태소 분석기를 비교해 봅니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "tokenizer_list = [Hannanum(),Kkma(),Komoran(),Mecab(),Okt(),Khaiii()]\n",
    "\n",
    "kor_text = '하... 잘좀하자 잘좀. 코로나바이러스는 2019년 12월 중국 우한에서 처음 발생한 뒤 전 세계로 확산된, 새로운 유형의 호흡기 감염 질환입니다.'\n",
    "\n",
    "for tokenizer in tokenizer_list:\n",
    "    st = time.time()\n",
    "    print('[{}] \\n{}'.format(tokenizer.__class__.__name__, tokenizer.pos(text + kor_text)))\n",
    "    print(time.time() - st)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Hannanum] \n",
      "[('자연어처리', 'N'), ('가', 'J'), ('너무재밌어서밥먹는것도가끔까먹어요하', 'N'), ('...', 'S'), ('잘좀하', 'N'), ('이', 'J'), ('자', 'E'), ('잘좀', 'N'), ('.', 'S'), ('코로나바이러스', 'N'), ('는', 'J'), ('2019년', 'N'), ('12월', 'N'), ('중국', 'N'), ('우한', 'N'), ('에서', 'J'), ('처음', 'M'), ('발생', 'N'), ('하', 'X'), ('ㄴ', 'E'), ('뒤', 'N'), ('전', 'N'), ('세계', 'N'), ('로', 'J'), ('확산', 'N'), ('되', 'X'), ('ㄴ', 'E'), (',', 'S'), ('새롭', 'P'), ('은', 'E'), ('유형', 'N'), ('의', 'J'), ('호흡기', 'N'), ('감염', 'N'), ('질환', 'N'), ('이', 'J'), ('ㅂ니다', 'E'), ('.', 'S')]\n",
      "1.9873437881469727\n",
      "[Kkma] \n",
      "[('자연어', 'NNG'), ('처리', 'NNG'), ('가', 'JKS'), ('너무', 'MAG'), ('재밌', 'VA'), ('어서', 'ECD'), ('밥', 'NNG'), ('먹', 'VV'), ('는', 'ETD'), ('것', 'NNB'), ('도', 'JX'), ('가끔', 'MAG'), ('까먹', 'VV'), ('어', 'ECD'), ('요하', 'NNG'), ('...', 'SE'), ('잘', 'MAG'), ('좀', 'MAG'), ('하', 'VV'), ('자', 'ECE'), ('잘', 'MAG'), ('좀', 'MAG'), ('.', 'SF'), ('코로나', 'NNG'), ('바', 'NNG'), ('이러', 'MAG'), ('슬', 'VV'), ('는', 'ETD'), ('2019', 'NR'), ('년', 'NNM'), ('12', 'NR'), ('월', 'NNM'), ('중국', 'NNG'), ('우', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('에', 'VV'), ('서', 'ECD'), ('처음', 'NNG'), ('발생', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('뒤', 'NNG'), ('전', 'NNG'), ('세계', 'NNG'), ('로', 'JKM'), ('확산', 'NNG'), ('되', 'XSV'), ('ㄴ', 'ETD'), (',', 'SP'), ('새', 'NNG'), ('롭', 'XSA'), ('ㄴ', 'ETD'), ('유형', 'NNG'), ('의', 'JKG'), ('호흡기', 'NNG'), ('감염', 'NNG'), ('질환', 'NNG'), ('이', 'VCP'), ('ㅂ니다', 'EFN'), ('.', 'SF')]\n",
      "23.717870235443115\n",
      "[Komoran] \n",
      "[('자연어', 'NNP'), ('처리', 'NNP'), ('가', 'JKS'), ('너무', 'MAG'), ('재밌', 'VA'), ('어서', 'EC'), ('밥', 'NNG'), ('먹', 'VV'), ('는', 'ETM'), ('것', 'NNB'), ('도', 'JX'), ('가끔', 'MAG'), ('까먹', 'VV'), ('어요', 'EC'), ('하', 'VX'), ('...', 'SE'), ('잘', 'MAG'), ('좀', 'MAG'), ('하', 'XSV'), ('자', 'EC'), ('잘', 'MAG'), ('좀', 'MAG'), ('.', 'SF'), ('코로나바이러스', 'NNP'), ('는', 'JX'), ('2019', 'SN'), ('년', 'NNB'), ('12월', 'NNP'), ('중국', 'NNP'), ('우', 'NNP'), ('한', 'NNP'), ('에서', 'JKB'), ('처음', 'NNG'), ('발생', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETM'), ('뒤', 'NNG'), ('전', 'MM'), ('세계로', 'NNP'), ('확산', 'NNG'), ('되', 'XSV'), ('ㄴ', 'ETM'), (',', 'SP'), ('새롭', 'VA'), ('ㄴ', 'ETM'), ('유형', 'NNP'), ('의', 'JKG'), ('호흡기', 'NNG'), ('감염', 'NNP'), ('질환', 'NNG'), ('이', 'VCP'), ('ㅂ니다', 'EF'), ('.', 'SF')]\n",
      "0.08722829818725586\n",
      "[Mecab] \n",
      "[('자연어', 'NNG'), ('처리', 'NNG'), ('가', 'JKS'), ('너무', 'MAG'), ('재밌', 'VA'), ('어서', 'EC'), ('밥', 'NNG'), ('먹', 'VV'), ('는', 'ETM'), ('것', 'NNB'), ('도', 'JX'), ('가끔', 'MAG'), ('까먹', 'VV'), ('어요', 'EF'), ('하', 'IC'), ('.', 'SF'), ('..', 'SY'), ('잘', 'MAG'), ('좀', 'MAG'), ('하', 'VV'), ('자', 'EC'), ('잘', 'MAG'), ('좀', 'MAG'), ('.', 'SF'), ('코로나', 'NNP'), ('바이러스', 'NNG'), ('는', 'JX'), ('2019', 'SN'), ('년', 'NNBC'), ('12', 'SN'), ('월', 'NNBC'), ('중국', 'NNP'), ('우한', 'NNP'), ('에서', 'JKB'), ('처음', 'NNG'), ('발생', 'NNG'), ('한', 'XSV+ETM'), ('뒤', 'NNG'), ('전', 'NNG'), ('세계', 'NNG'), ('로', 'JKB'), ('확산', 'NNG'), ('된', 'XSV+ETM'), (',', 'SC'), ('새로운', 'VA+ETM'), ('유형', 'NNG'), ('의', 'JKG'), ('호흡기', 'NNG'), ('감염', 'NNG'), ('질환', 'NNG'), ('입니다', 'VCP+EF'), ('.', 'SF')]\n",
      "0.06825757026672363\n",
      "[Okt] \n",
      "[('자연어', 'Noun'), ('처리', 'Noun'), ('가', 'Josa'), ('너무', 'Adverb'), ('재밌어서', 'Adjective'), ('밥', 'Noun'), ('먹는것도', 'Verb'), ('가끔', 'Noun'), ('까먹어', 'Verb'), ('요하', 'Noun'), ('...', 'Punctuation'), ('잘', 'VerbPrefix'), ('좀하자', 'Adjective'), ('잘', 'VerbPrefix'), ('좀', 'Adjective'), ('.', 'Punctuation'), ('코로나바이러스', 'Noun'), ('는', 'Josa'), ('2019년', 'Number'), ('12월', 'Number'), ('중국', 'Noun'), ('우한', 'Noun'), ('에서', 'Josa'), ('처음', 'Noun'), ('발생', 'Noun'), ('한', 'Josa'), ('뒤', 'Noun'), ('전', 'Noun'), ('세계', 'Noun'), ('로', 'Josa'), ('확산', 'Noun'), ('된', 'Verb'), (',', 'Punctuation'), ('새로운', 'Adjective'), ('유형', 'Noun'), ('의', 'Josa'), ('호흡기', 'Noun'), ('감염', 'Noun'), ('질환', 'Noun'), ('입니다', 'Adjective'), ('.', 'Punctuation')]\n",
      "10.696087837219238\n",
      "[Khaiii] \n",
      "[('자연어처리', 'NNG'), ('가', 'JKS'), ('너무재', 'MAG'), ('밌', 'VA'), ('어서', 'EC'), ('밥', 'NNG'), ('먹', 'VV'), ('는', 'ETM'), ('것', 'NNB'), ('도', 'JX'), ('가끔', 'MAG'), ('까먹', 'VV'), ('어', 'EC'), ('요', 'ZV'), ('하', 'VV'), ('...', 'SE'), ('잘좀', 'MAG'), ('하', 'XSV'), ('자', 'EC'), ('잘좀', 'MAG'), ('.', 'SF'), ('코', 'NNP'), ('로', 'NNG'), ('나', 'NNP'), ('바이러스', 'NNG'), ('는', 'JX'), ('2019', 'SN'), ('년', 'NNB'), ('12', 'SN'), ('월', 'NNB'), ('중국', 'NNP'), ('우', 'NNG'), ('한', 'NNP'), ('에서', 'JKB'), ('처음', 'NNG'), ('발생', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETM'), ('뒤', 'NNG'), ('전', 'MM'), ('세계', 'NNG'), ('로', 'JKB'), ('확산', 'NNG'), ('되', 'XSV'), ('ㄴ', 'ETM'), (',', 'SP'), ('새롭', 'VA'), ('ㄴ', 'ETM'), ('유형', 'NNG'), ('의', 'JKG'), ('호흡기', 'NNG'), ('감염', 'NNG'), ('질환', 'NNG'), ('이', 'VCP'), ('ㅂ니다', 'EF'), ('.', 'SF')]\n",
      "0.04337191581726074\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 저의 결론은 komoran과 mecab입니다. 이 두개를 써봐야겠어요.\n",
    "### hannanom도 괜찮아 보였는데, 띄어쓰기에 약하네요ㅜㅜ"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-12-10 11:39:22.166278: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-10 11:39:22.166383: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [여기](https://github.com/jungyeul/korean-parallel-corpora)보시면 말뭉치가 많아요!\n",
    "### 그중에 한국어 영어 번역을 학습시킬때 쓰는 말뭉치로 형태소 분석을 하겠습니다.\n",
    "### (우리말만 할거에요ㅎㅎ)\n",
    "```shell\n",
    "# 데이터를 받을 폴더에서 아래 명령을 하시면 데이터가 받아집니다.\n",
    "wget https://github.com/jungyeul/korean-parallel-corpora/raw/master/korean-english-news-v1/korean-english-park.train.tar.gz\n",
    "tar -xzvf korean-english-park.train.tar.gz\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import os\n",
    "path_to_file = 'data/kor_en/korean-english-park.train.ko'\n",
    "\n",
    "with open(path_to_file, \"r\") as f:\n",
    "    raw = f.read().splitlines()\n",
    "\n",
    "print(\"Data Size:\", len(raw))\n",
    "\n",
    "print(\"Example:\")\n",
    "for sen in raw[0:100][::20]: print(\">>\", sen)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data Size: 94123\n",
      "Example:\n",
      ">> 개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"\n",
      ">> 북한의 핵무기 계획을 포기하도록 하려는 압력이 거세지고 있는 가운데, 일본과 북한의 외교관들이 외교 관계를 정상화하려는 회담을 재개했다.\n",
      ">> \"경호 로보트가 침입자나 화재를 탐지하기 위해서 개인적으로, 그리고 전문적으로 사용되고 있습니다.\"\n",
      ">> 수자원부 당국은 논란이 되고 있고, 막대한 비용이 드는 이 사업에 대해 내년에 건설을 시작할 계획이다.\n",
      ">> 또한 근력 운동은 활발하게 걷는 것이나 최소한 20분 동안 뛰는 것과 같은 유산소 활동에서 얻는 운동 효과를 심장과 폐에 주지 않기 때문에, 연구학자들은 근력 운동이 심장에 큰 영향을 미치는지 여부에 대해 논쟁을 해왔다.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 이렇게 한국어 데이터를 받아왔어요.\n",
    "### 데이터의 분포를 눈으로 봐볼게요!\n",
    "### 최소길이 문장, 최대길이 문장, 문장 길이별 분포를 봐볼거에요.\n",
    "### 잠시 후 그 강력함을 볼 수 있어요."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in raw:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(raw))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in raw:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 377\n",
      "문장의 평균 길이: 60\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 모든 자연스러운 데이터 분포는 정규분포를 따라요. 여기서 특정 문장길이만 특별히 높게나온건 매우 수상합니다!\n",
    "### 해당 길이 문장을 출력해볼게요!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def check_sentence_with_length(raw, length):\n",
    "    count = 0\n",
    "    \n",
    "    for sen in raw:\n",
    "        if len(sen) == length:\n",
    "            print(sen)\n",
    "            count += 1\n",
    "            if count > 100: return\n",
    "\n",
    "check_sentence_with_length(raw, 1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "’\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 길이 1짜리 문장도 이상해서 시험삼아 출력해봤는데, 무의미한 문장입니다;;"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "for idx, _sum in enumerate(sentence_length):\n",
    "    # 문장의 수가 1500을 초과하는 문장 길이를 추출합니다.\n",
    "    if _sum > 1500:\n",
    "        print(\"Outlier Index:\", idx+1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Outlier Index: 11\n",
      "Outlier Index: 19\n",
      "Outlier Index: 21\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "check_sentence_with_length(raw, 11)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "라고 조던이 말했다.\n",
      "- 모르고 있습니다.\n",
      "- 네, 보이는군요.\n",
      "디즈니사만이 아니다.\n",
      "큰 파티는 아니지요.\n",
      "의자는 비어 있었다.\n",
      "이 일은 계속됩니다.\n",
      "나는 크게 실망했다.\n",
      "그 이유는 간단하다.\n",
      "이력서와 자기 소개서\n",
      "시대가 변하고 있다.\n",
      "는 돌발질문을 했다.\n",
      "9. 몇 분간의 명상\n",
      "하와이, 빅 아일랜드\n",
      "키스를 잘 하는 방법\n",
      "키스를 잘 하는 방법\n",
      "스피어스가 뚱뚱한가?\n",
      "산 위를 나는 느낌.\n",
      "세 시간쯤 걸었을까?\n",
      "(아직 읽고있습니까?\n",
      "처음에는 장난이었다.\n",
      "우리는 운이 좋았다.\n",
      "아기가 숨을 멈출 때\n",
      "건물 전체 무너져내려\n",
      "그녀의 아름다운 눈.\n",
      "대답은 다음과 같다.\n",
      "\"사과할 것이 없다.\n",
      "폭탄테러가 공포 유발\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "그는 \"잘 모르겠다.\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n",
      "더 내려야 하는 이유\n",
      "조금은 새침한 샬롯？\n",
      "조금은 새침한 샬롯？\n",
      "케냐 야생동물 고아원\n",
      "경유 1200원대로…\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "cleaned_corpus = list(set(raw))  # set를 사용해서 중복을 제거합니다.\n",
    "print(\"Data Size:\", len(cleaned_corpus))\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(cleaned_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in cleaned_corpus:   # 중복이 제거된 코퍼스 기준\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data Size: 77591\n",
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 377\n",
      "문장의 평균 길이: 64\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZ9klEQVR4nO3df5RcZZ3n8ffHBAKCk/CjNwNJ1g5jBhc5DmILcWQdjnEgIWJYD7JxWY2YOVlmYRZHGQiyR9D1R3AcGZlhYKOJBGX5MSgSJ3EkA8xxHZdIRyEkRKSFQDoE0kACCIoEvvvHfSpeiv5d1VXV9Xxe59TpW8996rnfvt39qXufe7tbEYGZmeXhdc0uwMzMGsehb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+WZ1J6pQUkibWccwzJd1Wx/E2SzoxLV8q6Vt1HPtTkr5er/Gsvhz6bU7SCZJ+LOkZSU9L+jdJ76jDuB+V9KN61FhPkrZKeu942qakayT9VtJz6bFJ0hclTa70iYjrIuKkYY71uaH6RcRbIuJfR1tzaXsnSuqtGvsLEfFntY5tY8Oh38Yk/R7wT8DfAQcD04DPAC82sy7r15ci4g1AB3AWMBv4N0kH1HMj9Tz7sPHJod/e/hAgIq6PiJcj4tcRcVtEbKx0kPQxSVsk7ZL0A0lvLK0LSWdLelDSbklXqvAfgKuBd0r6laTdqf8kSV+W9KikJyRdLWn/tO5ESb2SPilpp6Qdks4qbWt/SX8j6ZF0VvKj0mtnp7OV3ZLurUxLjISk10laKumXkp6SdJOkg9O6ynTMolT7k5IurqptVdpHWyRdUDm6lfRN4N8D30v74oLSZs/sb7zBRMRvIuJu4P3AIRRvAK86s0pfg8vTfnxW0n2Sjpa0BDgTuCDV8r3Uf6ukCyVtBJ6XNLGfs5P9JN2YzjR+KumPSp9/SHpT6fk1kj6X3pC+DxyetvcrSYerarpI0vtVTCftlvSv6funsm6rpPMlbUxf9xsl7TecfWWj49Bvb78AXk6BNU/SQeWVkhYAnwI+QHGE+X+B66vGeB/wDuCtwBnAyRGxBTgb+H8RcWBETEl9l1G80RwDvInizOLTpbF+H5ic2hcDV5Zq+jLwduCPKc5KLgBekTQNWAN8LrWfD3xbUscI98VfAKcBfwIcDuwCrqzqcwJwJDAH+HQpnC4BOoEjgD8F/mvlBRHxYeBR4NS0L740jPGGFBHPAeuA/9jP6pOAd1Ps68kUX5enImI5cB3FWcOBEXFq6TUfAuYDUyJiTz9jLgD+kWIf/x/gu5L2GaLG54F5wGNpewdGxGPlPpL+kOJ76uMU32NrKd4g9y11OwOYC8yk+D776GDbtdo49NtYRDxLETwBfA3ok7Ra0tTU5WzgixGxJQXBF4Bjykf7wLKI2B0RjwJ3UgT6a0gSsAT4y4h4OoXWF4CFpW4vAZ+NiJciYi3wK+BISa8DPgacFxHb01nJjyPiRYqAXRsRayPilYhYB3QDp4xwd5wNXBwRvWncS4HT9erpjs+ks6F7gXuBytHuGcAXImJXRPQCVwxzmwONN1yPUYRwtZeANwBvBpS+fjuGGOuKiNgWEb8eYP2GiLg5Il4CvgLsRzHFVKv/DKyJiHVp7C8D+1O8uZdreywinga+xwDfY1YfDv02lwLhoxExHTia4ij3b9PqNwJfTafdu4GnAVEciVc8Xlp+AThwgE11AK8HNpTG++fUXvFU1VFmZbxDKULml/2M+0bgg5Ux07gnAIcN9nkPMM4tpTG2AC8DU0t9BvpcDwe2ldaVlwcz3H03kGkUX5NXiYg7gL+nOFPZKWm5ius3gxmq5r3rI+IVoJfi867V4cAjVWNvY3TfY1YHDv2MRMTPgWsowh+KH77/FhFTSo/9I+LHwxmu6vmTwK+Bt5TGmhwRw/kBfhL4DfAH/azbBnyzqsYDImLZMMatHmde1Tj7RcT2Ybx2BzC99HxG1fq6/6laSQcC76WYcnuNiLgiIt4OHEUxzfNXQ9QyVI17P6d05jWd4kwDiiB+fanv749g3Mco3nArYyttazj73caAQ7+NSXpzunA6PT2fQTG3e1fqcjVwkaS3pPWTJX1wmMM/AUyvzM2mI7ivAZdL+ndpvGmSTh5qoPTalcBX0oXACZLeKWkS8C3gVEknp/b9VFwUnj7IkPukfpXHxPS5fr4ydSWpI13TGI6bKPbTQekaw7n97IsjhjnWoFRcDH878F2K6w7f6KfPOyQdn+bcn6d4w3ylxlreLukDaV99nOIOr8r3yT3Af0n7fy7FdZGKJ4BDVLq9tMpNwHxJc1K9n0xjD+fAwsaAQ7+9PQccD6yX9DzFD/Emih88IuIW4DLgBknPpnXzhjn2HcBm4HFJT6a2C4Ee4K403r9QXMgcjvOB+4C7KaY0LgNeFxHbKC4yfgroozhi/ysG/95dS3HWUXlcCnwVWA3cJuk5in1x/DBr+yzFdMfD6XO6mVff9vpF4H+mqaPzhzlmtQtSXU8B1wIbgD9OF0ur/R7FG+wuiqmTp4C/TutWAEelWr47gu3fSjH/vgv4MPCBNAcPcB5wKrCb4u6gveOms8frgYfSNl81JRQRD1Bcl/k7ijO6Uykuev92BLVZHcn/RMVsZCT9ObAwIv5kyM5mLcZH+mZDkHSYpHepuNf/SIozpVuaXZfZaPi388yGti/wvynuI98N3AD8QzMLMhstT++YmWXE0ztmZhlp6emdQw89NDo7O5tdhpnZuLJhw4YnI6LfP1XS0qHf2dlJd3d3s8swMxtXJD0y0DpP75iZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcSh32I6l65pdglm1sYc+mZmGRky9CWtlLRT0qZS219L+rmkjZJukTSltO4iST2SHij/f1RJc1Nbj6Sldf9MzMxsSMM50r8GmFvVtg44OiLeCvwCuAhA0lHAQuAt6TX/kP6Z8gTgSor/v3oU8KHU14bg6R4zq6chQz8ifkjxj6rLbbdFxJ709C5gelpeANwQES9GxMMU/yT7uPToiYiH0j9EviH1NTOzBqrHnP7HgO+n5WnAttK63tQ2UPtrSFoiqVtSd19fXx3Ka30+mjezRqkp9CVdDOwBrqtPORARyyOiKyK6Ojr6/R8A2ai8GfhNwczqZdShL+mjwPuAM+N3/2h3OzCj1G16ahuo3ZLqYHfQm9lYGFXoS5oLXAC8PyJeKK1aDSyUNEnSTGAW8BPgbmCWpJmS9qW42Lu6ttLbg8PdzBppyH+XKOl64ETgUEm9wCUUd+tMAtZJArgrIs6OiM2SbgLup5j2OSciXk7jnAv8AJgArIyIzWPw+ZiZ2SCGDP2I+FA/zSsG6f954PP9tK8F1o6oOutX59I1bF02v9llmNk45N/INTPLiEPfzCwjDn0zs4w49FuQ7+gxs7Hi0B8n/EZgZvXg0Dczy4hD38wsIw79FuIpHDMbaw59M7OMOPTNzDLi0G8iT+eYWaM59M3MMuLQH0d8ZmBmtXLoN8loA9zBb2a1cOibmWXEod8E9Tha9xG/mY2GQ9/MLCMO/Qby0bmZNZtD38wsIw79cc5nD2Y2Eg59M7OMOPTNzDLi0G8wT8eYWTM59Mcxv4GY2Ug59BvA4WxmrWLI0Je0UtJOSZtKbQdLWifpwfTxoNQuSVdI6pG0UdKxpdcsSv0flLRobD4dMzMbzHCO9K8B5la1LQVuj4hZwO3pOcA8YFZ6LAGuguJNArgEOB44Drik8kZhZmaNM2ToR8QPgaermhcAq9LyKuC0Uvu1UbgLmCLpMOBkYF1EPB0Ru4B1vPaNpK15isfMWsFo5/SnRsSOtPw4MDUtTwO2lfr1praB2l9D0hJJ3ZK6+/r6RlmemZn1p+YLuRERQNShlsp4yyOiKyK6Ojo66jWsmZkx+tB/Ik3bkD7uTO3bgRmlftNT20DtZmbWQKMN/dVA5Q6cRcCtpfaPpLt4ZgPPpGmgHwAnSTooXcA9KbW1Pc/lm1krmThUB0nXAycCh0rqpbgLZxlwk6TFwCPAGan7WuAUoAd4ATgLICKelvS/gLtTv89GRPXF4bbTyMCvbGvrsvkN26aZjT9Dhn5EfGiAVXP66RvAOQOMsxJYOaLqbFh8NmFmw+XfyDUzy4hD38wsIw59M7OMOPTNzDLi0B8jvrhqZq3IoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHfhvynUNmNhCHvplZRhz6ZmYZceibmWXEoW9mlhGHfp35IqqZtTKHfpvxm46ZDcahb2aWEYe+mVlGHPpmZhlx6JuZZcSh38Z8UdfMqjn025QD38z649AfAw5cM2tVNYW+pL+UtFnSJknXS9pP0kxJ6yX1SLpR0r6p76T0vCet76zLZ2CD8huQmZWNOvQlTQP+B9AVEUcDE4CFwGXA5RHxJmAXsDi9ZDGwK7VfnvqZmVkD1Tq9MxHYX9JE4PXADuA9wM1p/SrgtLS8ID0nrZ8jSTVu38zMRmDUoR8R24EvA49ShP0zwAZgd0TsSd16gWlpeRqwLb12T+p/SPW4kpZI6pbU3dfXN9ryzMysH7VM7xxEcfQ+EzgcOACYW2tBEbE8Iroioqujo6PW4czMrKSW6Z33Ag9HRF9EvAR8B3gXMCVN9wBMB7an5e3ADIC0fjLwVA3bNzOzEaol9B8FZkt6fZqbnwPcD9wJnJ76LAJuTcur03PS+jsiImrYfsvxnTJm1upqmdNfT3FB9qfAfWms5cCFwCck9VDM2a9IL1kBHJLaPwEsraFuMzMbhYlDdxlYRFwCXFLV/BBwXD99fwN8sJbtmZlZbfwbuWZmGXHom5llxKGfgc6la3yR2cwAh76ZWVYc+nXiI2kzGw8c+mZmGXHom5llxKFvZpYRh76ZWUYc+jXwxVszG28c+mZmGXHom5llxKFvZpYRh34deG7fzMYLh76ZWUYc+mZmGXHom5llxKGfEf+JZTNz6GfIwW+WL4d+jRygZjaeOPTNzDLi0Dczy4hDP3OenjLLi0M/Uw57szw59M3MMlJT6EuaIulmST+XtEXSOyUdLGmdpAfTx4NSX0m6QlKPpI2Sjq3Pp9Ac7XCk3A6fg5mNTK1H+l8F/jki3gz8EbAFWArcHhGzgNvTc4B5wKz0WAJcVeO2zcxshEYd+pImA+8GVgBExG8jYjewAFiVuq0CTkvLC4Bro3AXMEXSYaPdvpmZjVwtR/ozgT7gG5J+Junrkg4ApkbEjtTncWBqWp4GbCu9vje1vYqkJZK6JXX39fXVUJ6ZmVWrJfQnAscCV0XE24Dn+d1UDgAREUCMZNCIWB4RXRHR1dHRUUN5Y8dz4WY2XtUS+r1Ab0SsT89vpngTeKIybZM+7kzrtwMzSq+fntrMzKxBRh36EfE4sE3SkalpDnA/sBpYlNoWAbem5dXAR9JdPLOBZ0rTQGZm1gATa3z9XwDXSdoXeAg4i+KN5CZJi4FHgDNS37XAKUAP8ELqay2gc+kati6b3+wyzKwBagr9iLgH6Opn1Zx++gZwTi3bMzOz2vg3cs3MMuLQNzPLiEPfzCwjDn0zs4w49EfIv5hlZuOZQ98Av5mZ5cKhb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6Ntr+J59s/bl0Le9HPZm7c+hb2aWEYe+mVlGHPoj4OkPMxvvav0fuVlw2JtZu/CRvplZRhz69io+qzFrbw59M7OMOPTNzDLi0B+CpzvMrJ3UHPqSJkj6maR/Ss9nSlovqUfSjZL2Te2T0vOetL6z1m3b2PGbnVl7qseR/nnAltLzy4DLI+JNwC5gcWpfDOxK7ZenfmZm1kA1hb6k6cB84OvpuYD3ADenLquA09LygvSctH5O6m9mZg1S65H+3wIXAK+k54cAuyNiT3reC0xLy9OAbQBp/TOpv5mZNcioQ1/S+4CdEbGhjvUgaYmkbkndfX199RzaRsjz+mbtp5Yj/XcB75e0FbiBYlrnq8AUSZU/7zAd2J6WtwMzANL6ycBT1YNGxPKI6IqIro6OjhrKMzOzaqMO/Yi4KCKmR0QnsBC4IyLOBO4ETk/dFgG3puXV6Tlp/R0REaPdvpmZjdxY3Kd/IfAJST0Uc/YrUvsK4JDU/glg6Rhs28zMBqFWPtju6uqK7u7upm3fc9qFrcvmN7sEMxsBSRsioqu/df6NXDOzjDj0zcwy4tC3IXmay6x9OPTNzDLi0Ldh8dG+WXtw6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb8PmO3jMxr+JQ3fJj8PNzNqVj/TNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0LcR8Z1NZuObQ9/MLCMOfRsVH/GbjU8OfTOzjDj0q/gI1szamUPfRsxvjGbjl0PfzCwjDn0zs4yMOvQlzZB0p6T7JW2WdF5qP1jSOkkPpo8HpXZJukJSj6SNko6t1ydhzdG5dI2neszGmVqO9PcAn4yIo4DZwDmSjgKWArdHxCzg9vQcYB4wKz2WAFfVsG0zMxuFUYd+ROyIiJ+m5eeALcA0YAGwKnVbBZyWlhcA10bhLmCKpMNGu/2x4KPW0ansN+8/s9ZXlzl9SZ3A24D1wNSI2JFWPQ5MTcvTgG2ll/WmtuqxlkjqltTd19dXj/LMzCypOfQlHQh8G/h4RDxbXhcRAcRIxouI5RHRFRFdHR0dtZZnDeajfbPWVlPoS9qHIvCvi4jvpOYnKtM26ePO1L4dmFF6+fTUZm3AYW82PtRy946AFcCWiPhKadVqYFFaXgTcWmr/SLqLZzbwTGkayMzMGqCWf4z+LuDDwH2S7kltnwKWATdJWgw8ApyR1q0FTgF6gBeAs2rYtpmZjcKoQz8ifgRogNVz+ukfwDmj3Z6ZmdXOv5FrZpYRh37iC5FmlgOHvtWdf1nLrHU59G1MOPDNWpND38aUw9+stTj0cTA1gvexWWtw6JuZZcShb2aWkexD39MOZpaT7EPfxp7fWM1ah0PfGsb375s1n0PfzCwjDn0zs4w49K2hPMVj1lwOfTOzjDj0zcwykm3oe3qhNXi6x6yxsg19cNA0mwPfrPGyDn1rTX4TMBs7tfxjdLO6ctibjT2HvrWk6jeArcvmN6kSs/aS5fSOjyjHH3/NzOojy9C38cnBb1a7LELfd4m0l86la17ztfTX1mx4spvTdziMb+WvX2W5Mt9fXudrAGb9a/iRvqS5kh6Q1CNp6Vhvz0f57a+/r23lbGCgdQO9zqzdNfRIX9IE4ErgT4Fe4G5JqyPi/rHYnn+oDWr7PuhcusZnDdZWGj29cxzQExEPAUi6AVgAjEnomw1kJEf7g/XZumz+gLeXlt8wKsvVH6v7Dbf2wfrXezxrL4qIxm1MOh2YGxF/lp5/GDg+Is4t9VkCLElPjwQeqGGThwJP1vD6sdbq9UHr19jq9UHr1+j6atdqNb4xIjr6W9FyF3IjYjmwvB5jSeqOiK56jDUWWr0+aP0aW70+aP0aXV/txkONFY2+kLsdmFF6Pj21mZlZAzQ69O8GZkmaKWlfYCGwusE1mJllq6HTOxGxR9K5wA+ACcDKiNg8hpusyzTRGGr1+qD1a2z1+qD1a3R9tRsPNQINvpBrZmbNlcWfYTAzs4JD38wsI20b+o3+cw/DIWmrpPsk3SOpO7UdLGmdpAfTx4MaWM9KSTslbSq19VuPClek/blR0rFNrPFSSdvTfrxH0imldRelGh+QdHID6psh6U5J90vaLOm81N4S+3GQ+lppH+4n6SeS7k01fia1z5S0PtVyY7r5A0mT0vOetL6zSfVdI+nh0j48JrU35Wdl2CKi7R4UF4l/CRwB7AvcCxzVAnVtBQ6tavsSsDQtLwUua2A97waOBTYNVQ9wCvB9QMBsYH0Ta7wUOL+fvkelr/UkYGb6HpgwxvUdBhyblt8A/CLV0RL7cZD6WmkfCjgwLe8DrE/75iZgYWq/GvjztPzfgavT8kLgxibVdw1wej/9m/KzMtxHux7p7/1zDxHxW6Dy5x5a0QJgVVpeBZzWqA1HxA+Bp4dZzwLg2ijcBUyRdFiTahzIAuCGiHgxIh4Geii+F8ZMROyIiJ+m5eeALcA0WmQ/DlLfQJqxDyMifpWe7pMeAbwHuDm1V+/Dyr69GZgjSU2obyBN+VkZrnYN/WnAttLzXgb/Rm+UAG6TtCH9uQmAqRGxIy0/DkxtTml7DVRPq+3Tc9Op88rSlFhTa0zTDG+jOBJsuf1YVR+00D6UNEHSPcBOYB3FGcbuiNjTTx17a0zrnwEOaWR9EVHZh59P+/BySZOq6+un9qZr19BvVSdExLHAPOAcSe8ur4zi3LBl7qFttXpKrgL+ADgG2AH8TVOrASQdCHwb+HhEPFte1wr7sZ/6WmofRsTLEXEMxW/pHwe8uZn1VKuuT9LRwEUUdb4DOBi4sHkVDl+7hn5L/rmHiNiePu4EbqH45n6icuqXPu5sXoUwSD0ts08j4on0Q/gK8DV+N/3QlBol7UMRqNdFxHdSc8vsx/7qa7V9WBERu4E7gXdSTItUfoG0XMfeGtP6ycBTDa5vbpo6i4h4EfgGLbIPh9Kuod9yf+5B0gGS3lBZBk4CNqW6FqVui4Bbm1PhXgPVsxr4SLozYTbwTGn6oqGq5kf/E8V+hKLGhenujpnALOAnY1yLgBXAloj4SmlVS+zHgeprsX3YIWlKWt6f4v9tbKEI19NTt+p9WNm3pwN3pLOpRtb389KbuiiuN5T3YUv8rPSr2VeSx+pBcQX9FxRzgxe3QD1HUNwVcS+wuVITxVzk7cCDwL8ABzewpuspTu1foph3XDxQPRR3IlyZ9ud9QFcTa/xmqmEjxQ/YYaX+F6caHwDmNaC+EyimbjYC96THKa2yHwepr5X24VuBn6VaNgGfTu1HULzh9AD/CExK7ful5z1p/RFNqu+OtA83Ad/id3f4NOVnZbgP/xkGM7OMtOv0jpmZ9cOhb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlG/j+E+F/k4g/h4QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 신기하게 중복데이터만 제거해주었을 뿐인데, 데이터가 정규분포에 가까워졌죠?\n",
    "### 확률시간에 배우는 큰 수의 법칙과 일맥상통하는 현상입니다.\n",
    "### 이제 저는 로컬에서 할 수 있게 문장길이 100개 까지만 볼거에요ㅋㅋ\n",
    "### 사실 그렇게 하면 데이터는 거의다 보면서, 계산량은 매우 많이 줄일 수 있어요."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "max_len = 100\n",
    "min_len = 10\n",
    "\n",
    "# 길이 조건에 맞는 문장만 선택합니다.\n",
    "filtered_corpus = [s for s in cleaned_corpus if (len(s) < max_len) & (len(s) >= min_len)]\n",
    "\n",
    "# 분포도를 다시 그려봅니다.\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in filtered_corpus:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYvklEQVR4nO3dfZQcVZnH8e8PgrxqAiEbw0xgcIm4keMLjBCFVQ5hNeHFcDyIIIsB4smyBxVfIegeUVcxKAuCi7iRIEGRF1EgSlaJAY7rC8gEkbeIRAxkQiADJIAgQuTZP+pOLJqZzEx3T/dM39/nnD5Tdev2rVtdM0/deqq6RhGBmZnlYYtmd8DMzBrHQd/MLCMO+mZmGXHQNzPLiIO+mVlGHPTNzDLioG9WZ5I6JIWkMXVs81hJN9SxvXskHZimPyfpu3Vs+9OSLqpXe1ZfDvotTtIBkn4l6UlJT0j6paS31KHd4yX9oh59rCdJqyQdPJrWKekSSc9Lejq97pb0ZUlje+tExGUR8c5BtvXFgepFxOsj4uZq+1xa34GSuivaPjMiPlhr2zY8HPRbmKRXAT8Gvg7sBLQBnwf+2sx+WZ++EhGvBCYAJwDTgF9K2r6eK6nn2YeNTg76re21ABFxeUT8LSL+EhE3RMSdvRUknShphaT1kn4qabfSspB0kqT7JW2QdIEK/wR8E3irpD9L2pDqby3pbEkPSXpU0jclbZuWHSipW9InJK2TtFbSCaV1bSvpvyQ9mM5KflF677R0trJB0u960xJDIWkLSfMk/VHS45KukrRTWtabjpmd+v6YpM9U9G1R+oxWSDq1d3Qr6TvArsCP0mdxamm1x/bV3uZExHMRcRvwbmA8xQHgJWdWaR+cmz7HpyTdJWkvSXOBY4FTU19+lOqvknSapDuBZySN6ePsZBtJV6YzjdslvbG0/SFpj9L8JZK+mA5I/wvsktb3Z0m7qCJdJOndKtJJGyTdnH5/epetkvRJSXem/X6lpG0G81lZdRz0W9sfgL+lgDVT0o7lhZJmAZ8G3kMxwvw/4PKKNg4D3gK8ATgKeFdErABOAn4dETtExLhUdz7FgeZNwB4UZxafLbX1amBsKp8DXFDq09nAPsDbKM5KTgVelNQGXA98MZV/EviBpAlD/Cw+DBwBvAPYBVgPXFBR5wBgT2A68NlScDoD6ABeA/wL8K+9b4iI44CHgMPTZ/GVQbQ3oIh4GlgK/HMfi98JvJ3isx5LsV8ej4gFwGUUZw07RMThpfccAxwKjIuIjX20OQv4PsVn/D3gWklbDdDHZ4CZwMNpfTtExMPlOpJeS/E79VGK37ElFAfIV5SqHQXMAHan+D07fnPrtdo46LewiHiKIvAE8C2gR9JiSRNTlZOAL0fEihQIzgTeVB7tA/MjYkNEPATcRBHQX0aSgLnAxyLiiRS0zgSOLlV7AfhCRLwQEUuAPwN7StoCOBE4JSLWpLOSX0XEXykC7JKIWBIRL0bEUqALOGSIH8dJwGcioju1+zngSL003fH5dDb0O+B3QO9o9yjgzIhYHxHdwPmDXGd/7Q3WwxRBuNILwCuB1wFK+2/tAG2dHxGrI+Iv/SxfHhFXR8QLwDnANhQpplq9D7g+Ipamts8GtqU4uJf79nBEPAH8iH5+x6w+HPRbXAoIx0dEO7AXxSj3a2nxbsB56bR7A/AEIIqReK9HStPPAjv0s6oJwHbA8lJ7P0nlvR6vGGX2trczRZD5Yx/t7ga8t7fN1O4BwKTNbXc/7VxTamMF8DdgYqlOf9u6C7C6tKw8vTmD/ez600axT14iIm4E/pviTGWdpAUqrt9szkB93rQ8Il4Euim2u1a7AA9WtL2a6n7HrA4c9DMSEb8HLqEI/lD88f1bRIwrvbaNiF8NprmK+ceAvwCvL7U1NiIG8wf8GPAc8I99LFsNfKeij9tHxPxBtFvZzsyKdraJiDWDeO9aoL00P7lied0fVStpB+BgipTby0TE+RGxDzCVIs3zqQH6MlAfN21TOvNqpzjTgCIQb1eq++ohtPswxQG3t22ldQ3mc7dh4KDfwiS9Ll04bU/zkylyu7ekKt8ETpf0+rR8rKT3DrL5R4H23txsGsF9CzhX0j+k9tokvWughtJ7LwbOSRcCt5T0VklbA98FDpf0rlS+jYqLwu2baXKrVK/3NSZt65d6U1eSJqRrGoNxFcXntGO6xvChPj6L1wyyrc1ScTF8H+BaiusO3+6jzlsk7Zdy7s9QHDBfrLEv+0h6T/qsPkpxh1fv78kdwPvT5z+D4rpIr0eB8SrdXlrhKuBQSdNTfz+R2h7MwMKGgYN+a3sa2A+4VdIzFH/Ed1P84RER1wBnAVdIeiotmznItm8E7gEekfRYKjsNWAncktr7GcWFzMH4JHAXcBtFSuMsYIuIWE1xkfHTQA/FiP1TbP53dwnFWUfv63PAecBi4AZJT1N8FvsNsm9foEh3/Clt09W89LbXLwP/kVJHnxxkm5VOTf16HLgUWA68LV0srfQqigPseorUyePAV9OyhcDU1Jdrh7D+6yjy7+uB44D3pBw8wCnA4cAGiruDNrWbzh4vBx5I63xJSigi7qO4LvN1ijO6wykuej8/hL5ZHcn/RMVsaCT9O3B0RLxjwMpmI4xH+mYDkDRJ0v4q7vXfk+JM6Zpm98usGv52ntnAXgH8D8V95BuAK4BvNLNDZtVyesfMLCNO75iZZWREp3d23nnn6OjoaHY3zMxGleXLlz8WEX0+qmREB/2Ojg66urqa3Q0zs1FF0oP9LXN6x8wsIw76ZmYZcdA3M8uIg76ZWUYc9M3MMuKgb2aWEQd9M7OMOOibmWXEQd/MLCMj+hu5ZjnomHf9pulV8w9tYk8sBx7pm5llZMCgL+liSesk3V0q+6qk30u6U9I1ksaVlp0uaaWk+8r/H1XSjFS2UtK8um+JmW3SMe/6TS+zssGM9C8BZlSULQX2iog3AH8ATgeQNBU4Gnh9es830j9T3hK4gOL/r04Fjkl1zawGDu42VAPm9CPi55I6KspuKM3eAhyZpmcBV0TEX4E/SVoJ7JuWrYyIBwAkXZHq3ltb981ai/P7NtzqcSH3RODKNN1GcRDo1Z3KAFZXlO/XV2OS5gJzAXbdddc6dM+seRzEbaSpKehL+gywEbisPt2BiFgALADo7Oz0/3K0UWe4Uy39te8Ujw1G1UFf0vHAYcD0+Ps/2l0DTC5Va09lbKbcLAu1jPod0K1eqgr6kmYApwLviIhnS4sWA9+TdA6wCzAF+A0gYIqk3SmC/dHA+2vpuNlI4qBso8WAQV/S5cCBwM6SuoEzKO7W2RpYKgnglog4KSLukXQVxQXajcDJEfG31M6HgJ8CWwIXR8Q9w7A9Zma2GYO5e+eYPooXbqb+l4Av9VG+BFgypN6ZWcP4onMe/I1cM7OMOOibmWXEQd/MLCN+yqbZCOU7gmw4OOibtbjKg4cv0ubN6R0zs4w46JuZZcTpHbMmcL7emsUjfTOzjDjom5llxOkdsyo5RWOjkUf6ZmYZ8UjfLDN+sFre9Pf/fzLydHZ2RldXV7O7YbZJjikdHxhGH0nLI6Kzr2VO75iZZcTpHbMB5Di6L3M6qLV4pG9mlhGP9C1rHsVabjzSNzPLiEf6ZlYVnyWNTg76Zn3I/eKttS6nd8zMMuKRvlni0b3lwEHfzAbNB8bRz0HfsuCLjmaFAXP6ki6WtE7S3aWynSQtlXR/+rljKpek8yWtlHSnpL1L75md6t8vafbwbI6ZNVvHvOs3vWzkGcyF3EuAGRVl84BlETEFWJbmAWYCU9JrLnAhFAcJ4AxgP2Bf4IzeA4WZmTXOgOmdiPi5pI6K4lnAgWl6EXAzcFoqvzSKR3feImmcpEmp7tKIeAJA0lKKA8nltW+C2dB4BGo5q/aWzYkRsTZNPwJMTNNtwOpSve5U1l/5y0iaK6lLUldPT0+V3TMzs77UfCE3IkJS3R7KHxELgAVQPE+/Xu1afjyiN3u5akf6j6a0DennulS+BphcqteeyvorNzOzBqp2pL8YmA3MTz+vK5V/SNIVFBdtn4yItZJ+CpxZunj7TuD06rtt9nIe2ZsNbMCgL+lyiguxO0vqprgLZz5wlaQ5wIPAUan6EuAQYCXwLHACQEQ8Iek/gdtSvS/0XtQ1q4UD/cjW3/7xdyWaZzB37xzTz6LpfdQN4OR+2rkYuHhIvTOzUcEH39HDD1wzM8uIg76ZWUYc9M3MMuKgb2aWET9l00YdXzQ0q55H+mZmGXHQNzPLiIO+mVlGHPTNzDLiC7k2YvlfHJrVn4O+mTWVD+6N5fSOmVlGHPTNzDLioG9mlhHn9M1sxHB+f/g56NuI4kcsmA0vB30zazgf3JvHOX0zs4w46JuZZcRB38wsIw76ZmYZ8YVcMxvxfCtn/Tjom9mI5Dt8hoeDvo0KDgBm9VFT0Jf0MeCDQAB3AScAk4ArgPHAcuC4iHhe0tbApcA+wOPA+yJiVS3rN7P8ONVTm6ov5EpqAz4CdEbEXsCWwNHAWcC5EbEHsB6Yk94yB1ifys9N9czMrIFqvXtnDLCtpDHAdsBa4CDg6rR8EXBEmp6V5knLp0tSjes3M7MhqDroR8Qa4GzgIYpg/yRFOmdDRGxM1bqBtjTdBqxO792Y6o+vbFfSXEldkrp6enqq7Z6ZmfWhlvTOjhSj992BXYDtgRm1digiFkREZ0R0TpgwodbmzMyspJb0zsHAnyKiJyJeAH4I7A+MS+kegHZgTZpeA0wGSMvHUlzQNTOzBqnl7p2HgGmStgP+AkwHuoCbgCMp7uCZDVyX6i9O879Oy2+MiKhh/dYifDumWePUktO/leKC7O0Ut2tuASwATgM+LmklRc5+YXrLQmB8Kv84MK+GfpuZWRVquk8/Is4AzqgofgDYt4+6zwHvrWV9ZmZWGz9wzcwsIw76ZmYZ8bN3zGzU6u+RDH5UQ/880jczy4hH+tYUvk3TrDk80jczy4hH+mbWEnz2ODge6ZuZZcRB38wsI07vWF34Fjmz0cFB34aVDwZmI4vTO2ZmGXHQNzPLiNM71jC+pc6s+TzSNzPLiIO+mVlGHPTNzDLinL6ZtbT+riXleguxg76ZZanyYJDLQcBB3+rOd+mYjVzO6ZuZZcRB38wsI07vmJkNUis8S8pB38yM1gjog+H0jplZRmoa6UsaB1wE7AUEcCJwH3Al0AGsAo6KiPWSBJwHHAI8CxwfEbfXsn5rLt+lY62qlX+3ax3pnwf8JCJeB7wRWAHMA5ZFxBRgWZoHmAlMSa+5wIU1rtvMzIao6qAvaSzwdmAhQEQ8HxEbgFnAolRtEXBEmp4FXBqFW4BxkiZVu34zMxu6Wkb6uwM9wLcl/VbSRZK2ByZGxNpU5xFgYppuA1aX3t+dyl5C0lxJXZK6enp6auiemZlVqiWnPwbYG/hwRNwq6Tz+nsoBICJCUgyl0YhYACwA6OzsHNJ7bfi1cq7TLAe1jPS7ge6IuDXNX01xEHi0N22Tfq5Ly9cAk0vvb09lZmbWIFUH/Yh4BFgtac9UNB24F1gMzE5ls4Hr0vRi4AMqTAOeLKWBzMysAWr9ctaHgcskvQJ4ADiB4kBylaQ5wIPAUanuEorbNVdS3LJ5Qo3rNjNrmtH6Za6agn5E3AF09rFoeh91Azi5lvWZmVlt/I1cM7OMOOibmWXEQd/MLCMO+mZmGfGjlW1A/kKWWetw0Dczq9Foun3T6R0zs4w46JuZZcTpHeuT8/hm1RnpqR6P9M3MMuKgb2aWEQd9M7OMOOibmWXEF3LNzBqsmRd7HfTNzIbJSLyTx+kdM7OMOOibmWXE6R3bxF/IMmt9DvoZcnA3y5fTO2ZmGfFI38ysAUbKGbZH+mZmGXHQNzPLiNM7mRgpp5Zm1lw1B31JWwJdwJqIOEzS7sAVwHhgOXBcRDwvaWvgUmAf4HHgfRGxqtb1m5mNZo3+1m490junACtK82cB50bEHsB6YE4qnwOsT+XnpnpmZtZANQV9Se3AocBFaV7AQcDVqcoi4Ig0PSvNk5ZPT/XNzKxBah3pfw04FXgxzY8HNkTExjTfDbSl6TZgNUBa/mSqb2ZmDVJ1Tl/SYcC6iFgu6cB6dUjSXGAuwK677lqvZrPki7dmVqmWkf7+wLslraK4cHsQcB4wTlLvwaQdWJOm1wCTAdLysRQXdF8iIhZERGdEdE6YMKGG7pmZWaWqg35EnB4R7RHRARwN3BgRxwI3AUemarOB69L04jRPWn5jRES16zczs6Ebji9nnQZ8XNJKipz9wlS+EBifyj8OzBuGdZuZ2WbU5ctZEXEzcHOafgDYt486zwHvrcf6rH/O45vZ5vgxDGZmGXHQNzPLiIO+mVlGHPTNzDLioG9mlhEHfTOzjDjom5llxEHfzCwjDvpmZhlx0Dczy4iDvplZRvyP0UchP1/HzKrlkb6ZWUYc9M3MMuKgb2aWEQd9M7OMOOibmWXEd++MYOW7dFbNP7SJPTGzVuGRvplZRhz0zcwy4qBvZpYR5/RHCX8L18zqwSN9M7OMOOibmWXEQd/MLCNVB31JkyXdJOleSfdIOiWV7yRpqaT7088dU7kknS9ppaQ7Je1dr40wM7PBqWWkvxH4RERMBaYBJ0uaCswDlkXEFGBZmgeYCUxJr7nAhTWs28zMqlD13TsRsRZYm6aflrQCaANmAQemaouAm4HTUvmlERHALZLGSZqU2rHEd+mY2XCqS05fUgfwZuBWYGIpkD8CTEzTbcDq0tu6U1llW3MldUnq6unpqUf3zMwsqTnoS9oB+AHw0Yh4qrwsjepjKO1FxIKI6IyIzgkTJtTaPTMzK6kp6EvaiiLgXxYRP0zFj0qalJZPAtal8jXA5NLb21OZmZk1SC137whYCKyIiHNKixYDs9P0bOC6UvkH0l0804Annc83M2usWh7DsD9wHHCXpDtS2aeB+cBVkuYADwJHpWVLgEOAlcCzwAk1rNvMzKpQy907vwDUz+LpfdQP4ORq12dmZrXzN3LNzDLip2yOAL4338waxSN9M7OMOOibmWXEQd/MLCPO6TeJ8/hm1gwe6ZuZZcRB38wsI07vNJBTOmbWbB7pm5llxEHfzCwjDvpmZhlx0Dczy4iDvplZRnz3zjDzHTtmNpJ4pG9mlhGP9OukPKJfNf/QJvbEzKx/DvrDwCkdMxupnN4xM8uIg76ZWUYc9M3MMuKgb2aWEQd9M7OMOOibmWXEQd/MLCMND/qSZki6T9JKSfMavX4zs5w1NOhL2hK4AJgJTAWOkTS1kX0wM8tZo0f6+wIrI+KBiHgeuAKY1eA+mJllq9GPYWgDVpfmu4H9yhUkzQXmptk/S7qvxnXuDDxWYxujjbc5D97mFqOz+iyuZpt362/BiHv2TkQsABbUqz1JXRHRWa/2RgNvcx68zXmo9zY3Or2zBphcmm9PZWZm1gCNDvq3AVMk7S7pFcDRwOIG98HMLFsNTe9ExEZJHwJ+CmwJXBwR9wzzauuWKhpFvM158Dbnoa7brIioZ3tmZjaC+Ru5ZmYZcdA3M8tISwf9HB75IGmypJsk3SvpHkmnpPKdJC2VdH/6uWOz+1pPkraU9FtJP07zu0u6Ne3rK9ONAi1D0jhJV0v6vaQVkt6awT7+WPqdvlvS5ZK2abX9LOliSesk3V0q63O/qnB+2vY7Je1dzTpbNuhn9MiHjcAnImIqMA04OW3nPGBZREwBlqX5VnIKsKI0fxZwbkTsAawH5jSlV8PnPOAnEfE64I0U296y+1hSG/ARoDMi9qK48eNoWm8/XwLMqCjrb7/OBKak11zgwmpW2LJBn0we+RARayPi9jT9NEUwaKPY1kWp2iLgiKZ0cBhIagcOBS5K8wIOAq5OVVpte8cCbwcWAkTE8xGxgRbex8kYYFtJY4DtgLW02H6OiJ8DT1QU97dfZwGXRuEWYJykSUNdZysH/b4e+dDWpL40hKQO4M3ArcDEiFibFj0CTGxWv4bB14BTgRfT/HhgQ0RsTPOttq93B3qAb6eU1kWStqeF93FErAHOBh6iCPZPAstp7f3cq7/9WpeY1spBPyuSdgB+AHw0Ip4qL4vivtyWuDdX0mHAuohY3uy+NNAYYG/gwoh4M/AMFamcVtrHACmPPYvigLcLsD0vT4O0vOHYr60c9LN55IOkrSgC/mUR8cNU/GjvqV/6ua5Z/auz/YF3S1pFkbI7iCLfPS6lAaD19nU30B0Rt6b5qykOAq26jwEOBv4UET0R8QLwQ4p938r7uVd/+7UuMa2Vg34Wj3xI+eyFwIqIOKe0aDEwO03PBq5rdN+GQ0ScHhHtEdFBsU9vjIhjgZuAI1O1ltlegIh4BFgtac9UNB24lxbdx8lDwDRJ26Xf8d5tbtn9XNLffl0MfCDdxTMNeLKUBhq8iGjZF3AI8Afgj8Bnmt2fYdrGAyhO/+4E7kivQyjy3MuA+4GfATs1u6/DsO0HAj9O068BfgOsBL4PbN3s/tV5W98EdKX9fC2wY6vvY+DzwO+Bu4HvAFu32n4GLqe4ZvECxRndnP72KyCKOxL/CNxFcWfTkNfpxzCYmWWkldM7ZmZWwUHfzCwjDvpmZhlx0Dczy4iDvplZRhz0zcwy4qBvZpaR/weWEn3vE+5zAQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def tokenize(corpus):  # corpus: Tokenized Sentence's List\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "split_tensor, split_tokenizer = tokenize(filtered_corpus)\n",
    "\n",
    "print(\"Split Vocab Size:\", len(split_tokenizer.index_word))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Split Vocab Size: 209340\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 그냥 띄어쓰기 기반으로 데이터를 정리하면 이렇게 20만단어나 제 모델이 학습해야해요.\n",
    "### 그럼 1,2번 나온단어는 어차피 학습도 제대로 안될꺼고, 또 빼고 학습하자니, 분통이 터지네요ㅜㅜ\n",
    "### 그러면 한번 형태소 단위로 잘라봅시다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "for idx, word in enumerate(split_tokenizer.word_index):\n",
    "    print(idx, \":\", word)\n",
    "\n",
    "    if idx > 10: break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 : 이\n",
      "1 : 있다.\n",
      "2 : 밝혔다.\n",
      "3 : 말했다.\n",
      "4 : 수\n",
      "5 : 있는\n",
      "6 : 그는\n",
      "7 : 대한\n",
      "8 : 전했다.\n",
      "9 : 위해\n",
      "10 : 지난\n",
      "11 : 이번\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "mecab_corpus = []\n",
    "for kor in filtered_corpus:\n",
    "    # 코드를 작성하세요\n",
    "    mecab_corpus.append(mecab.morphs(kor))\n",
    "    # re.sub(r\"[^0-9A-zㅏ-ㅣㄱ-ㅎ가-힣?!,.()]\",\"\",kor)\n",
    "    # komoran_corpus.append(komoran.morphs(kor))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# 위에서 사용한 코드를 활용해 MeCab 단어 사전을 만들어보세요. \n",
    "# Hint : mecab.morphs()를 사용해서 형태소분석을 합니다.\n",
    "from konlpy.tag import Komoran, Mecab\n",
    "import re\n",
    "mecab = Mecab()\n",
    "komoran = Komoran()\n",
    "\n",
    "\n",
    "komoran_corpus = []\n",
    "\n",
    "for kor in filtered_corpus:\n",
    "    # 코드를 작성하세요\n",
    "    #mecab_corpus.append(mecab.morphs(kor))\n",
    "    kor = re.sub(r\"[^0-9A-zㅏ-ㅣㄱ-ㅎ가-힣?!,.()\\s'\\\"]\",\"\",kor)\n",
    "    komoran_corpus.append(komoran.morphs(kor))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 위와같은 코드로 받는 이유는 komoran은 글자만 학습을 한 상태여서 그래요. 이모지 같은게 데이터에 섞여있어서, 오류가 나더라구요. mecab은 그냥 다 처리 하더라구요."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "mecab_tensor, mecab_tokenizer = tokenize(mecab_corpus)\n",
    "komoran_tensor, komoran_tokenizer = tokenize(komoran_corpus)\n",
    "\n",
    "print(\"MeCab Vocab Size:\", len(mecab_tokenizer.index_word))\n",
    "print(\"Komoran Vocab Size:\", len(komoran_tokenizer.index_word))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MeCab Vocab Size: 47782\n",
      "Komoran Vocab Size: 43944\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 확실히 단어수가 4-5배 가량 줄었네요.\n",
    "### 이렇게 하면 학습도 효율적일 뿐만 아니라, 없던 단어까지 만들어낼 수 있습니다!\n",
    "### 성능은 말할 것도 없구요.ㅎㅎ\n",
    "### komoran이 단어를 더 효율적으로 잘 줄여준 모습을 볼 수 있습니다.\n",
    "### 제가 여러차례 테스트해본 결과, mecab은 한글을 위해서 나온 건 아니다보니, '했다'를 '했', '다'로는 해주지만, '하', '였', '다'로는 구분해주지 않습니다. komoran은 해줍니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "print(komoran_tokenizer.sequences_to_texts([komoran_tensor[100]]))\n",
    "# print(komoran_tokenizer.index_word(komoran_tensor[100]))\n",
    "sentence = \"\"\n",
    "\n",
    "for w in komoran_tensor[100]:\n",
    "    if w == 0: continue\n",
    "    sentence += komoran_tokenizer.index_word[w] + \" \"\n",
    "\n",
    "print(sentence)\n",
    "\n",
    "print(mecab_tokenizer.sequences_to_texts([mecab_tensor[100]]))\n",
    "texts = mecab_tokenizer.sequences_to_texts([mecab_tensor[100]])\n",
    "print(texts[0])\n",
    "# print(mecab_tokenizer.index_word(mecab_tensor[100]))\n",
    "sentence = \"\"\n",
    "\n",
    "for w in mecab_tensor[100]:\n",
    "    if w == 0: continue\n",
    "    sentence += mecab_tokenizer.index_word[w] + \" \"\n",
    "    \n",
    "print(sentence)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['vice foreign minister lee taesik is appointed as the new ambassador to the u . s . 새 주 미 대사 에 이태식 외무부 차관']\n",
      "vice foreign minister lee taesik is appointed as the new ambassador to the u . s . 새 주 미 대사 에 이태식 외무부 차관 \n",
      "['vice foreign minister lee tae - sik is appointed as the new ambassador to the u . s . 새 주미 대사 에 이태식 외무부 차관']\n",
      "vice foreign minister lee tae - sik is appointed as the new ambassador to the u . s . 새 주미 대사 에 이태식 외무부 차관\n",
      "vice foreign minister lee tae - sik is appointed as the new ambassador to the u . s . 새 주미 대사 에 이태식 외무부 차관 \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 이제 그 잘난 sentencepiece는 얼마나 더 잘하는지 봐보겠습니다!\n",
    "```bash\n",
    "pip install sentencepiece\n",
    "```\n",
    "### 로 설치해줍니다.\n",
    "![image](data/me.png)\n",
    "### 왜 저는 이미 깔려있는걸까요??"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "temp_file = 'data/kor_en/korean-english-park.train.ko.temp'\n",
    "\n",
    "vocab_size = 20000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_corpus:            # 이전 스텝에서 정제했던 corpus를 활용합니다.\n",
    "        row = re.sub(r\"[^0-9A-zㅏ-ㅣㄱ-ㅎ가-힣?!,.()\\s'\\\"]\",\"\",row)\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "#위 Train에서  --model_type = 'unigram'이 디폴트 적용되어 있습니다. --model_type = 'bpe' 로 옵션을 주어 변경할 수 있습니다.\n",
    "\n",
    "!ls -l korean_spm*"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=data/kor_en/korean-english-park.train.ko.temp --model_prefix=korean_spm --vocab_size=20000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: data/kor_en/korean-english-park.train.ko.temp\n",
      "  input_format: \n",
      "  model_prefix: korean_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 20000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: data/kor_en/korean-english-park.train.ko.temp\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 69564 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=4116173\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1232\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 69564 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 152972 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 69564\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 201713\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 201713 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=80377 obj=14.5716 num_tokens=428565 num_tokens/piece=5.33194\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=70276 obj=13.2643 num_tokens=430609 num_tokens/piece=6.1274\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=52694 obj=13.2971 num_tokens=448375 num_tokens/piece=8.50903\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=52647 obj=13.253 num_tokens=448987 num_tokens/piece=8.52825\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=39484 obj=13.4352 num_tokens=472814 num_tokens/piece=11.9748\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=39484 obj=13.3908 num_tokens=472946 num_tokens/piece=11.9782\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=29613 obj=13.6408 num_tokens=499042 num_tokens/piece=16.8521\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=29613 obj=13.5887 num_tokens=499089 num_tokens/piece=16.8537\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=22209 obj=13.8932 num_tokens=526227 num_tokens/piece=23.6943\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=22209 obj=13.8365 num_tokens=526233 num_tokens/piece=23.6946\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=22000 obj=13.8479 num_tokens=527067 num_tokens/piece=23.9576\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=22000 obj=13.8457 num_tokens=527067 num_tokens/piece=23.9576\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: korean_spm.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: korean_spm.vocab\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-rw-r--r-- 1 hchang hchang 620482 Dec 10 15:47 korean_spm.model\n",
      "-rw-r--r-- 1 hchang hchang 400780 Dec 10 15:47 korean_spm.vocab\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[759, 10, 637, 11, 3418, 10, 519, 42, 3]\n",
      "['▁아버지', '가', '방', '에', '들어', '가', '신', '다', '.']\n",
      "아버지가방에들어가신다.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "def sp_tokenize(s, corpus):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./korean_spm.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({idx:word})\n",
    "        index_word.update({word:idx})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, word_index, index_word"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "#sp_tokenize(s, corpus) 사용예제\n",
    "\n",
    "my_corpus = ['나는 밥을 먹었습니다.', '그러나 여전히 ㅠㅠ 배가 고픕니다...']\n",
    "tensor, word_index, index_word = sp_tokenize(s, my_corpus)\n",
    "print(tensor)\n",
    "print(list(tensor[0]))\n",
    "print(type(tokensIDs))\n",
    "print(tokensIDs)\n",
    "# print(s.DecodeIds())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 668 4571    4 3381 2061    3    0    0    0    0    0    0    0]\n",
      " [  68 1083   83    6    0 8211    6   14    0 2509    3    3    3]]\n",
      "[668, 4571, 4, 3381, 2061, 3, 0, 0, 0, 0, 0, 0, 0]\n",
      "<class 'list'>\n",
      "[759, 10, 637, 11, 3418, 10, 519, 42, 3]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 왜..!! 왜 똑같은 숫자인데, 오류가 나는걸까요... numpy.int를 지원하지 않는대요...\n",
    "### 아래처럼 넣어야 나왔습니다.."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "print(s.DecodeIds(list(map(int,tensor[0]))+list(map(int,tensor[1]))))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "나는 밥을 먹었습니다. ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  그러나 여전히  ⁇  배가 고 ⁇ 니다...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ?? 이거하려고 한걸까요???? 아무래도 진짜 능력을 확인해봐야 할 것 같습니다.\n",
    "### 자기도 어이가 없는지 패딩을 모르고 ??를 밷는군요..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "# with open('data/naver_movie/ratings.txt','r') as f:\n",
    "#     with open('data/naver_movie/refined_ratings.txt','w') as re_f:\n",
    "#         for i in f.readlines():\n",
    "#             j = re.sub(r\"\")\n",
    "#             re_f.write()\n",
    "data_path = 'data/'\n",
    "train_data = pd.read_table(data_path + 'ratings_train.txt')\n",
    "test_data = pd.read_table(data_path + 'ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_data[\"document\"][0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'아 더빙.. 진짜 짜증나네요 목소리'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 생각해보니, 어차피 감성분석 성능만 볼것이기 때문에, 특별히 패딩을 구분해주지 않아도 될 것 같습니다. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from konlpy.tag import Komoran, Mecab\n",
    "import sentencepiece as spm\n",
    "import re\n",
    "komoran = Komoran()\n",
    "# mecab = Mecab()\n",
    "\n",
    "\n",
    "def preprocessing(data_df,tokenizer):\n",
    "    data_df.drop_duplicates(inplace=True)\n",
    "    data_df = data_df.dropna(how='any')\n",
    "\n",
    "    token_seq = []\n",
    "    for sentence in data_df['document']:\n",
    "        sentence = re.sub(r\"[^0-9A-zㅏ-ㅣㄱ-ㅎ가-힣?!,.()\\s'\\\"]\",\"\",sentence)\n",
    "        sentence = tokenizer.morphs(sentence)\n",
    "        token_seq.append(sentence)\n",
    "    \n",
    "    return token_seq, tokenizer\n",
    "           \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "komoran_seq, komoran = preprocessing(train_data, komoran)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "mecab_seq, mecab = preprocessing(train_data, mecab)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "c = 1\n",
    "for i in train_data['document']:\n",
    "    print(i)\n",
    "    c +=1\n",
    "    if c == 5:\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "아 더빙.. 진짜 짜증나네요 목소리\n",
      "흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
      "너무재밓었다그래서보는것을추천한다\n",
      "교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip list | grep sentencepiece"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sentencepiece                 0.1.95\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 슬슬 모델학습을 해보기 위해 클라우드로 넘어가겠습니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import pandas as pd\n",
    "ratings_train = pd.read_table('ratings_train.txt')\n",
    "ratings_test = pd.read_table('ratings_test.txt')\n",
    "ratings_train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "raw = ratings_train['document']\n",
    "\n",
    "for sen in raw:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(raw))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in raw:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 146\n",
      "문장의 평균 길이: 35\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYaElEQVR4nO3debBcZZ3G8e/DDqKEJWJIMt4oqAOUAkYWZUYKlCRsYSxlwjAaMFMZpnAGLBQTsEQUNCgDgsNiFGSRISAKREAxstSMOiI37BAjAQJJWBJIwqYggd/8cd7Gk6Y73Te309233+dTdev2ec/pt99+b/dz3n7P6XMVEZiZWR7W63QDzMysfRz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibtZikPkkhaYMW1nmEpF+2sL4HJO2Tbn9V0o9aWPeJkn7QqvqstRz6PU7S3pJ+K+k5Scsl/UbSh1pQ75GSft2KNraSpIWSPjaUHlPSxZL+IumF9HO/pG9K2qKyTURcHhH7N1nXqY22i4idIuK2tW1z6fH2kbS4qu5vRMS/DLZuWzcc+j1M0tuA64HvAlsBI4FTgFc62S6r6VsR8VZgOHAUsCfwG0lvaeWDtPLThw1NDv3e9h6AiLgiIl6LiD9HxC8j4t7KBpI+K2mepBWSbpL0ztK6kHS0pIckrZR0rgp/C1wA7CXpRUkr0/YbSzpD0uOSnpZ0gaRN07p9JC2WdLykpZKelHRU6bE2lfSfkh5Ln0p+XbrvnunTykpJ91SmJQZC0nqSpkl6WNKzkq6StFVaV5mOmZza/oykk6radknqo3mSTqiMbiVdBvwN8LPUFyeUHvaIWvWtSUS8HBF3AIcAW1PsAFb7ZJX+Bmelfnxe0n2SdpY0FTgCOCG15Wdp+4WSviTpXuAlSRvU+HSyiaQr0yeNOyV9oPT8Q9L2peWLJZ2adkg/B7ZLj/eipO1UNV0k6RAV00krJd2WXj+VdQslfUHSvenvfqWkTZrpK1s7Dv3e9kfgtRRYEyRtWV4paSJwIvAJihHm/wJXVNVxEPAh4P3AYcC4iJgHHA38X0RsHhHD0rYzKHY0uwDbU3yy+EqprncAW6TyKcC5pTadAXwQ+DDFp5ITgNcljQRuAE5N5V8AfiJp+AD74t+BQ4GPAtsBK4Bzq7bZG3gvsB/wlVI4nQz0Ae8CPg78c+UOEfFp4HHg4NQX32qivoYi4gVgDvB3NVbvD/w9RV9vQfF3eTYiZgKXU3xq2DwiDi7d53DgQGBYRKyqUedE4McUffzfwLWSNmzQxpeACcAT6fE2j4gnyttIeg/Fa+o4itfYjRQ7yI1Kmx0GjAfGULzOjlzT49rgOPR7WEQ8TxE8AXwfWCZptqRt0yZHA9+MiHkpCL4B7FIe7QMzImJlRDwO3EoR6G8iScBU4PMRsTyF1jeASaXNXgW+FhGvRsSNwIvAeyWtB3wWODYilqRPJb+NiFcoAvbGiLgxIl6PiDlAP3DAALvjaOCkiFic6v0q8EmtPt1xSvo0dA9wD1AZ7R4GfCMiVkTEYuCcJh+zXn3NeoIihKu9CrwVeB+g9Pd7skFd50TEooj4c531cyPi6oh4FTgT2IRiimmw/hG4ISLmpLrPADal2LmX2/ZERCwHfkad15i1hkO/x6VAODIiRgE7U4xyv5NWvxM4O33sXgksB0QxEq94qnT7T8DmdR5qOLAZMLdU3y9SecWzVaPMSn3bUITMwzXqfSfwqUqdqd69gRFret516rmmVMc84DVg29I29Z7rdsCi0rry7TVptu/qGUnxN1lNRNwC/BfFJ5WlkmaqOH6zJo3a/Mb6iHgdWEzxvAdrO+CxqroXsXavMWsBh35GIuIPwMUU4Q/Fm+9fI2JY6WfTiPhtM9VVLT8D/BnYqVTXFhHRzBv4GeBl4N011i0CLqtq41siYkYT9VbXM6Gqnk0iYkkT930SGFVaHl21vuWXqpW0OfAxiim3N4mIcyLig8COFNM8X2zQlkZtfOM5pU9eoyg+aUARxJuVtn3HAOp9gmKHW6lb6bGa6XdbBxz6PUzS+9KB01FpeTTF3O7v0iYXANMl7ZTWbyHpU01W/zQwqjI3m0Zw3wfOkvT2VN9ISeMaVZTuexFwZjoQuL6kvSRtDPwIOFjSuFS+iYqDwqPWUOWGabvKzwbpuZ5WmbqSNDwd02jGVRT9tGU6xvC5Gn3xribrWiMVB8M/CFxLcdzhhzW2+ZCkPdKc+0sUO8zXB9mWD0r6ROqr4yjO8Kq8Tu4G/in1/3iK4yIVTwNbq3R6aZWrgAMl7Zfae3yqu5mBha0DDv3e9gKwB3C7pJco3sT3U7zxiIhrgNOBWZKeT+smNFn3LcADwFOSnkllXwIWAL9L9f2K4kBmM74A3AfcQTGlcTqwXkQsojjIeCKwjGLE/kXW/Nq9keJTR+Xnq8DZwGzgl5JeoOiLPZps29copjseTc/palY/7fWbwJfT1NEXmqyz2gmpXc8ClwJzgQ+ng6XV3kaxg11BMXXyLPDttO5CYMfUlmsH8PjXUcy/rwA+DXwizcEDHAscDKykODvojXrTp8crgEfSY642JRQR8ymOy3yX4hPdwRQHvf8ygLZZC8n/RMVsYCT9GzApIj7acGOzLuORvlkDkkZI+oiKc/3fS/FJ6ZpOt8tsbfjbeWaNbQR8j+I88pXALOC8TjbIbG15esfMLCOe3jEzy0hXT+9ss8020dfX1+lmmJkNKXPnzn0mImpeqqSrQ7+vr4/+/v5ON8PMbEiR9Fi9dZ7eMTPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLSFd/I3co6Jt2w2rLC2cc2KGWmJk15pG+mVlGHPpmZhlx6JuZZcShb2aWER/IXQvVB2/NzIYKj/TNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw79FuubdoPP4zezruXQNzPLiEPfzCwjDn0zs4w49M3MMtJ06EtaX9Jdkq5Py2Mk3S5pgaQrJW2UyjdOywvS+r5SHdNT+XxJ41r+bMzMbI0GMtI/FphXWj4dOCsitgdWAFNS+RRgRSo/K22HpB2BScBOwHjgPEnrD675ZmY2EE2FvqRRwIHAD9KygH2Bq9MmlwCHptsT0zJp/X5p+4nArIh4JSIeBRYAu7fgOZiZWZOaHel/BzgBeD0tbw2sjIhVaXkxMDLdHgksAkjrn0vbv1Fe4z5mZtYGDUNf0kHA0oiY24b2IGmqpH5J/cuWLWvHQ5qZZaOZkf5HgEMkLQRmUUzrnA0Mk1T5z1ujgCXp9hJgNEBavwXwbLm8xn3eEBEzI2JsRIwdPnz4gJ+QmZnV1zD0I2J6RIyKiD6KA7G3RMQRwK3AJ9Nmk4Hr0u3ZaZm0/paIiFQ+KZ3dMwbYAfh9y56JmZk1NJj/kfslYJakU4G7gAtT+YXAZZIWAMspdhRExAOSrgIeBFYBx0TEa4N4/K5Wuf7OwhkHdrglZmZ/NaDQj4jbgNvS7UeocfZNRLwMfKrO/U8DThtoI83MrDX8jVwzs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQbxP/71wz6wYOfTOzjAzmG7nWBI/uzaybeKRvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh36b+Xx9M+skh76ZWUYc+mZmGXHom5llxKHfIZ7bN7NOcOibmWXEoW9mlhGHfod5msfM2slX2RwAh7OZDXUe6ZuZZcShb2aWEYd+l/Dcvpm1g0PfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDv0u47N4zGxdcuibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEl1buUuUzeBbOOLCDLTGzXtJwpC9pE0m/l3SPpAcknZLKx0i6XdICSVdK2iiVb5yWF6T1faW6pqfy+ZLGrbNnZWZmNTUzvfMKsG9EfADYBRgvaU/gdOCsiNgeWAFMSdtPAVak8rPSdkjaEZgE7ASMB86TtH4Ln4uZmTXQMPSj8GJa3DD9BLAvcHUqvwQ4NN2emJZJ6/eTpFQ+KyJeiYhHgQXA7q14EmZm1pymDuRKWl/S3cBSYA7wMLAyIlalTRYDI9PtkcAigLT+OWDrcnmN+5Qfa6qkfkn9y5YtG/ATMjOz+po6kBsRrwG7SBoGXAO8b101KCJmAjMBxo4dG+vqcYaS6ssy+MCuma2tAZ2yGRErgVuBvYBhkio7jVHAknR7CTAaIK3fAni2XF7jPmZm1gbNnL0zPI3wkbQp8HFgHkX4fzJtNhm4Lt2enZZJ62+JiEjlk9LZPWOAHYDft+h5mJlZE5qZ3hkBXJLOtFkPuCoirpf0IDBL0qnAXcCFafsLgcskLQCWU5yxQ0Q8IOkq4EFgFXBMmjaytVSZ9vF0j5k1q2HoR8S9wK41yh+hxtk3EfEy8Kk6dZ0GnDbwZlqZL71sZmvLl2EwM8uIQ9/MLCMO/R7g/7ZlZs1y6JuZZcShb2aWEYd+D/E0j5k14tA3M8uIQ9/MLCMO/R7kaR4zq8eh38Mc/mZWzaFvZpYR/2P0Jni0bGa9wiN9M7OMOPTNzDLi0Dczy4hDPwM+i8fMKhz6ZmYZcehnxCN+M3Pom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxNfTz1D5W7kLZxzYwZaYWbt5pG9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6mWv0j1X8j1fMeotD38wsIw59M7OMNPxGrqTRwKXAtkAAMyPibElbAVcCfcBC4LCIWCFJwNnAAcCfgCMj4s5U12Tgy6nqUyPiktY+HVtb1VM4/qauWW9q5jIMq4DjI+JOSW8F5kqaAxwJ3BwRMyRNA6YBXwImADuknz2A84E90k7iZGAsxc5jrqTZEbGi1U/KBs/z+Ga9qeH0TkQ8WRmpR8QLwDxgJDARqIzULwEOTbcnApdG4XfAMEkjgHHAnIhYnoJ+DjC+lU/GzMzWbEBz+pL6gF2B24FtI+LJtOopiukfKHYIi0p3W5zK6pVXP8ZUSf2S+pctWzaQ5pmZWQNNh76kzYGfAMdFxPPldRERFFM2gxYRMyNibESMHT58eCuqNDOzpKnQl7QhReBfHhE/TcVPp2kb0u+lqXwJMLp091GprF65DWE+j99saGkY+ulsnAuBeRFxZmnVbGByuj0ZuK5U/hkV9gSeS9NANwH7S9pS0pbA/qnMeoDD32xoaObsnY8Anwbuk3R3KjsRmAFcJWkK8BhwWFp3I8XpmgsoTtk8CiAilkv6OnBH2u5rEbG8FU+iVSqh5dMV38x9Y9YbGoZ+RPwaUJ3V+9XYPoBj6tR1EXDRQBpo3cXhbza0+d8l1uBga8xTOWZDky/DYGaWEY/018CjWTPrNR7pm5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUZ8nj4+H7+V/G1ms+7mkb6ZWUYc+mZmGXHom5llxKFvZpaRLEPf/+XJzHKVZeibmeXKoW9mlhGHvplZRhz6ZmYZyfobuT6Ya2a58UjfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjWZ2947N1zCx3HumbmWXEoW9mlpGspnesfcpTaf7XiWbdwyN9M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy0jD0Jd0kaSlku4vlW0laY6kh9LvLVO5JJ0jaYGkeyXtVrrP5LT9Q5Imr5unU1vftBt8CQYzM5ob6V8MjK8qmwbcHBE7ADenZYAJwA7pZypwPhQ7CeBkYA9gd+Dkyo7CzMzap2HoR8T/AMuriicCl6TblwCHlsovjcLvgGGSRgDjgDkRsTwiVgBzePOOxMzM1rG1ndPfNiKeTLefArZNt0cCi0rbLU5l9crfRNJUSf2S+pctW7aWzTMzs1oGfSA3IgKIFrSlUt/MiBgbEWOHDx/eqmrNzIy1D/2n07QN6ffSVL4EGF3ablQqq1duGfCBdMtVN7721zb0ZwOVM3AmA9eVyj+TzuLZE3guTQPdBOwvact0AHf/VGZmZm3U8NLKkq4A9gG2kbSY4iycGcBVkqYAjwGHpc1vBA4AFgB/Ao4CiIjlkr4O3JG2+1pEVB8cNjOzdaxh6EfE4XVW7Vdj2wCOqVPPRcBFA2qdmZm1lL+Ra2aWEYe+mVlGHPrWNt14JoNZbhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZcehb2/ksHrPOceibmWXEoW8d4xG/Wfs59M3MMtLwgmtm61q90f7CGQe2uSVmva+nQ99TB2bWCd2cPZ7esa7lOX+z1nPom5llxKFvQ4ZH/maD19Nz+tbbyjsAH/Q1a45D37pe9ejeo32ztefQt55QvSPwyN+sNs/pW0/zcQCz1Xmkbz2pXtBXyv1JwNaFoTDAcOhbFpo9LuCdgfU6h76Z2SANhRF+hef0zWqodSzAxwesF3ikb1biULeBGIqvF4e+2RrUelPXOz3UB4ltKHDomw3SYA8S+5vF1k4OfbM2aWYqoPrTgj89dKehOK1T4dA3G4L8DeTOGMphX+HQN+tCvt5Qd+ml/nfom/WQZsKpeuqo3nrrrbCvcOib9YCBhFOjbQdzHGEoH4PI5YC6Q9/MahrMKLfRMYeBHrAeSCA3W/eanl8vjvArFBGdbkNdY8eOjf7+/rW+fy//4cx62ZqmoBpNT3Wjdn9ykDQ3IsbWWueRvpl1nVxH4e3ga++YmWXEoW9mlpG2h76k8ZLmS1ogaVq7H9/MLGdtDX1J6wPnAhOAHYHDJe3YzjaYmeWs3QdydwcWRMQjAJJmAROBB9vcDjOzthnIl+bWtXaH/khgUWl5MbBHeQNJU4GpafFFSfMH+ZjbAM8Mso51bSi0EdzOVhoKbQS3s5XW2Ead3tLHeme9FV13ymZEzARmtqo+Sf31zlftFkOhjeB2ttJQaCO4na3ULW1s94HcJcDo0vKoVGZmZm3Q7tC/A9hB0hhJGwGTgNltboOZWbbaOr0TEaskfQ64CVgfuCgiHljHD9uyqaJ1aCi0EdzOVhoKbQS3s5W6oo1dfe0dMzNrLX8j18wsIw59M7OM9Gzod+vlHiSNlnSrpAclPSDp2FS+laQ5kh5Kv7fsgrauL+kuSden5TGSbk99emU6GN/pNg6TdLWkP0iaJ2mvLu3Lz6e/9/2SrpC0STf0p6SLJC2VdH+prGb/qXBOau+9knbrYBu/nf7m90q6RtKw0rrpqY3zJY1rRxvrtbO07nhJIWmbtNyRvoQeDf0uv9zDKuD4iNgR2BM4JrVtGnBzROwA3JyWO+1YYF5p+XTgrIjYHlgBTOlIq1Z3NvCLiHgf8AGK9nZVX0oaCfwHMDYidqY4iWES3dGfFwPjq8rq9d8EYIf0MxU4v4NtnAPsHBHvB/4ITAdI76VJwE7pPuelPOhUO5E0GtgfeLxU3Km+hIjouR9gL+Cm0vJ0YHqn21WnrdcBHwfmAyNS2QhgfofbNYriDb8vcD0gim8TblCrjzvUxi2AR0knJJTKu60vK99E34rijLnrgXHd0p9AH3B/o/4DvgccXmu7drexat0/AJen26u91ynOFNyrU32Zyq6mGJAsBLbpdF/25Eif2pd7GNmhttQlqQ/YFbgd2DYinkyrngK27VS7ku8AJwCvp+WtgZURsSotd0OfjgGWAT9M01A/kPQWuqwvI2IJcAbFSO9J4DlgLt3XnxX1+q9b31efBX6ebndVGyVNBJZExD1VqzrWzl4N/a4naXPgJ8BxEfF8eV0Uu/6OnUsr6SBgaUTM7VQbmrQBsBtwfkTsCrxE1VROp/sSIM2JT6TYSW0HvIUa0wDdqBv6b00knUQxZXp5p9tSTdJmwInAVzrdlrJeDf2uvtyDpA0pAv/yiPhpKn5a0oi0fgSwtFPtAz4CHCJpITCLYornbGCYpMoX+rqhTxcDiyPi9rR8NcVOoJv6EuBjwKMRsSwiXgV+StHH3dafFfX6r6veV5KOBA4Cjkg7J+iuNr6bYkd/T3ovjQLulPQOOtjOXg39rr3cgyQBFwLzIuLM0qrZwOR0ezLFXH9HRMT0iBgVEX0UfXdLRBwB3Ap8Mm3W0TYCRMRTwCJJ701F+1Fcprtr+jJ5HNhT0mbp719pZ1f1Z0m9/psNfCadebIn8FxpGqitJI2nmH48JCL+VFo1G5gkaWNJYygOlP6+E22MiPsi4u0R0ZfeS4uB3dLrtnN92a4DHO3+AQ6gOKr/MHBSp9tTatfeFB+X7wXuTj8HUMyZ3ww8BPwK2KrTbU3t3Qe4Pt1+F8UbaAHwY2DjLmjfLkB/6s9rgS27sS+BU4A/APcDlwEbd0N/AldQHGd4lSKUptTrP4qD+eem99R9FGcjdaqNCyjmxCvvoQtK25+U2jgfmNDJvqxav5C/HsjtSF9GhC/DYGaWk16d3jEzsxoc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5ll5P8BJjENaZM7ENsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 문장길이 140에서 하나의 피크를 찍는이유는 제한 길이때문이 아닐까요? 또 그런 것 치고는 넘는 것들이 있어 있상합니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def check_sentence_with_length(raw, length):\n",
    "    count = 0\n",
    "    \n",
    "    for sen in raw:\n",
    "        if len(sen) == length:\n",
    "            print(sen)\n",
    "            count += 1\n",
    "            if count > 100: return\n",
    "\n",
    "check_sentence_with_length(raw, 1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "아\n",
      "잼\n",
      "1\n",
      "4\n",
      "4\n",
      "굿\n",
      "짱\n",
      "휴\n",
      ".\n",
      "1\n",
      "굿\n",
      "음\n",
      "?\n",
      "?\n",
      "ㅎ\n",
      "굿\n",
      "ㅋ\n",
      "굿\n",
      "즐\n",
      "♥\n",
      "굳\n",
      "ㅋ\n",
      "네\n",
      "ㅎ\n",
      "ㅋ\n",
      "굿\n",
      "ㅇ\n",
      "k\n",
      ".\n",
      "굿\n",
      "굿\n",
      "굳\n",
      "ㅠ\n",
      "?\n",
      "1\n",
      "ㅋ\n",
      "굿\n",
      "쒯\n",
      "굿\n",
      "굿\n",
      "굳\n",
      "♬\n",
      "굿\n",
      "토\n",
      "ㅋ\n",
      "ㅋ\n",
      "굿\n",
      "ㅋ\n",
      "굿\n",
      "O\n",
      "똥\n",
      "ㅎ\n",
      ".\n",
      "굿\n",
      "ㅎ\n",
      "짱\n",
      "굳\n",
      "굿\n",
      "굿\n",
      "짱\n",
      "?\n",
      "z\n",
      "굿\n",
      "짱\n",
      "음\n",
      "굳\n",
      "ㅇ\n",
      "헐\n",
      "굳\n",
      "굳\n",
      "굿\n",
      "굿\n",
      "굿\n",
      "삼\n",
      "꽝\n",
      "굿\n",
      "굿\n",
      "굿\n",
      "굿\n",
      "ㅎ\n",
      "굳\n",
      "굿\n",
      "4\n",
      "!\n",
      "?\n",
      "ㅎ\n",
      "1\n",
      "굳\n",
      ".\n",
      "ㅎ\n",
      "풉\n",
      "아\n",
      "굿\n",
      "똥\n",
      "ㅅ\n",
      "왜\n",
      "ㄴ\n",
      "굳\n",
      "쉣\n",
      "봐\n",
      "z\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "check_sentence_with_length(raw, 146)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\"스폰으로 먹고사는 방송이라 어쩔수 없다고 하지만. 이건 그냥 비현실적인 자동차만;...독일3사&슈퍼카 홍보 프로그램도 아니구.대중적인 자동차 방송으로 이루어 졌으면 합니다. 보는내내 \"\"카탈로그 책자\"\"를 \"\"동영상으로 보여주는 방송\"\" 같아서 씁쓸하네요.!\"\n",
      "\"\"\"니 짓은 생각않고, 웬 복수!\"\"의 교훈이라! 그럼 \"\"서바이벌 액션\"\"으로 홍보하면 안되지! 초반 45분은 멋지게 열더니.. 억지 반전, 하드고어로 시간끌다가, 허둥지둥 화해로 끝내버리네. 90분 러닝타임에 엔딩자막만 11분 틀어주는 해괴망측한 영화~!\"\n",
      "\"2007.02.25_ 벌교의 한 국밥집_ 점심: \"\"갸는 첫째고, 저 놈은 우리 둘째~\"\" 재문: \"\"아줌마! 미안해~ 그냥.. 아줌마! 나 그 남방 잘 어울려ㅠ_ㅠ?\"\" 대식에게 복수하려던 1주일 전_ 대식의 엄마를 먼저 만났다. 사랑의 꽃남방도..^-^o\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 무튼 댓글 길이제한이 있는거 같아서 너무 긴 글은 없네요. 그래도 문장개수가 너무 많은게 있을까요?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "temp_file = 'aiffel/sentiment_classification/ratings.temp'\n",
    "\n",
    "ratings_train.drop_duplicates(inplace=True)\n",
    "ratings_train = ratings_train.dropna(how='any')\n",
    "with open(temp_file, 'w') as f:\n",
    "    for sentence in ratings_train['document']:            # 이전 스텝에서 정제했던 corpus를 활용합니다.\n",
    "        sentence = re.sub(r\"[^0-9A-zㅏ-ㅣㄱ-ㅎ가-힣?!,.()\\s'\\\"]\",\"\",sentence)\n",
    "        f.write(str(sentence) + '\\n')\n",
    "\n",
    "target_train = ratings_train['label']\n",
    "!head aiffel/sentiment_classification/ratings.temp"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "아 더빙.. 진짜 짜증나네요 목소리\n",
      "흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
      "너무재밓었다그래서보는것을추천한다\n",
      "교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
      "사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n",
      "막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.\n",
      "원작의 긴장감을 제대로 살려내지못했다.\n",
      "별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네\n",
      "액션이 없는데도 재미 있는 몇안되는 영화\n",
      "왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 전처리 해서 받은 문장을 단어개수별로 보겠습니다... 라고 하려고 했는데, 저희는 어차피 형태소 단위로 볼거여서 지금 확정하기가 어렵군요ㅜㅜ\n",
    "### 어쩔 수 없이 패딩을 넉넉하게 주어서 학습을 시켜보겠습니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "testtemp_file = 'aiffel/sentiment_classification/testratings.temp'\n",
    "\n",
    "ratings_test.drop_duplicates(inplace=True)\n",
    "ratings_test = ratings_test.dropna(how='any')\n",
    "with open(testtemp_file, 'w') as f:\n",
    "    for sentence in ratings_test['document']:            # 이전 스텝에서 정제했던 corpus를 활용합니다.\n",
    "        sentence = re.sub(r\"[^0-9A-zㅏ-ㅣㄱ-ㅎ가-힣?!,.()\\s'\\\"]\",\"\",sentence)\n",
    "        f.write(str(sentence) + '\\n')\n",
    "\n",
    "target_test = ratings_test['label']\n",
    "!head aiffel/sentiment_classification/testratings.temp"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "굳 ㅋ\n",
      "GDNTOPCLASSINTHECLUB\n",
      "뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n",
      "지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n",
      "3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n",
      "음악이 주가 된, 최고의 음악영화\n",
      "진정한 쓰레기\n",
      "마치 미국애니에서 튀어나온듯한 창의력없는 로봇디자인부터가,고개를 젖게한다\n",
      "갈수록 개판되가는 중국영화 유치하고 내용없음 폼잡다 끝남 말도안되는 무기에 유치한cg남무 아 그립다 동사서독같은 영화가 이건 3류아류작이다\n",
      "이별의 아픔뒤에 찾아오는 새로운 인연의 기쁨 But, 모든 사람이 그렇지는 않네..\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "temp_file = 'aiffel/sentiment_classification/ratings.temp'\n",
    "vocab_size = 20000 # 으로 했더니, 단어 너무 많다고 8아래로 해달라고 오류 뜸... 단어개수가 아니라, 최대 길이였나봐요.\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=aiffel/naver --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "#위 Train에서  --model_type = 'unigram'이 디폴트 적용되어 있습니다. --model_type = 'bpe' 로 옵션을 주어 변경할 수 있습니다.\n",
    "# 라고 써있었는데, 둘다 없다고 나옵니다.. 뭘까요???\n",
    "!ls -l aiffel/naver*"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-rw-r--r-- 1 root root 617188 Dec 14 02:01 aiffel/naver.model\n",
      "-rw-r--r-- 1 root root 397544 Dec 14 02:01 aiffel/naver.vocab\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "vocab_size = 20000 # 으로 했더니, 단어 너무 많다고 8아래로 해달라고 오류 뜸... 단어개수가 아니라, 최대 길이였나봐요.\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=aiffel/sentiment_classification/naver_bpe --vocab_size={} --model_type=bpe'.format(temp_file, vocab_size)    \n",
    ")\n",
    "#위 Train에서  --model_type = 'unigram'이 디폴트 적용되어 있습니다. --model_type = 'bpe' 로 옵션을 주어 변경할 수 있습니다.\n",
    "# 라고 써있었는데, 둘다 없다고 나옵니다.. 뭘까요???\n",
    "!ls -l aiffel/sentiment_classification/naver_bpe*"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-rw-r--r-- 1 root root 602543 Dec 14 02:02 aiffel/sentiment_classification/naver_bpe.model\n",
      "-rw-r--r-- 1 root root 333758 Dec 14 02:02 aiffel/sentiment_classification/naver_bpe.vocab\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('aiffel/naver.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[6856, 450, 16, 10837, 206, 21, 3]\n",
      "['▁아버지가', '방', '에', '들어가', '신', '다', '.']\n",
      "아버지가방에들어가신다.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('aiffel/sentiment_classification/naver_bpe.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[7316, 12695, 1405, 18407, 15219, 18399]\n",
      "['▁아버지가', '방에', '들어', '가', '신다', '.']\n",
      "아버지가방에들어가신다.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import tensorflow as tf\n",
    "def tokenize(corpus, tensorlen):  # corpus: Tokenized Sentence's List\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post',maxlen=tensorlen)\n",
    "\n",
    "    return tensor, tokenizer\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "temp_file = 'aiffel/sentiment_classification/ratings.temp'\n",
    "token_seq = []\n",
    "with open(temp_file,'r') as f:\n",
    "    for i in f.readlines():\n",
    "        token_seq.append(s.SampleEncodeAsPieces(i,1, 0.0))\n",
    "senten_tensor, senten_tokenizer = tokenize(token_seq,100)\n",
    "print(token_seq[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['▁아', '▁더빙', '..', '▁진짜', '▁짜증나네요', '▁목소리']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 흠... 저는 형태소 100개면 하고 싶은 표현은 들었을거라고 생각하거든요."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "print(f\"bpe모델 단어개수: {len(senten_tokenizer.index_word)}\")\n",
    "senten_tensor[0]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bpe모델 단어개수: 20933\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([   46,  1110,     2,    15, 17003,  1889,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "for i in range(20):\n",
    "    print(senten_tokenizer.index_word[i+1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".\n",
      "..\n",
      "...\n",
      "▁영화\n",
      ",\n",
      "?\n",
      "▁너무\n",
      "!\n",
      "▁정말\n",
      "의\n",
      "이\n",
      "도\n",
      "▁이\n",
      "에\n",
      "▁진짜\n",
      "을\n",
      "은\n",
      "가\n",
      "....\n",
      "는\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 확실히 불용어 제거가 없으니 가장 많이 쓰이는 단어는 이렇군요.\n",
    "### 이어서 komoran과 비교해보겠습니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "komoran_seq, komoran = preprocessing(ratings_train, komoran)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "komoran_tensor, komoran_tokenizer = tokenize(komoran_seq,100)\n",
    "for i in range(20):\n",
    "    print(komoran_tokenizer.index_word[i+1])\n",
    "\n",
    "print(\"Komoran Vocab Size:\", len(komoran_tokenizer.index_word))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ".\n",
      "이\n",
      "하\n",
      "ㄴ\n",
      "는\n",
      "다\n",
      "영화\n",
      "보\n",
      "고\n",
      "에\n",
      "가\n",
      "의\n",
      "도\n",
      "은\n",
      "을\n",
      "았\n",
      "게\n",
      "...\n",
      "었\n",
      "ㄹ\n",
      "Komoran Vocab Size: 59099\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "print(f\"bpe모델 단어개수: {len(senten_tokenizer.index_word)}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bpe모델 단어개수: 20933\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### !!!뭐가 더 좋다는 건가 했는데, 이렇게 차이가 많이 날까요?!??\n",
    "### 단어 개수가 적어서 학습 효율도 훨씬 좋고, 능력도 좋을까요?? 너무 궁금합니다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "from tensorflow.keras import layers\n",
    "vocab_size = 60000\n",
    "embedding_size = 256\n",
    "\n",
    "komoran_model = tf.keras.Sequential()\n",
    "komoran_model.add(layers.Embedding(vocab_size,\n",
    "                                   embedding_size,\n",
    "                                   input_length=100,\n",
    "                                   embeddings_initializer=tf.keras.initializers.RandomNormal()\n",
    "))\n",
    "komoran_model.add(layers.Conv1D(256,3, activation='relu', padding=\"same\"))\n",
    "komoran_model.add(layers.Conv1D(256,3, activation='relu', padding=\"same\"))\n",
    "komoran_model.add(layers.Conv1D(128,3, activation='relu', padding=\"same\"))\n",
    "komoran_model.add(layers.BatchNormalization())\n",
    "komoran_model.add(layers.Conv1D(128,3, activation='relu', padding=\"same\"))\n",
    "komoran_model.add(layers.Conv1D(64,3, activation='relu', padding=\"same\"))\n",
    "komoran_model.add(layers.Conv1D(32,3, activation='relu', padding=\"same\"))\n",
    "komoran_model.add(layers.BatchNormalization())\n",
    "komoran_model.add(layers.GlobalAveragePooling1D())\n",
    "komoran_model.add(layers.Dense(10, activation='relu'))\n",
    "komoran_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "komoran_model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 100, 256)          15360000  \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 100, 256)          196864    \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 100, 256)          196864    \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 100, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 100, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 100, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 100, 64)           24640     \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 100, 32)           6176      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 100, 32)           128       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_11  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 15,933,237\n",
      "Trainable params: 15,932,917\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "bpe_vocab_size = 30000\n",
    "\n",
    "bpe_model = tf.keras.Sequential()\n",
    "bpe_model.add(layers.Embedding(bpe_vocab_size,\n",
    "                               embedding_size,\n",
    "                               input_length=100,\n",
    "                               embeddings_initializer=tf.keras.initializers.RandomNormal()\n",
    "))   \n",
    "bpe_model.add(layers.Conv1D(256,3, activation='relu', padding=\"same\"))\n",
    "bpe_model.add(layers.Conv1D(256,3, activation='relu', padding=\"same\"))\n",
    "bpe_model.add(layers.Conv1D(128,3, activation='relu', padding=\"same\"))\n",
    "bpe_model.add(layers.BatchNormalization())\n",
    "bpe_model.add(layers.Conv1D(128,3, activation='relu', padding=\"same\"))\n",
    "bpe_model.add(layers.Conv1D(64,3, activation='relu', padding=\"same\"))\n",
    "bpe_model.add(layers.Conv1D(32,3, activation='relu', padding=\"same\"))\n",
    "bpe_model.add(layers.BatchNormalization())\n",
    "bpe_model.add(layers.GlobalAveragePooling1D())\n",
    "bpe_model.add(layers.Dense(10, activation='relu'))\n",
    "bpe_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "bpe_model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 100, 256)          7680000   \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 100, 256)          196864    \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 100, 256)          196864    \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 100, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 100, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 100, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 100, 64)           24640     \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 100, 32)           6176      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 100, 32)           128       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_12  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 8,253,237\n",
      "Trainable params: 8,252,917\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "batch_size = 128\n",
    "print(komoran_tensor.shape)\n",
    "target_train = tf.constant(np.array(target_train).T)\n",
    "print(target_train.shape)\n",
    "BUFFER_SIZE = len(komoran_tensor)\n",
    "komoran_train = tf.data.Dataset.from_tensor_slices((komoran_tensor, target_train))\n",
    "\n",
    "komoran_train.batch(batch_size)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(149995, 100)\n",
      "(149995, 1)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 100), (None, 1)), types: (tf.int32, tf.int64)>"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "bpe_train = tf.data.Dataset.from_tensor_slices({'x_train': senten_tensor, 'y_train': target_train})\n",
    "bpe_train.batch(batch_size)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: {x_train: (None, 100), y_train: (None, 1)}, types: {x_train: tf.int32, y_train: tf.int64}>"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "komoran_model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = komoran_model.fit(komoran_tensor,\n",
    "                            target_train,\n",
    "                            epochs=10,\n",
    "                            batch_size=128\n",
    "\n",
    ")\n",
    "# what = komoran_train.__iter__()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1172/1172 [==============================] - 119s 84ms/step - loss: 0.3505 - accuracy: 0.8441\n",
      "Epoch 2/10\n",
      "1172/1172 [==============================] - 81s 69ms/step - loss: 0.2371 - accuracy: 0.9067\n",
      "Epoch 3/10\n",
      "1172/1172 [==============================] - 80s 68ms/step - loss: 0.1593 - accuracy: 0.9401\n",
      "Epoch 4/10\n",
      "1172/1172 [==============================] - 79s 67ms/step - loss: 0.1084 - accuracy: 0.9614\n",
      "Epoch 5/10\n",
      "1172/1172 [==============================] - 79s 67ms/step - loss: 0.0782 - accuracy: 0.9727\n",
      "Epoch 6/10\n",
      "1172/1172 [==============================] - 79s 67ms/step - loss: 0.0619 - accuracy: 0.9790\n",
      "Epoch 7/10\n",
      "1172/1172 [==============================] - 78s 67ms/step - loss: 0.0519 - accuracy: 0.9821\n",
      "Epoch 8/10\n",
      "1172/1172 [==============================] - 78s 67ms/step - loss: 0.0457 - accuracy: 0.9849\n",
      "Epoch 9/10\n",
      "1172/1172 [==============================] - 80s 68ms/step - loss: 0.0421 - accuracy: 0.9858\n",
      "Epoch 10/10\n",
      "1172/1172 [==============================] - 79s 68ms/step - loss: 0.0387 - accuracy: 0.9863\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "bpe_model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = bpe_model.fit(senten_tensor,\n",
    "                        target_train,\n",
    "                        epochs=10,\n",
    "                        batch_size=256\n",
    "\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "586/586 [==============================] - 89s 118ms/step - loss: 0.4644 - accuracy: 0.7634\n",
      "Epoch 2/10\n",
      "586/586 [==============================] - 51s 87ms/step - loss: 0.2484 - accuracy: 0.8980\n",
      "Epoch 3/10\n",
      "586/586 [==============================] - 51s 87ms/step - loss: 0.1844 - accuracy: 0.9273\n",
      "Epoch 4/10\n",
      "586/586 [==============================] - 51s 87ms/step - loss: 0.1235 - accuracy: 0.9525\n",
      "Epoch 5/10\n",
      "586/586 [==============================] - 51s 87ms/step - loss: 0.0726 - accuracy: 0.9743\n",
      "Epoch 6/10\n",
      "586/586 [==============================] - 51s 88ms/step - loss: 0.0426 - accuracy: 0.9858\n",
      "Epoch 7/10\n",
      "586/586 [==============================] - 51s 87ms/step - loss: 0.0299 - accuracy: 0.9900\n",
      "Epoch 8/10\n",
      "586/586 [==============================] - 51s 87ms/step - loss: 0.0232 - accuracy: 0.9924\n",
      "Epoch 9/10\n",
      "586/586 [==============================] - 52s 88ms/step - loss: 0.0210 - accuracy: 0.9924\n",
      "Epoch 10/10\n",
      "586/586 [==============================] - 51s 88ms/step - loss: 0.0178 - accuracy: 0.9934\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "def gen_tensor(corpus, tokenizer, tensorlen):  # corpus: Tokenized Sentence's List\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post',maxlen=tensorlen)\n",
    "\n",
    "    return tensor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "def preprocessing(data_df,tokenizer):\n",
    "    data_df.drop_duplicates(inplace=True)\n",
    "    data_df = data_df.dropna(how='any')\n",
    "    \n",
    "    token_seq = []\n",
    "    for sentence in data_df['document']:\n",
    "        sentence = re.sub(r\"[^0-9A-zㅏ-ㅣㄱ-ㅎ가-힣?!,.()\\s'\\\"]\",\"\",sentence)\n",
    "        try:\n",
    "            sentence = tokenizer.morphs(sentence)\n",
    "            token_seq.append(sentence)\n",
    "        except:\n",
    "            token_seq.append(['하..'])\n",
    "    return token_seq, tokenizer\n",
    "           "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "komoran_test_seq, _ = preprocessing(ratings_test, komoran)\n",
    "komoran_test_tensor = gen_tensor(komoran_test_seq, komoran_tokenizer, 100)\n",
    "target_tst = tf.constant(np.array(target_test).T)\n",
    "\n",
    "komoran_results = komoran_model.evaluate(komoran_test_tensor,target_tst, verbose=2)\n",
    "\n",
    "print(komoran_results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1563/1563 - 10s - loss: 1.0517 - accuracy: 0.8075\n",
      "[1.051745891571045, 0.8074684739112854]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "\n",
    "temp_file = 'aiffel/sentiment_classification/testratings.temp'\n",
    "token_seq = []\n",
    "with open(temp_file,'r') as f:\n",
    "    for i in f.readlines():\n",
    "        token_seq.append(s.SampleEncodeAsPieces(i,1, 0.0))\n",
    "bpe_test_tensor, _ = tokenize(token_seq,100)\n",
    "print(token_seq[0])\n",
    "\n",
    "target_tst = tf.constant(np.array(target_test).T)\n",
    "\n",
    "bpe_results = bpe_model.evaluate(bpe_test_tensor,target_tst, verbose=2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['▁굳', '▁ᄏ']\n",
      "1563/1563 - 16s - loss: 3.6413 - accuracy: 0.5137\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "komoran_model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = komoran_model.fit(komoran_tensor,\n",
    "                            target_train,\n",
    "                            epochs=3,\n",
    "                            batch_size=256\n",
    "\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "586/586 [==============================] - 113s 190ms/step - loss: 0.4647 - accuracy: 0.7706\n",
      "Epoch 2/3\n",
      "586/586 [==============================] - 110s 188ms/step - loss: 0.2435 - accuracy: 0.9043\n",
      "Epoch 3/3\n",
      "586/586 [==============================] - 111s 189ms/step - loss: 0.1554 - accuracy: 0.9434\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "komoran_results = komoran_model.evaluate(komoran_test_tensor,target_tst, verbose=2)\n",
    "\n",
    "print(komoran_results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1563/1563 - 9s - loss: 0.3524 - accuracy: 0.8588\n",
      "[0.3524326682090759, 0.858831524848938]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "bpe_model.compile(optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = bpe_model.fit(senten_tensor,\n",
    "                        target_train,\n",
    "                        epochs=2,\n",
    "                        batch_size=256\n",
    "\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "586/586 [==============================] - 75s 124ms/step - loss: 0.1005 - accuracy: 0.9637\n",
      "Epoch 2/2\n",
      "586/586 [==============================] - 72s 124ms/step - loss: 0.0530 - accuracy: 0.9827\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "temp_file = 'aiffel/sentiment_classification/testratings.temp'\n",
    "token_seq = []\n",
    "with open(temp_file,'r') as f:\n",
    "    for i in f.readlines():\n",
    "        token_seq.append(s.SampleEncodeAsPieces(i,1, 0.0))\n",
    "bpe_test_tensor = gen_tensor(token_seq, senten_tokenizer, 100)\n",
    "print(token_seq[0])\n",
    "\n",
    "bpe_results = bpe_model.evaluate(bpe_test_tensor,target_tst, verbose=2)\n",
    "print(bpe_results)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['▁굳', '▁ᄏ']\n",
      "1563/1563 - 9s - loss: 0.4027 - accuracy: 0.8549\n",
      "[0.4026740491390228, 0.8548513054847717]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 뭐 안했는데, 85%씩은 그냥 넘네요ㅎㅎ 뿌듯합니다!"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "interpreter": {
   "hash": "026aceb1435085fcef523649cdfc9385a4a55dbc5c65435142607853821fa50a"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}